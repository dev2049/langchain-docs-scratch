<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Embeddings &mdash; 🦜🔗 LangChain 0.0.190</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/autodoc_pydantic.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/js/mendablesearch.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Vector Stores" href="vectorstores.html" />
    <link rel="prev" title="Document Transformers" href="document_transformers.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            🦜🔗 LangChain
          </a>
              <div class="version">
                0.0.190
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Abstractions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="base_classes.html">Base classes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../model_io.html">Model I/O</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../data_connection.html">Data connection</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="document_loaders.html">Document Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="document_transformers.html">Document Transformers</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="vectorstores.html">Vector Stores</a></li>
<li class="toctree-l2"><a class="reference internal" href="retrievers.html">Retrievers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="chains.html">Chains</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agents.html">Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory.html">Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="callbacks.html">Callbacks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Additional</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="experimental.html">Experimental</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">🦜🔗 LangChain</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../data_connection.html">Data connection</a></li>
      <li class="breadcrumb-item active">Embeddings</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/hwchase17/langchain/blob/master/docs/api_referencemodules/embeddings.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-langchain.embeddings">
<span id="embeddings"></span><h1>Embeddings<a class="headerlink" href="#module-langchain.embeddings" title="Permalink to this headline"></a></h1>
<p>Wrappers around embedding modules.</p>
<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.OpenAIEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">OpenAIEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-embedding-ada-002'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-embedding-ada-002'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_ctx_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8191</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_organization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disallowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request_timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">headers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/openai.html#OpenAIEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.OpenAIEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around OpenAI embedding models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> set with your API key or pass it
as a named parameter to the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="n">openai</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">(</span><span class="n">openai_api_key</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In order to use the library with Microsoft Azure endpoints, you need to set
the OPENAI_API_TYPE, OPENAI_API_BASE, OPENAI_API_KEY and OPENAI_API_VERSION.
The OPENAI_API_TYPE must be set to ‘azure’ and the others correspond to
the properties of your endpoint.
In addition, the deployment name must be passed as the model parameter.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_TYPE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;azure&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_BASE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;https://&lt;your-endpoint.openai.azure.com/&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;your AzureOpenAI key&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_VERSION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;2023-03-15-preview&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_PROXY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;http://your-corporate-proxy:8080&quot;</span>

<span class="kn">from</span> <span class="nn">langchain.embeddings.openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">(</span>
    <span class="n">deployment</span><span class="o">=</span><span class="s2">&quot;your-embeddings-deployment-name&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;your-embeddings-model-name&quot;</span><span class="p">,</span>
    <span class="n">api_base</span><span class="o">=</span><span class="s2">&quot;https://your-endpoint.openai.azure.com/&quot;</span><span class="p">,</span>
    <span class="n">api_type</span><span class="o">=</span><span class="s2">&quot;azure&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;This is a test query.&quot;</span>
<span class="n">query_result</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model</strong> (<em>str</em>) – </p></li>
<li><p><strong>deployment</strong> (<em>str</em>) – </p></li>
<li><p><strong>openai_api_version</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>openai_api_base</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>openai_api_type</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>openai_proxy</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>embedding_ctx_length</strong> (<em>int</em>) – </p></li>
<li><p><strong>openai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>openai_organization</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>allowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.Set</em><em>[</em><em>str</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>disallowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.Set</em><em>[</em><em>str</em><em>]</em><em>, </em><em>typing.Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>chunk_size</strong> (<em>int</em>) – </p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) – </p></li>
<li><p><strong>request_timeout</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>headers</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.OpenAIEmbeddings.chunk_size">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">chunk_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1000</span></em><a class="headerlink" href="#langchain.embeddings.OpenAIEmbeddings.chunk_size" title="Permalink to this definition"></a></dt>
<dd><p>Maximum number of texts to embed in each batch</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.OpenAIEmbeddings.max_retries">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">6</span></em><a class="headerlink" href="#langchain.embeddings.OpenAIEmbeddings.max_retries" title="Permalink to this definition"></a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.OpenAIEmbeddings.request_timeout">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">request_timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.OpenAIEmbeddings.request_timeout" title="Permalink to this definition"></a></dt>
<dd><p>Timeout in seconds for the OpenAPI request.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.OpenAIEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/openai.html#OpenAIEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.OpenAIEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Call out to OpenAI’s embedding endpoint for embedding search docs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p></li>
<li><p><strong>chunk_size</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The chunk size of embeddings. If None, will use the chunk size
specified by the class.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.OpenAIEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/openai.html#OpenAIEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.OpenAIEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Call out to OpenAI’s embedding endpoint for embedding query text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embedding for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">HuggingFaceEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sentence-transformers/all-mpnet-base-v2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encode_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface.html#HuggingFaceEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around sentence_transformers embedding models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">sentence_transformers</span></code> python package installed.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;sentence-transformers/all-mpnet-base-v2&quot;</span>
<span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cpu&#39;</span><span class="p">}</span>
<span class="n">encode_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;normalize_embeddings&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFaceEmbeddings</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">,</span>
    <span class="n">encode_kwargs</span><span class="o">=</span><span class="n">encode_kwargs</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>cache_folder</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
<li><p><strong>encode_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceEmbeddings.cache_folder">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache_folder</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceEmbeddings.cache_folder" title="Permalink to this definition"></a></dt>
<dd><p>Path to store models.
Can be also set by SENTENCE_TRANSFORMERS_HOME environment variable.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceEmbeddings.encode_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">encode_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceEmbeddings.encode_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Key word arguments to pass when calling the <cite>encode</cite> method of the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceEmbeddings.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceEmbeddings.model_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceEmbeddings.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'sentence-transformers/all-mpnet-base-v2'</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceEmbeddings.model_name" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface.html#HuggingFaceEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Compute doc embeddings using a HuggingFace transformer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface.html#HuggingFaceEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Compute query embeddings using a HuggingFace transformer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.CohereEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">CohereEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'embed-english-v2.0'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cohere_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/cohere.html#CohereEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.CohereEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around Cohere embedding models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">cohere</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">COHERE_API_KEY</span></code> set with your API key or pass it
as a named parameter to the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">CohereEmbeddings</span>
<span class="n">cohere</span> <span class="o">=</span> <span class="n">CohereEmbeddings</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;embed-english-light-v2.0&quot;</span><span class="p">,</span> <span class="n">cohere_api_key</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model</strong> (<em>str</em>) – </p></li>
<li><p><strong>truncate</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>cohere_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.CohereEmbeddings.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'embed-english-v2.0'</span></em><a class="headerlink" href="#langchain.embeddings.CohereEmbeddings.model" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.CohereEmbeddings.truncate">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">truncate</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.CohereEmbeddings.truncate" title="Permalink to this definition"></a></dt>
<dd><p>Truncate embeddings that are too long from start or end (“NONE”|”START”|”END”)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.CohereEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/cohere.html#CohereEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.CohereEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Call out to Cohere’s embedding endpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.CohereEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/cohere.html#CohereEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.CohereEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Call out to Cohere’s embedding endpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="langchain.embeddings.ElasticsearchEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">ElasticsearchEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_field</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text_field'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/elasticsearch.html#ElasticsearchEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.ElasticsearchEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around Elasticsearch embedding models.</p>
<p>This class provides an interface to generate embeddings using a model deployed
in an Elasticsearch cluster. It requires an Elasticsearch connection object
and the model_id of the model deployed in the cluster.</p>
<p>In Elasticsearch you need to have an embedding model loaded and deployed.
- <a class="reference external" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-trained-model.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-trained-model.html</a>
- <a class="reference external" href="https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-deploy-models.html">https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-deploy-models.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>MlClient</em>) – </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – </p></li>
<li><p><strong>input_field</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.ElasticsearchEmbeddings.from_credentials">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_credentials</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">es_cloud_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">es_user</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">es_password</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_field</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text_field'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/elasticsearch.html#ElasticsearchEmbeddings.from_credentials"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.ElasticsearchEmbeddings.from_credentials" title="Permalink to this definition"></a></dt>
<dd><p>Instantiate embeddings from Elasticsearch credentials.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) – The model_id of the model deployed in the Elasticsearch
cluster.</p></li>
<li><p><strong>input_field</strong> (<em>str</em>) – The name of the key for the input text field in the
document. Defaults to ‘text_field’.</p></li>
<li><p><strong>es_cloud_id</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – (str, optional): The Elasticsearch cloud ID to connect to.</p></li>
<li><p><strong>es_user</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – (str, optional): Elasticsearch username.</p></li>
<li><p><strong>es_password</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – (str, optional): Elasticsearch password.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#langchain.embeddings.ElasticsearchEmbeddings" title="langchain.embeddings.elasticsearch.ElasticsearchEmbeddings">langchain.embeddings.elasticsearch.ElasticsearchEmbeddings</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">ElasticsearchEmbeddings</span>

<span class="c1"># Define the model ID and input field name (if different from default)</span>
<span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;your_model_id&quot;</span>
<span class="c1"># Optional, only if different from &#39;text_field&#39;</span>
<span class="n">input_field</span> <span class="o">=</span> <span class="s2">&quot;your_input_field&quot;</span>

<span class="c1"># Credentials can be passed in two ways. Either set the env vars</span>
<span class="c1"># ES_CLOUD_ID, ES_USER, ES_PASSWORD and they will be automatically</span>
<span class="c1"># pulled in, or pass them in directly as kwargs.</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">ElasticsearchEmbeddings</span><span class="o">.</span><span class="n">from_credentials</span><span class="p">(</span>
    <span class="n">model_id</span><span class="p">,</span>
    <span class="n">input_field</span><span class="o">=</span><span class="n">input_field</span><span class="p">,</span>
    <span class="c1"># es_cloud_id=&quot;foo&quot;,</span>
    <span class="c1"># es_user=&quot;bar&quot;,</span>
    <span class="c1"># es_password=&quot;baz&quot;,</span>
<span class="p">)</span>

<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;This is an example document.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Another example document to generate embeddings for.&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">embeddings_generator</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.ElasticsearchEmbeddings.from_es_connection">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_es_connection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">es_connection</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_field</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text_field'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/elasticsearch.html#ElasticsearchEmbeddings.from_es_connection"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.ElasticsearchEmbeddings.from_es_connection" title="Permalink to this definition"></a></dt>
<dd><p>Instantiate embeddings from an existing Elasticsearch connection.</p>
<p>This method provides a way to create an instance of the ElasticsearchEmbeddings
class using an existing Elasticsearch connection. The connection object is used
to create an MlClient, which is then used to initialize the
ElasticsearchEmbeddings instance.</p>
<p>Args:
model_id (str): The model_id of the model deployed in the Elasticsearch cluster.
es_connection (elasticsearch.Elasticsearch): An existing Elasticsearch
connection object. input_field (str, optional): The name of the key for the
input text field in the document. Defaults to ‘text_field’.</p>
<p>Returns:
ElasticsearchEmbeddings: An instance of the ElasticsearchEmbeddings class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">elasticsearch</span> <span class="kn">import</span> <span class="n">Elasticsearch</span>

<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">ElasticsearchEmbeddings</span>

<span class="c1"># Define the model ID and input field name (if different from default)</span>
<span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;your_model_id&quot;</span>
<span class="c1"># Optional, only if different from &#39;text_field&#39;</span>
<span class="n">input_field</span> <span class="o">=</span> <span class="s2">&quot;your_input_field&quot;</span>

<span class="c1"># Create Elasticsearch connection</span>
<span class="n">es_connection</span> <span class="o">=</span> <span class="n">Elasticsearch</span><span class="p">(</span>
    <span class="n">hosts</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;localhost:9200&quot;</span><span class="p">],</span> <span class="n">http_auth</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;password&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Instantiate ElasticsearchEmbeddings using the existing connection</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">ElasticsearchEmbeddings</span><span class="o">.</span><span class="n">from_es_connection</span><span class="p">(</span>
    <span class="n">model_id</span><span class="p">,</span>
    <span class="n">es_connection</span><span class="p">,</span>
    <span class="n">input_field</span><span class="o">=</span><span class="n">input_field</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;This is an example document.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Another example document to generate embeddings for.&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">embeddings_generator</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) – </p></li>
<li><p><strong>es_connection</strong> (<em>Elasticsearch</em>) – </p></li>
<li><p><strong>input_field</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#langchain.embeddings.ElasticsearchEmbeddings" title="langchain.embeddings.ElasticsearchEmbeddings">ElasticsearchEmbeddings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.ElasticsearchEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/elasticsearch.html#ElasticsearchEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.ElasticsearchEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Generate embeddings for a list of documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – A list of document text strings to generate embeddings
for.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A list of embeddings, one for each document in the input</dt><dd><p>list.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.ElasticsearchEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/elasticsearch.html#ElasticsearchEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.ElasticsearchEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Generate an embedding for a single query text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The query text to generate an embedding for.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The embedding for the input query text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">LlamaCppEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_parts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f16_kv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_all</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mlock</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_threads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_gpu_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/llamacpp.html#LlamaCppEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around llama.cpp embedding models.</p>
<p>To use, you should have the llama-cpp-python library installed, and provide the
path to the Llama model as a named parameter to the constructor.
Check out: <a class="reference external" href="https://github.com/abetlen/llama-cpp-python">https://github.com/abetlen/llama-cpp-python</a></p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">LlamaCppEmbeddings</span>
<span class="n">llama</span> <span class="o">=</span> <span class="n">LlamaCppEmbeddings</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;/path/to/model.bin&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_path</strong> (<em>str</em>) – </p></li>
<li><p><strong>n_ctx</strong> (<em>int</em>) – </p></li>
<li><p><strong>n_parts</strong> (<em>int</em>) – </p></li>
<li><p><strong>seed</strong> (<em>int</em>) – </p></li>
<li><p><strong>f16_kv</strong> (<em>bool</em>) – </p></li>
<li><p><strong>logits_all</strong> (<em>bool</em>) – </p></li>
<li><p><strong>vocab_only</strong> (<em>bool</em>) – </p></li>
<li><p><strong>use_mlock</strong> (<em>bool</em>) – </p></li>
<li><p><strong>n_threads</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>n_batch</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>n_gpu_layers</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.f16_kv">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">f16_kv</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.f16_kv" title="Permalink to this definition"></a></dt>
<dd><p>Use half-precision for key/value cache.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.logits_all">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logits_all</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.logits_all" title="Permalink to this definition"></a></dt>
<dd><p>Return logits for all tokens, not just the last token.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.n_batch">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_batch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">8</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.n_batch" title="Permalink to this definition"></a></dt>
<dd><p>Number of tokens to process in parallel.
Should be a number between 1 and n_ctx.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.n_ctx">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_ctx</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">512</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.n_ctx" title="Permalink to this definition"></a></dt>
<dd><p>Token context window.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.n_gpu_layers">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_gpu_layers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.n_gpu_layers" title="Permalink to this definition"></a></dt>
<dd><p>Number of layers to be loaded into gpu memory. Default None.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.n_parts">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_parts</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">-1</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.n_parts" title="Permalink to this definition"></a></dt>
<dd><p>Number of parts to split the model into.
If -1, the number of parts is automatically determined.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.n_threads">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_threads</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.n_threads" title="Permalink to this definition"></a></dt>
<dd><p>Number of threads to use. If None, the number
of threads is automatically determined.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.seed">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">seed</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">-1</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.seed" title="Permalink to this definition"></a></dt>
<dd><p>Seed. If -1, a random seed is used.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.use_mlock">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">use_mlock</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.use_mlock" title="Permalink to this definition"></a></dt>
<dd><p>Force system to keep model in RAM.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.vocab_only">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">vocab_only</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.vocab_only" title="Permalink to this definition"></a></dt>
<dd><p>Only load the vocabulary, no weights.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/llamacpp.html#LlamaCppEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Embed a list of documents using the Llama model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.LlamaCppEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/llamacpp.html#LlamaCppEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.LlamaCppEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Embed a query using the Llama model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceHubEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">HuggingFaceHubEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repo_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sentence-transformers/all-mpnet-base-v2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'feature-extraction'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">huggingfacehub_api_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface_hub.html#HuggingFaceHubEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceHubEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around HuggingFaceHub embedding models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">huggingface_hub</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">HUGGINGFACEHUB_API_TOKEN</span></code> set with your API token, or pass
it as a named parameter to the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceHubEmbeddings</span>
<span class="n">repo_id</span> <span class="o">=</span> <span class="s2">&quot;sentence-transformers/all-mpnet-base-v2&quot;</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFaceHubEmbeddings</span><span class="p">(</span>
    <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="s2">&quot;feature-extraction&quot;</span><span class="p">,</span>
    <span class="n">huggingfacehub_api_token</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>repo_id</strong> (<em>str</em>) – </p></li>
<li><p><strong>task</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) – </p></li>
<li><p><strong>huggingfacehub_api_token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceHubEmbeddings.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceHubEmbeddings.model_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceHubEmbeddings.repo_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repo_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'sentence-transformers/all-mpnet-base-v2'</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceHubEmbeddings.repo_id" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceHubEmbeddings.task">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">task</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'feature-extraction'</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceHubEmbeddings.task" title="Permalink to this definition"></a></dt>
<dd><p>Task to call the model with.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceHubEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface_hub.html#HuggingFaceHubEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceHubEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Call out to HuggingFaceHub’s embedding endpoint for embedding search docs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceHubEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface_hub.html#HuggingFaceHubEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceHubEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Call out to HuggingFaceHub’s embedding endpoint for embedding query text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.ModelScopeEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">ModelScopeEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'damo/nlp_corom_sentence-embedding_english-base'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/modelscope_hub.html#ModelScopeEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.ModelScopeEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around modelscope_hub embedding models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">modelscope</span></code> python package installed.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">ModelScopeEmbeddings</span>
<span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;damo/nlp_corom_sentence-embedding_english-base&quot;</span>
<span class="n">embed</span> <span class="o">=</span> <span class="n">ModelScopeEmbeddings</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embed</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.ModelScopeEmbeddings.model_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'damo/nlp_corom_sentence-embedding_english-base'</span></em><a class="headerlink" href="#langchain.embeddings.ModelScopeEmbeddings.model_id" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.ModelScopeEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/modelscope_hub.html#ModelScopeEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.ModelScopeEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Compute doc embeddings using a modelscope embedding model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.ModelScopeEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/modelscope_hub.html#ModelScopeEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.ModelScopeEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Compute query embeddings using a modelscope embedding model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.TensorflowHubEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">TensorflowHubEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'https://tfhub.dev/google/universal-sentence-encoder-multilingual/3'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/tensorflow_hub.html#TensorflowHubEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.TensorflowHubEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around tensorflow_hub embedding models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">tensorflow_text</span></code> python package installed.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">TensorflowHubEmbeddings</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://tfhub.dev/google/universal-sentence-encoder-multilingual/3&quot;</span>
<span class="n">tf</span> <span class="o">=</span> <span class="n">TensorflowHubEmbeddings</span><span class="p">(</span><span class="n">model_url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embed</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_url</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.TensorflowHubEmbeddings.model_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'https://tfhub.dev/google/universal-sentence-encoder-multilingual/3'</span></em><a class="headerlink" href="#langchain.embeddings.TensorflowHubEmbeddings.model_url" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.TensorflowHubEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/tensorflow_hub.html#TensorflowHubEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.TensorflowHubEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Compute doc embeddings using a TensorflowHub embedding model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.TensorflowHubEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/tensorflow_hub.html#TensorflowHubEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.TensorflowHubEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Compute query embeddings using a TensorflowHub embedding model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">SagemakerEndpointEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">region_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">credentials_profile_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">content_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/sagemaker_endpoint.html#SagemakerEndpointEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around custom Sagemaker Inference Endpoints.</p>
<p>To use, you must supply the endpoint name from your deployed
Sagemaker model &amp; the region where it is deployed.</p>
<p>To authenticate, the AWS client uses the following methods to
automatically load credentials:
<a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html">https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</a></p>
<p>If a specific credential profile should be used, you must pass
the name of the profile from the ~/.aws/credentials file that is to be used.</p>
<p>Make sure the credentials / roles used have the required policies to
access the Sagemaker endpoint.
See: <a class="reference external" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>endpoint_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>region_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>credentials_profile_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>content_handler</strong> (<em>langchain.embeddings.sagemaker_endpoint.EmbeddingsContentHandler</em>) – </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – </p></li>
<li><p><strong>endpoint_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings.content_handler">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">content_handler</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">langchain.embeddings.sagemaker_endpoint.EmbeddingsContentHandler</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings.content_handler" title="Permalink to this definition"></a></dt>
<dd><p>The content handler class that provides an input and
output transform functions to handle formats between LLM
and the endpoint.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings.credentials_profile_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">credentials_profile_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings.credentials_profile_name" title="Permalink to this definition"></a></dt>
<dd><p>The name of the profile in the ~/.aws/credentials or ~/.aws/config files, which
has either access keys or role information specified.
If not specified, the default credential profile or, if on an EC2 instance,
credentials from IMDS will be used.
See: <a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html">https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</a></p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings.endpoint_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings.endpoint_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Optional attributes passed to the invoke_endpoint
function. See <a href="#id1"><span class="problematic" id="id2">`boto3`_</span></a>. docs for more info.
.. _boto3: &lt;<a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>&gt;</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings.endpoint_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings.endpoint_name" title="Permalink to this definition"></a></dt>
<dd><p>The name of the endpoint from the deployed Sagemaker model.
Must be unique within an AWS Region.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings.model_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings.region_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">region_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings.region_name" title="Permalink to this definition"></a></dt>
<dd><p>The aws region where the Sagemaker model is deployed, eg. <cite>us-west-2</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/sagemaker_endpoint.html#SagemakerEndpointEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Compute doc embeddings using a SageMaker Inference Endpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p></li>
<li><p><strong>chunk_size</strong> (<em>int</em>) – The chunk size defines how many input texts will
be grouped together as request. If None, will use the
chunk size specified by the class.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.SagemakerEndpointEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/sagemaker_endpoint.html#SagemakerEndpointEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SagemakerEndpointEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Compute query embeddings using a SageMaker inference endpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">HuggingFaceInstructEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'hkunlp/instructor-large'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encode_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_instruction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">document</span> <span class="pre">for</span> <span class="pre">retrieval:</span> <span class="pre">'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query_instruction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">question</span> <span class="pre">for</span> <span class="pre">retrieving</span> <span class="pre">supporting</span> <span class="pre">documents:</span> <span class="pre">'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface.html#HuggingFaceInstructEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around sentence_transformers embedding models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">sentence_transformers</span></code>
and <code class="docutils literal notranslate"><span class="pre">InstructorEmbedding</span></code> python packages installed.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceInstructEmbeddings</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;hkunlp/instructor-large&quot;</span>
<span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cpu&#39;</span><span class="p">}</span>
<span class="n">encode_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;normalize_embeddings&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFaceInstructEmbeddings</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">,</span>
    <span class="n">encode_kwargs</span><span class="o">=</span><span class="n">encode_kwargs</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>cache_folder</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
<li><p><strong>encode_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
<li><p><strong>embed_instruction</strong> (<em>str</em>) – </p></li>
<li><p><strong>query_instruction</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings.cache_folder">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache_folder</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings.cache_folder" title="Permalink to this definition"></a></dt>
<dd><p>Path to store models.
Can be also set by SENTENCE_TRANSFORMERS_HOME environment variable.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings.embed_instruction">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">embed_instruction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">document</span> <span class="pre">for</span> <span class="pre">retrieval:</span> <span class="pre">'</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings.embed_instruction" title="Permalink to this definition"></a></dt>
<dd><p>Instruction to use for embedding documents.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings.encode_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">encode_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings.encode_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Key word arguments to pass when calling the <cite>encode</cite> method of the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings.model_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hkunlp/instructor-large'</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings.model_name" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings.query_instruction">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">query_instruction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">question</span> <span class="pre">for</span> <span class="pre">retrieving</span> <span class="pre">supporting</span> <span class="pre">documents:</span> <span class="pre">'</span></em><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings.query_instruction" title="Permalink to this definition"></a></dt>
<dd><p>Instruction to use for embedding query.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface.html#HuggingFaceInstructEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Compute doc embeddings using a HuggingFace instruct model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.HuggingFaceInstructEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/huggingface.html#HuggingFaceInstructEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.HuggingFaceInstructEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Compute query embeddings using a HuggingFace instruct model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.MosaicMLInstructorEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">MosaicMLInstructorEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'https://models.hosted-on.mosaicml.hosting/instructor-large/v1/predict'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_instruction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">document</span> <span class="pre">for</span> <span class="pre">retrieval:</span> <span class="pre">'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query_instruction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">question</span> <span class="pre">for</span> <span class="pre">retrieving</span> <span class="pre">supporting</span> <span class="pre">documents:</span> <span class="pre">'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_sleep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mosaicml_api_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/mosaicml.html#MosaicMLInstructorEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.MosaicMLInstructorEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around MosaicML’s embedding inference service.</p>
<p>To use, you should have the
environment variable <code class="docutils literal notranslate"><span class="pre">MOSAICML_API_TOKEN</span></code> set with your API token, or pass
it as a named parameter to the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">MosaicMLInstructorEmbeddings</span>
<span class="n">endpoint_url</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;https://models.hosted-on.mosaicml.hosting/instructor-large/v1/predict&quot;</span>
<span class="p">)</span>
<span class="n">mosaic_llm</span> <span class="o">=</span> <span class="n">MosaicMLInstructorEmbeddings</span><span class="p">(</span>
    <span class="n">endpoint_url</span><span class="o">=</span><span class="n">endpoint_url</span><span class="p">,</span>
    <span class="n">mosaicml_api_token</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>endpoint_url</strong> (<em>str</em>) – </p></li>
<li><p><strong>embed_instruction</strong> (<em>str</em>) – </p></li>
<li><p><strong>query_instruction</strong> (<em>str</em>) – </p></li>
<li><p><strong>retry_sleep</strong> (<em>float</em>) – </p></li>
<li><p><strong>mosaicml_api_token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MosaicMLInstructorEmbeddings.embed_instruction">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">embed_instruction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">document</span> <span class="pre">for</span> <span class="pre">retrieval:</span> <span class="pre">'</span></em><a class="headerlink" href="#langchain.embeddings.MosaicMLInstructorEmbeddings.embed_instruction" title="Permalink to this definition"></a></dt>
<dd><p>Instruction used to embed documents.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MosaicMLInstructorEmbeddings.endpoint_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'https://models.hosted-on.mosaicml.hosting/instructor-large/v1/predict'</span></em><a class="headerlink" href="#langchain.embeddings.MosaicMLInstructorEmbeddings.endpoint_url" title="Permalink to this definition"></a></dt>
<dd><p>Endpoint URL to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MosaicMLInstructorEmbeddings.query_instruction">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">query_instruction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">question</span> <span class="pre">for</span> <span class="pre">retrieving</span> <span class="pre">supporting</span> <span class="pre">documents:</span> <span class="pre">'</span></em><a class="headerlink" href="#langchain.embeddings.MosaicMLInstructorEmbeddings.query_instruction" title="Permalink to this definition"></a></dt>
<dd><p>Instruction used to embed the query.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MosaicMLInstructorEmbeddings.retry_sleep">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">retry_sleep</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.0</span></em><a class="headerlink" href="#langchain.embeddings.MosaicMLInstructorEmbeddings.retry_sleep" title="Permalink to this definition"></a></dt>
<dd><p>How long to try sleeping for if a rate limit is encountered</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.MosaicMLInstructorEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/mosaicml.html#MosaicMLInstructorEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.MosaicMLInstructorEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Embed documents using a MosaicML deployed instructor embedding model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.MosaicMLInstructorEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/mosaicml.html#MosaicMLInstructorEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.MosaicMLInstructorEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Embed a query using a MosaicML deployed instructor embedding model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">SelfHostedEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*,</span> <span class="pre">cache=None,</span> <span class="pre">verbose=None,</span> <span class="pre">callbacks=None,</span> <span class="pre">callback_manager=None,</span> <span class="pre">pipeline_ref=None,</span> <span class="pre">client=None,</span> <span class="pre">inference_fn=&lt;function</span> <span class="pre">_embed_documents&gt;,</span> <span class="pre">hardware=None,</span> <span class="pre">model_load_fn,</span> <span class="pre">load_fn_kwargs=None,</span> <span class="pre">model_reqs=['./',</span> <span class="pre">'torch'],</span> <span class="pre">inference_kwargs=None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/self_hosted.html#SelfHostedEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SelfHostedEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="llms.html#langchain.llms.SelfHostedPipeline" title="langchain.llms.self_hosted.SelfHostedPipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.self_hosted.SelfHostedPipeline</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Runs custom embedding models on self-hosted remote hardware.</p>
<p>Supported hardware includes auto-launched instances on AWS, GCP, Azure,
and Lambda, as well as servers specified
by IP address and SSH credentials (such as on-prem, or another
cloud like Paperspace, Coreweave, etc.).</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">runhouse</span></code> python package installed.</p>
<dl>
<dt>Example using a model load function:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">SelfHostedEmbeddings</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>

<span class="n">gpu</span> <span class="o">=</span> <span class="n">rh</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;rh-a10x&quot;</span><span class="p">,</span> <span class="n">instance_type</span><span class="o">=</span><span class="s2">&quot;A100:1&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_pipeline</span><span class="p">():</span>
    <span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;facebook/bart-large&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;feature-extraction&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">SelfHostedEmbeddings</span><span class="p">(</span>
    <span class="n">model_load_fn</span><span class="o">=</span><span class="n">get_pipeline</span><span class="p">,</span>
    <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span>
    <span class="n">model_reqs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="s2">&quot;transformers&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>Example passing in a pipeline path:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">SelfHostedHFEmbeddings</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">gpu</span> <span class="o">=</span> <span class="n">rh</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;rh-a10x&quot;</span><span class="p">,</span> <span class="n">instance_type</span><span class="o">=</span><span class="s2">&quot;A100:1&quot;</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;feature-extraction&quot;</span><span class="p">)</span>
<span class="n">rh</span><span class="o">.</span><span class="n">blob</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">pipeline</span><span class="p">),</span>
    <span class="n">path</span><span class="o">=</span><span class="s2">&quot;models/pipeline.pkl&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">SelfHostedHFEmbeddings</span><span class="o">.</span><span class="n">from_pipeline</span><span class="p">(</span>
    <span class="n">pipeline</span><span class="o">=</span><span class="s2">&quot;models/pipeline.pkl&quot;</span><span class="p">,</span>
    <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
    <span class="n">model_reqs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="s2">&quot;transformers&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) – </p></li>
<li><p><strong>pipeline_ref</strong> (<em>Any</em>) – </p></li>
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>inference_fn</strong> (<em>Callable</em>) – </p></li>
<li><p><strong>hardware</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_load_fn</strong> (<em>Callable</em>) – </p></li>
<li><p><strong>load_fn_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) – </p></li>
<li><p><strong>model_reqs</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>inference_kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedEmbeddings.inference_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inference_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;function</span> <span class="pre">_embed_documents&gt;</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedEmbeddings.inference_fn" title="Permalink to this definition"></a></dt>
<dd><p>Inference function to extract the embeddings on the remote hardware.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedEmbeddings.inference_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inference_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedEmbeddings.inference_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Any kwargs to pass to the model’s inference function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/self_hosted.html#SelfHostedEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SelfHostedEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Compute doc embeddings using a HuggingFace transformer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.s</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/self_hosted.html#SelfHostedEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SelfHostedEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Compute query embeddings using a HuggingFace transformer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">SelfHostedHuggingFaceEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*,</span> <span class="pre">cache=None,</span> <span class="pre">verbose=None,</span> <span class="pre">callbacks=None,</span> <span class="pre">callback_manager=None,</span> <span class="pre">pipeline_ref=None,</span> <span class="pre">client=None,</span> <span class="pre">inference_fn=&lt;function</span> <span class="pre">_embed_documents&gt;,</span> <span class="pre">hardware=None,</span> <span class="pre">model_load_fn=&lt;function</span> <span class="pre">load_embedding_model&gt;,</span> <span class="pre">load_fn_kwargs=None,</span> <span class="pre">model_reqs=['./',</span> <span class="pre">'sentence_transformers',</span> <span class="pre">'torch'],</span> <span class="pre">inference_kwargs=None,</span> <span class="pre">model_id='sentence-transformers/all-mpnet-base-v2'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/self_hosted_hugging_face.html#SelfHostedHuggingFaceEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#langchain.embeddings.SelfHostedEmbeddings" title="langchain.embeddings.self_hosted.SelfHostedEmbeddings"><code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.self_hosted.SelfHostedEmbeddings</span></code></a></p>
<p>Runs sentence_transformers embedding models on self-hosted remote hardware.</p>
<p>Supported hardware includes auto-launched instances on AWS, GCP, Azure,
and Lambda, as well as servers specified
by IP address and SSH credentials (such as on-prem, or another cloud
like Paperspace, Coreweave, etc.).</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">runhouse</span></code> python package installed.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">SelfHostedHuggingFaceEmbeddings</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;sentence-transformers/all-mpnet-base-v2&quot;</span>
<span class="n">gpu</span> <span class="o">=</span> <span class="n">rh</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;rh-a10x&quot;</span><span class="p">,</span> <span class="n">instance_type</span><span class="o">=</span><span class="s2">&quot;A100:1&quot;</span><span class="p">)</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">SelfHostedHuggingFaceEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) – </p></li>
<li><p><strong>pipeline_ref</strong> (<em>Any</em>) – </p></li>
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>inference_fn</strong> (<em>Callable</em>) – </p></li>
<li><p><strong>hardware</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_load_fn</strong> (<em>Callable</em>) – </p></li>
<li><p><strong>load_fn_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) – </p></li>
<li><p><strong>model_reqs</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>inference_kwargs</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceEmbeddings.hardware">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hardware</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceEmbeddings.hardware" title="Permalink to this definition"></a></dt>
<dd><p>Remote hardware to send the inference function to.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceEmbeddings.inference_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inference_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;function</span> <span class="pre">_embed_documents&gt;</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceEmbeddings.inference_fn" title="Permalink to this definition"></a></dt>
<dd><p>Inference function to extract the embeddings.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceEmbeddings.load_fn_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_fn_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceEmbeddings.load_fn_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Key word arguments to pass to the model load function.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceEmbeddings.model_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'sentence-transformers/all-mpnet-base-v2'</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceEmbeddings.model_id" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceEmbeddings.model_load_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_load_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;function</span> <span class="pre">load_embedding_model&gt;</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceEmbeddings.model_load_fn" title="Permalink to this definition"></a></dt>
<dd><p>Function to load the model remotely on the server.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceEmbeddings.model_reqs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_reqs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['./',</span> <span class="pre">'sentence_transformers',</span> <span class="pre">'torch']</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceEmbeddings.model_reqs" title="Permalink to this definition"></a></dt>
<dd><p>Requirements to install on hardware to inference the model.</p>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">SelfHostedHuggingFaceInstructEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*,</span> <span class="pre">cache=None,</span> <span class="pre">verbose=None,</span> <span class="pre">callbacks=None,</span> <span class="pre">callback_manager=None,</span> <span class="pre">pipeline_ref=None,</span> <span class="pre">client=None,</span> <span class="pre">inference_fn=&lt;function</span> <span class="pre">_embed_documents&gt;,</span> <span class="pre">hardware=None,</span> <span class="pre">model_load_fn=&lt;function</span> <span class="pre">load_embedding_model&gt;,</span> <span class="pre">load_fn_kwargs=None,</span> <span class="pre">model_reqs=['./',</span> <span class="pre">'InstructorEmbedding',</span> <span class="pre">'torch'],</span> <span class="pre">inference_kwargs=None,</span> <span class="pre">model_id='hkunlp/instructor-large',</span> <span class="pre">embed_instruction='Represent</span> <span class="pre">the</span> <span class="pre">document</span> <span class="pre">for</span> <span class="pre">retrieval:</span> <span class="pre">',</span> <span class="pre">query_instruction='Represent</span> <span class="pre">the</span> <span class="pre">question</span> <span class="pre">for</span> <span class="pre">retrieving</span> <span class="pre">supporting</span> <span class="pre">documents:</span> <span class="pre">'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/self_hosted_hugging_face.html#SelfHostedHuggingFaceInstructEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#langchain.embeddings.SelfHostedHuggingFaceEmbeddings" title="langchain.embeddings.self_hosted_hugging_face.SelfHostedHuggingFaceEmbeddings"><code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.self_hosted_hugging_face.SelfHostedHuggingFaceEmbeddings</span></code></a></p>
<p>Runs InstructorEmbedding embedding models on self-hosted remote hardware.</p>
<p>Supported hardware includes auto-launched instances on AWS, GCP, Azure,
and Lambda, as well as servers specified
by IP address and SSH credentials (such as on-prem, or another
cloud like Paperspace, Coreweave, etc.).</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">runhouse</span></code> python package installed.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">SelfHostedHuggingFaceInstructEmbeddings</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;hkunlp/instructor-large&quot;</span>
<span class="n">gpu</span> <span class="o">=</span> <span class="n">rh</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;rh-a10x&#39;</span><span class="p">,</span> <span class="n">instance_type</span><span class="o">=</span><span class="s1">&#39;A100:1&#39;</span><span class="p">)</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">SelfHostedHuggingFaceInstructEmbeddings</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) – </p></li>
<li><p><strong>pipeline_ref</strong> (<em>Any</em>) – </p></li>
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>inference_fn</strong> (<em>Callable</em>) – </p></li>
<li><p><strong>hardware</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_load_fn</strong> (<em>Callable</em>) – </p></li>
<li><p><strong>load_fn_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) – </p></li>
<li><p><strong>model_reqs</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>inference_kwargs</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – </p></li>
<li><p><strong>embed_instruction</strong> (<em>str</em>) – </p></li>
<li><p><strong>query_instruction</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.embed_instruction">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">embed_instruction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">document</span> <span class="pre">for</span> <span class="pre">retrieval:</span> <span class="pre">'</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.embed_instruction" title="Permalink to this definition"></a></dt>
<dd><p>Instruction to use for embedding documents.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.model_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hkunlp/instructor-large'</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.model_id" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.model_reqs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_reqs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['./',</span> <span class="pre">'InstructorEmbedding',</span> <span class="pre">'torch']</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.model_reqs" title="Permalink to this definition"></a></dt>
<dd><p>Requirements to install on hardware to inference the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.query_instruction">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">query_instruction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Represent</span> <span class="pre">the</span> <span class="pre">question</span> <span class="pre">for</span> <span class="pre">retrieving</span> <span class="pre">supporting</span> <span class="pre">documents:</span> <span class="pre">'</span></em><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.query_instruction" title="Permalink to this definition"></a></dt>
<dd><p>Instruction to use for embedding query.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/self_hosted_hugging_face.html#SelfHostedHuggingFaceInstructEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Compute doc embeddings using a HuggingFace instruct model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/self_hosted_hugging_face.html#SelfHostedHuggingFaceInstructEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.SelfHostedHuggingFaceInstructEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Compute query embeddings using a HuggingFace instruct model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.FakeEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">FakeEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/fake.html#FakeEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.FakeEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>size</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.FakeEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/fake.html#FakeEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.FakeEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Embed search docs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.FakeEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/fake.html#FakeEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.FakeEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Embed query text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">AlephAlphaAsymmetricSemanticEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'luminous-base'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hosting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'https://api.aleph-alpha.com'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compress_to_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contextual_control_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">control_log_additive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aleph_alpha_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/aleph_alpha.html#AlephAlphaAsymmetricSemanticEmbedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper for Aleph Alpha’s Asymmetric Embeddings
AA provides you with an endpoint to embed a document and a query.
The models were optimized to make the embeddings of documents and
the query for a document as similar as possible.
To learn more, check out: <a class="reference external" href="https://docs.aleph-alpha.com/docs/tasks/semantic_embed/">https://docs.aleph-alpha.com/docs/tasks/semantic_embed/</a></p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aleph_alpha</span> <span class="kn">import</span> <span class="n">AlephAlphaAsymmetricSemanticEmbedding</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">AlephAlphaSymmetricSemanticEmbedding</span><span class="p">()</span>

<span class="n">document</span> <span class="o">=</span> <span class="s2">&quot;This is a content of the document&quot;</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;What is the content of the document?&quot;</span>

<span class="n">doc_result</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">document</span><span class="p">])</span>
<span class="n">query_result</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>hosting</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>normalize</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – </p></li>
<li><p><strong>compress_to_size</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>contextual_control_threshold</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>control_log_additive</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – </p></li>
<li><p><strong>aleph_alpha_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.aleph_alpha_api_key">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aleph_alpha_api_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.aleph_alpha_api_key" title="Permalink to this definition"></a></dt>
<dd><p>API key for Aleph Alpha API.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.compress_to_size">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compress_to_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">128</span></em><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.compress_to_size" title="Permalink to this definition"></a></dt>
<dd><p>Should the returned embeddings come back as an original 5120-dim vector,
or should it be compressed to 128-dim.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.contextual_control_threshold">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">contextual_control_threshold</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.contextual_control_threshold" title="Permalink to this definition"></a></dt>
<dd><p>Attention control parameters only apply to those tokens that have
explicitly been set in the request.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.control_log_additive">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">control_log_additive</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.control_log_additive" title="Permalink to this definition"></a></dt>
<dd><p>Apply controls on prompt items by adding the log(control_factor)
to attention scores.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.hosting">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hosting</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'https://api.aleph-alpha.com'</span></em><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.hosting" title="Permalink to this definition"></a></dt>
<dd><p>Optional parameter that specifies which datacenters may process the request.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'luminous-base'</span></em><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.model" title="Permalink to this definition"></a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.normalize">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">normalize</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.normalize" title="Permalink to this definition"></a></dt>
<dd><p>Should returned embeddings be normalized</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/aleph_alpha.html#AlephAlphaAsymmetricSemanticEmbedding.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Call out to Aleph Alpha’s asymmetric Document endpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/aleph_alpha.html#AlephAlphaAsymmetricSemanticEmbedding.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Call out to Aleph Alpha’s asymmetric, query embedding endpoint
:param text: The text to embed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Embeddings for the text.</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>text</strong> (<em>str</em>) – </p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaSymmetricSemanticEmbedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">AlephAlphaSymmetricSemanticEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'luminous-base'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hosting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'https://api.aleph-alpha.com'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compress_to_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contextual_control_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">control_log_additive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aleph_alpha_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/aleph_alpha.html#AlephAlphaSymmetricSemanticEmbedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.AlephAlphaSymmetricSemanticEmbedding" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#langchain.embeddings.AlephAlphaAsymmetricSemanticEmbedding" title="langchain.embeddings.aleph_alpha.AlephAlphaAsymmetricSemanticEmbedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.aleph_alpha.AlephAlphaAsymmetricSemanticEmbedding</span></code></a></p>
<p>The symmetric version of the Aleph Alpha’s semantic embeddings.</p>
<p>The main difference is that here, both the documents and
queries are embedded with a SemanticRepresentation.Symmetric
.. rubric:: Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aleph_alpha</span> <span class="kn">import</span> <span class="n">AlephAlphaSymmetricSemanticEmbedding</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">AlephAlphaAsymmetricSemanticEmbedding</span><span class="p">()</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;This is a test text&quot;</span>

<span class="n">doc_result</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
<span class="n">query_result</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>hosting</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>normalize</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – </p></li>
<li><p><strong>compress_to_size</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>contextual_control_threshold</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>control_log_additive</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – </p></li>
<li><p><strong>aleph_alpha_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaSymmetricSemanticEmbedding.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/aleph_alpha.html#AlephAlphaSymmetricSemanticEmbedding.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.AlephAlphaSymmetricSemanticEmbedding.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Call out to Aleph Alpha’s Document endpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.AlephAlphaSymmetricSemanticEmbedding.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/aleph_alpha.html#AlephAlphaSymmetricSemanticEmbedding.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.AlephAlphaSymmetricSemanticEmbedding.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Call out to Aleph Alpha’s asymmetric, query embedding endpoint
:param text: The text to embed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Embeddings for the text.</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>text</strong> (<em>str</em>) – </p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="langchain.embeddings.SentenceTransformerEmbeddings">
<span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">SentenceTransformerEmbeddings</span></span><a class="headerlink" href="#langchain.embeddings.SentenceTransformerEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>alias of <a class="reference internal" href="#langchain.embeddings.HuggingFaceEmbeddings" title="langchain.embeddings.huggingface.HuggingFaceEmbeddings"><code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.huggingface.HuggingFaceEmbeddings</span></code></a></p>
</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">MiniMaxEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'https://api.minimax.chat/v1/embeddings'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'embo-01'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_type_db</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'db'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_type_query</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'query'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimax_group_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimax_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/minimax.html#MiniMaxEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Wrapper around MiniMax’s embedding inference service.</p>
<p>To use, you should have the environment variable <code class="docutils literal notranslate"><span class="pre">MINIMAX_GROUP_ID</span></code> and
<code class="docutils literal notranslate"><span class="pre">MINIMAX_API_KEY</span></code> set with your API token, or pass it as a named parameter to
the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">MiniMaxEmbeddings</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">MiniMaxEmbeddings</span><span class="p">()</span>

<span class="n">query_text</span> <span class="o">=</span> <span class="s2">&quot;This is a test query.&quot;</span>
<span class="n">query_result</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">query_text</span><span class="p">)</span>

<span class="n">document_text</span> <span class="o">=</span> <span class="s2">&quot;This is a test document.&quot;</span>
<span class="n">document_result</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">document_text</span><span class="p">])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>endpoint_url</strong> (<em>str</em>) – </p></li>
<li><p><strong>model</strong> (<em>str</em>) – </p></li>
<li><p><strong>embed_type_db</strong> (<em>str</em>) – </p></li>
<li><p><strong>embed_type_query</strong> (<em>str</em>) – </p></li>
<li><p><strong>minimax_group_id</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>minimax_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings.embed_type_db">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">embed_type_db</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'db'</span></em><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings.embed_type_db" title="Permalink to this definition"></a></dt>
<dd><p>For embed_documents</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings.embed_type_query">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">embed_type_query</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'query'</span></em><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings.embed_type_query" title="Permalink to this definition"></a></dt>
<dd><p>For embed_query</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings.endpoint_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'https://api.minimax.chat/v1/embeddings'</span></em><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings.endpoint_url" title="Permalink to this definition"></a></dt>
<dd><p>Endpoint URL to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings.minimax_api_key">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">minimax_api_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings.minimax_api_key" title="Permalink to this definition"></a></dt>
<dd><p>API Key for MiniMax API.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings.minimax_group_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">minimax_group_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings.minimax_group_id" title="Permalink to this definition"></a></dt>
<dd><p>Group ID for MiniMax API.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'embo-01'</span></em><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings.model" title="Permalink to this definition"></a></dt>
<dd><p>Embeddings model name to use.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/minimax.html#MiniMaxEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Embed documents using a MiniMax embedding endpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.MiniMaxEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/minimax.html#MiniMaxEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.MiniMaxEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Embed a query using a MiniMax embedding endpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.embeddings.BedrockEmbeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.embeddings.</span></span><span class="sig-name descname"><span class="pre">BedrockEmbeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">region_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">credentials_profile_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'amazon.titan-e1t-medium'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/bedrock.html#BedrockEmbeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.BedrockEmbeddings" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.embeddings.base.Embeddings</span></code></p>
<p>Embeddings provider to invoke Bedrock embedding models.</p>
<p>To authenticate, the AWS client uses the following methods to
automatically load credentials:
<a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html">https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</a></p>
<p>If a specific credential profile should be used, you must pass
the name of the profile from the ~/.aws/credentials file that is to be used.</p>
<p>Make sure the credentials / roles used have the required policies to
access the Bedrock service.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) – </p></li>
<li><p><strong>region_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>credentials_profile_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.BedrockEmbeddings.credentials_profile_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">credentials_profile_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.BedrockEmbeddings.credentials_profile_name" title="Permalink to this definition"></a></dt>
<dd><p>The name of the profile in the ~/.aws/credentials or ~/.aws/config files, which
has either access keys or role information specified.
If not specified, the default credential profile or, if on an EC2 instance,
credentials from IMDS will be used.
See: <a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html">https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</a></p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.BedrockEmbeddings.model_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'amazon.titan-e1t-medium'</span></em><a class="headerlink" href="#langchain.embeddings.BedrockEmbeddings.model_id" title="Permalink to this definition"></a></dt>
<dd><p>Id of the model to call, e.g., amazon.titan-e1t-medium, this is
equivalent to the modelId property in the list-foundation-models api</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.BedrockEmbeddings.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.BedrockEmbeddings.model_kwargs" title="Permalink to this definition"></a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.embeddings.BedrockEmbeddings.region_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">region_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.embeddings.BedrockEmbeddings.region_name" title="Permalink to this definition"></a></dt>
<dd><p>The aws region e.g., <cite>us-west-2</cite>. Fallsback to AWS_DEFAULT_REGION env variable
or region specified in ~/.aws/config in case it is not provided here.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.BedrockEmbeddings.embed_documents">
<span class="sig-name descname"><span class="pre">embed_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/bedrock.html#BedrockEmbeddings.embed_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.BedrockEmbeddings.embed_documents" title="Permalink to this definition"></a></dt>
<dd><p>Compute doc embeddings using a Bedrock model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>texts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of texts to embed.</p></li>
<li><p><strong>chunk_size</strong> (<em>int</em>) – Bedrock currently only allows single string
inputs, so chunk size is always 1. This input is here
only for compatibility with the embeddings interface.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of embeddings, one for each text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[<em>List</em>[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.embeddings.BedrockEmbeddings.embed_query">
<span class="sig-name descname"><span class="pre">embed_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/embeddings/bedrock.html#BedrockEmbeddings.embed_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.embeddings.BedrockEmbeddings.embed_query" title="Permalink to this definition"></a></dt>
<dd><p>Compute query embeddings using a Bedrock model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embeddings for the text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="document_transformers.html" class="btn btn-neutral float-left" title="Document Transformers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="vectorstores.html" class="btn btn-neutral float-right" title="Vector Stores" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Harrison Chase.
      <span class="lastupdated">Last updated on Jun 14, 2023.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>