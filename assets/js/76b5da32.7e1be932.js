"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[98681],{3905:(e,n,t)=>{t.d(n,{Zo:()=>h,kt:()=>d});var o=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=o.createContext({}),c=function(e){var n=o.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},h=function(e){var n=c(e.components);return o.createElement(l.Provider,{value:n},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},p=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,h=s(e,["components","mdxType","originalType","parentName"]),m=c(t),p=a,d=m["".concat(l,".").concat(p)]||m[p]||u[p]||r;return t?o.createElement(d,i(i({ref:n},h),{},{components:t})):o.createElement(d,i({ref:n},h))}));function d(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,i=new Array(r);i[0]=p;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[m]="string"==typeof e?e:a,i[1]=s;for(var c=2;c<r;c++)i[c]=t[c];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}p.displayName="MDXCreateElement"},99218:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var o=t(87462),a=(t(67294),t(3905));const r={},i="How to customize conversational memory",s={unversionedId:"modules/memory/how_to/conversational_customization",id:"modules/memory/how_to/conversational_customization",title:"How to customize conversational memory",description:"This notebook walks through a few ways to customize conversational memory.",source:"@site/docs/modules/memory/how_to/conversational_customization.md",sourceDirName:"modules/memory/how_to",slug:"/modules/memory/how_to/conversational_customization",permalink:"/langchain-docs-scratch/docs/modules/memory/how_to/conversational_customization",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/memory/how_to/conversational_customization.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Conversation buffer window memory",permalink:"/langchain-docs-scratch/docs/modules/memory/how_to/buffer_window"},next:{title:"How to create a custom Memory class",permalink:"/langchain-docs-scratch/docs/modules/memory/how_to/custom_memory"}},l={},c=[{value:"AI Prefix",id:"ai-prefix",level:2},{value:"Human Prefix",id:"human-prefix",level:2}],h=(m="CodeOutputBlock",function(e){return console.warn("Component "+m+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var m;const u={toc:c},p="wrapper";function d(e){let{components:n,...t}=e;return(0,a.kt)(p,(0,o.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"how-to-customize-conversational-memory"},"How to customize conversational memory"),(0,a.kt)("p",null,"This notebook walks through a few ways to customize conversational memory."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.llms import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationBufferMemory\n\n\nllm = OpenAI(temperature=0)\n")),(0,a.kt)("h2",{id:"ai-prefix"},"AI Prefix"),(0,a.kt)("p",null,'The first way to do so is by changing the AI prefix in the conversation summary. By default, this is set to "AI", but you can set this to be anything you want. Note that if you change this, you should also change the prompt used in the chain to reflect this naming change. Let\'s walk through an example of that in the example below.'),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# Here it is by default set to "AI"\nconversation = ConversationChain(\n    llm=llm, \n    verbose=True, \n    memory=ConversationBufferMemory()\n)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="Hi there!")\n')),(0,a.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    \n    Human: Hi there!\n    AI:\n    \n    > Finished ConversationChain chain.\n\n\n\n\n\n    " Hi there! It\'s nice to meet you. How can I help you today?"\n'))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="What\'s the weather?")\n')),(0,a.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    \n    Human: Hi there!\n    AI:  Hi there! It's nice to meet you. How can I help you today?\n    Human: What's the weather?\n    AI:\n    \n    > Finished ConversationChain chain.\n\n\n\n\n\n    ' The current weather is sunny and warm with a temperature of 75 degrees Fahrenheit. The forecast for the next few days is sunny with temperatures in the mid-70s.'\n"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# Now we can override it and set it to "AI Assistant"\nfrom langchain.prompts.prompt import PromptTemplate\n\ntemplate = """The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI Assistant:"""\nPROMPT = PromptTemplate(\n    input_variables=["history", "input"], template=template\n)\nconversation = ConversationChain(\n    prompt=PROMPT,\n    llm=llm, \n    verbose=True, \n    memory=ConversationBufferMemory(ai_prefix="AI Assistant")\n)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="Hi there!")\n')),(0,a.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    \n    Human: Hi there!\n    AI Assistant:\n    \n    > Finished ConversationChain chain.\n\n\n\n\n\n    " Hi there! It\'s nice to meet you. How can I help you today?"\n'))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="What\'s the weather?")\n')),(0,a.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    \n    Human: Hi there!\n    AI Assistant:  Hi there! It's nice to meet you. How can I help you today?\n    Human: What's the weather?\n    AI Assistant:\n    \n    > Finished ConversationChain chain.\n\n\n\n\n\n    ' The current weather is sunny and warm with a temperature of 75 degrees Fahrenheit. The forecast for the rest of the day is sunny with a high of 78 degrees and a low of 65 degrees.'\n"))),(0,a.kt)("h2",{id:"human-prefix"},"Human Prefix"),(0,a.kt)("p",null,'The next way to do so is by changing the Human prefix in the conversation summary. By default, this is set to "Human", but you can set this to be anything you want. Note that if you change this, you should also change the prompt used in the chain to reflect this naming change. Let\'s walk through an example of that in the example below.'),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# Now we can override it and set it to "Friend"\nfrom langchain.prompts.prompt import PromptTemplate\n\ntemplate = """The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nFriend: {input}\nAI:"""\nPROMPT = PromptTemplate(\n    input_variables=["history", "input"], template=template\n)\nconversation = ConversationChain(\n    prompt=PROMPT,\n    llm=llm, \n    verbose=True, \n    memory=ConversationBufferMemory(human_prefix="Friend")\n)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="Hi there!")\n')),(0,a.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    \n    Friend: Hi there!\n    AI:\n    \n    > Finished ConversationChain chain.\n\n\n\n\n\n    " Hi there! It\'s nice to meet you. How can I help you today?"\n'))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="What\'s the weather?")\n')),(0,a.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    \n    Friend: Hi there!\n    AI:  Hi there! It's nice to meet you. How can I help you today?\n    Friend: What's the weather?\n    AI:\n    \n    > Finished ConversationChain chain.\n\n\n\n\n\n    ' The weather right now is sunny and warm with a temperature of 75 degrees Fahrenheit. The forecast for the rest of the day is mostly sunny with a high of 82 degrees.'\n"))))}d.isMDXComponent=!0}}]);