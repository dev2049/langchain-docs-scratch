"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[26358],{3905:(e,n,t)=>{t.d(n,{Zo:()=>u,kt:()=>y});var o=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function p(e,n){if(null==e)return{};var t,o,r=function(e,n){if(null==e)return{};var t,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var i=o.createContext({}),s=function(e){var n=o.useContext(i),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},u=function(e){var n=s(e.components);return o.createElement(i.Provider,{value:n},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},d=o.forwardRef((function(e,n){var t=e.components,r=e.mdxType,a=e.originalType,i=e.parentName,u=p(e,["components","mdxType","originalType","parentName"]),c=s(t),d=r,y=c["".concat(i,".").concat(d)]||c[d]||m[d]||a;return t?o.createElement(y,l(l({ref:n},u),{},{components:t})):o.createElement(y,l({ref:n},u))}));function y(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=t.length,l=new Array(a);l[0]=d;var p={};for(var i in n)hasOwnProperty.call(n,i)&&(p[i]=n[i]);p.originalType=e,p[c]="string"==typeof e?e:r,l[1]=p;for(var s=2;s<a;s++)l[s]=t[s];return o.createElement.apply(null,l)}return o.createElement.apply(null,t)}d.displayName="MDXCreateElement"},24009:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>y,frontMatter:()=>a,metadata:()=>p,toc:()=>s});var o=t(87462),r=(t(67294),t(3905));const a={},l="Azure OpenAI",p={unversionedId:"modules/model_io/models/llms/integrations/azure_openai_example",id:"modules/model_io/models/llms/integrations/azure_openai_example",title:"Azure OpenAI",description:"This notebook goes over how to use Langchain with Azure OpenAI.",source:"@site/docs/modules/model_io/models/llms/integrations/azure_openai_example.md",sourceDirName:"modules/model_io/models/llms/integrations",slug:"/modules/model_io/models/llms/integrations/azure_openai_example",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/azure_openai_example",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/models/llms/integrations/azure_openai_example.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Anyscale",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/anyscale"},next:{title:"Banana",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/banana"}},i={},s=[{value:"API configuration",id:"api-configuration",level:2},{value:"Deployments",id:"deployments",level:2}],u=(c="CodeOutputBlock",function(e){return console.warn("Component "+c+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var c;const m={toc:s},d="wrapper";function y(e){let{components:n,...t}=e;return(0,r.kt)(d,(0,o.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"azure-openai"},"Azure OpenAI"),(0,r.kt)("p",null,"This notebook goes over how to use Langchain with ",(0,r.kt)("a",{parentName:"p",href:"https://aka.ms/azure-openai"},"Azure OpenAI"),"."),(0,r.kt)("p",null,"The Azure OpenAI API is compatible with OpenAI's API.  The ",(0,r.kt)("inlineCode",{parentName:"p"},"openai")," Python package makes it easy to use both OpenAI and Azure OpenAI.  You can call Azure OpenAI the same way you call OpenAI with the exceptions noted below."),(0,r.kt)("h2",{id:"api-configuration"},"API configuration"),(0,r.kt)("p",null,"You can configure the ",(0,r.kt)("inlineCode",{parentName:"p"},"openai")," package to use Azure OpenAI using environment variables.  The following is for ",(0,r.kt)("inlineCode",{parentName:"p"},"bash"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# Set this to `azure`\nexport OPENAI_API_TYPE=azure\n# The API version you want to use: set this to `2023-03-15-preview` for the released version.\nexport OPENAI_API_VERSION=2023-03-15-preview\n# The base URL for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\nexport OPENAI_API_BASE=https://your-resource-name.openai.azure.com\n# The API key for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\nexport OPENAI_API_KEY=<your Azure OpenAI API key>\n")),(0,r.kt)("p",null,"Alternatively, you can configure the API right within your running Python environment:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import os\nos.environ["OPENAI_API_TYPE"] = "azure"\n...\n')),(0,r.kt)("h2",{id:"deployments"},"Deployments"),(0,r.kt)("p",null,"With Azure OpenAI, you set up your own deployments of the common GPT-3 and Codex models.  When calling the API, you need to specify the deployment you want to use."),(0,r.kt)("p",null,"Let's say your deployment name is ",(0,r.kt)("inlineCode",{parentName:"p"},"text-davinci-002-prod"),".  In the ",(0,r.kt)("inlineCode",{parentName:"p"},"openai")," Python API, you can specify this deployment with the ",(0,r.kt)("inlineCode",{parentName:"p"},"engine")," parameter.  For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import openai\n\nresponse = openai.Completion.create(\n    engine="text-davinci-002-prod",\n    prompt="This is a test",\n    max_tokens=5\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install openai\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import os\nos.environ["OPENAI_API_TYPE"] = "azure"\nos.environ["OPENAI_API_VERSION"] = "2023-03-15-preview"\nos.environ["OPENAI_API_BASE"] = "..."\nos.environ["OPENAI_API_KEY"] = "..."\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Import Azure OpenAI\nfrom langchain.llms import AzureOpenAI\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Create an instance of Azure OpenAI\n# Replace the deployment name with your own\nllm = AzureOpenAI(\n    deployment_name="td2",\n    model_name="text-davinci-002", \n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Run the LLM\nllm("Tell me a joke")\n')),(0,r.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'    "\\n\\nWhy couldn\'t the bicycle stand up by itself? Because it was...two tired!"\n'))),(0,r.kt)("p",null,"We can also print the LLM and see its custom print."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"print(llm)\n")),(0,r.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    AzureOpenAI\n    Params: {'deployment_name': 'text-davinci-002', 'model_name': 'text-davinci-002', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'best_of': 1}\n"))))}y.isMDXComponent=!0}}]);