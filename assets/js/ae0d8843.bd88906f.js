"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[20411],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>m});var r=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=r.createContext({}),l=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=l(e.components);return r.createElement(c.Provider,{value:t},e.children)},u="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=l(n),d=o,m=u["".concat(c,".").concat(d)]||u[d]||g[d]||a;return n?r.createElement(m,i(i({ref:t},p),{},{components:n})):r.createElement(m,i({ref:t},p))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=d;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[u]="string"==typeof e?e:o,i[1]=s;for(var l=2;l<a;l++)i[l]=n[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},27960:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>m,frontMatter:()=>a,metadata:()=>s,toc:()=>l});var r=n(87462),o=(n(67294),n(3905));const a={},i="Split by tokens (Hugging Face tokenizer)",s={unversionedId:"modules/data_io/text_splitters/how_to/huggingface_length_function",id:"modules/data_io/text_splitters/how_to/huggingface_length_function",title:"Split by tokens (Hugging Face tokenizer)",description:"Hugging Face has many tokenizers.",source:"@site/docs/modules/data_io/text_splitters/how_to/huggingface_length_function.md",sourceDirName:"modules/data_io/text_splitters/how_to",slug:"/modules/data_io/text_splitters/how_to/huggingface_length_function",permalink:"/langchain-docs-scratch/docs/modules/data_io/text_splitters/how_to/huggingface_length_function",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/data_io/text_splitters/how_to/huggingface_length_function.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Split code",permalink:"/langchain-docs-scratch/docs/modules/data_io/text_splitters/how_to/code_splitter"},next:{title:"Split by tokens (NLTK)",permalink:"/langchain-docs-scratch/docs/modules/data_io/text_splitters/how_to/nltk"}},c={},l=[],p=(u="CodeOutputBlock",function(e){return console.warn("Component "+u+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var u;const g={toc:l},d="wrapper";function m(e){let{components:t,...n}=e;return(0,o.kt)(d,(0,r.Z)({},g,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"split-by-tokens-hugging-face-tokenizer"},"Split by tokens (Hugging Face tokenizer)"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/docs/tokenizers/index"},"Hugging Face")," has many tokenizers.")),(0,o.kt)("p",null,"We use Hugging Face tokenizer, the ",(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/Ransaka/gpt2-tokenizer-fast"},"GPT2TokenizerFast")," to count the text length in tokens."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"How the text is split: by character passed in"),(0,o.kt)("li",{parentName:"ol"},"How the chunk size is measured: by number of tokens calculated by the ",(0,o.kt)("inlineCode",{parentName:"li"},"Hugging Face")," tokenizer")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from transformers import GPT2TokenizerFast\n\ntokenizer = GPT2TokenizerFast.from_pretrained("gpt2")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"# This is a long document we can split up.\nwith open('../../../state_of_the_union.txt') as f:\n    state_of_the_union = f.read()\nfrom langchain.text_splitter import CharacterTextSplitter\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(tokenizer, chunk_size=100, chunk_overlap=0)\ntexts = text_splitter.split_text(state_of_the_union)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"print(texts[0])\n")),(0,o.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n    \n    Last year COVID-19 kept us apart. This year we are finally together again. \n    \n    Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n    \n    With a duty to one another to the American people to the Constitution.\n"))))}m.isMDXComponent=!0}}]);