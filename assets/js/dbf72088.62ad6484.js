"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[92359],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>g});var o=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function d(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?d(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):d(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},d=Object.keys(e);for(o=0;o<d.length;o++)n=d[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var d=Object.getOwnPropertySymbols(e);for(o=0;o<d.length;o++)n=d[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=o.createContext({}),l=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},m=function(e){var t=l(e.components);return o.createElement(s.Provider,{value:t},e.children)},c="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},u=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,d=e.originalType,s=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),c=l(n),u=r,g=c["".concat(s,".").concat(u)]||c[u]||p[u]||d;return n?o.createElement(g,a(a({ref:t},m),{},{components:n})):o.createElement(g,a({ref:t},m))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var d=n.length,a=new Array(d);a[0]=u;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[c]="string"==typeof e?e:r,a[1]=i;for(var l=2;l<d;l++)a[l]=n[l];return o.createElement.apply(null,a)}return o.createElement.apply(null,n)}u.displayName="MDXCreateElement"},61469:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>c,default:()=>f,frontMatter:()=>m,metadata:()=>p,toc:()=>g});var o=n(87462),r=(n(67294),n(3905));const d=(a="CodeOutputBlock",function(e){return console.warn("Component "+a+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var a;const i={toc:[]},s="wrapper";function l(e){let{components:t,...n}=e;return(0,r.kt)(s,(0,o.Z)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.embeddings import OpenAIEmbeddings\n\nembedding_model = OpenAIEmbeddings()\nembeddings = embedding_model.embed_documents(\n    [\n        "Hi there!",\n        "Oh, hello!",\n        "What\'s your name?",\n        "My friends call me World",\n        "Hello World!"\n    ]\n)\nlen(embeddings), len(embeddings[0])\n')),(0,r.kt)(d,{language:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"(5, 1536)\n"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'embedded_query = embedding_model.embed_query("What was the name mentioned in the conversation?")\nembedded_query[:5]\n')),(0,r.kt)(d,{language:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[0.0053587136790156364,\n -0.0004999046213924885,\n 0.038883671164512634,\n -0.003001077566295862,\n -0.00900818221271038]\n"))))}l.isMDXComponent=!0;const m={sidebar_position:2},c="Text embedding models",p={unversionedId:"modules/model_io/models/text_embedding/index",id:"modules/model_io/models/text_embedding/index",title:"Text embedding models",description:"The Embeddings class is a class designed for interfacing with text embedding models. There are lots of embedding model providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them.",source:"@site/docs/modules/model_io/models/text_embedding/index.mdx",sourceDirName:"modules/model_io/models/text_embedding",slug:"/modules/model_io/models/text_embedding/",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/text_embedding/",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/models/text_embedding/index.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"sidebar",previous:{title:"PromptLayer ChatOpenAI",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/chat/integrations/promptlayer_chatopenai"},next:{title:"Aleph Alpha",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/text_embedding/integrations/aleph_alpha"}},u={},g=[{value:"Get started",id:"get-started",level:2}],h={toc:g},b="wrapper";function f(e){let{components:t,...n}=e;return(0,r.kt)(b,(0,o.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"text-embedding-models"},"Text embedding models"),(0,r.kt)("p",null,"The Embeddings class is a class designed for interfacing with text embedding models. There are lots of embedding model providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them."),(0,r.kt)("p",null,"Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space."),(0,r.kt)("p",null,"The base Embeddings class in LangChain exposes two methods: one for embedding documents and one for embedding a query. The former takes as input multiple texts, while the latter takes a single text. The reason for having these as two separate methods is that some embedding providers have different embedding methods for documents (to be searched over) vs queries (the search query itself)."),(0,r.kt)("h2",{id:"get-started"},"Get started"),(0,r.kt)(l,{mdxType:"GetStarted"}))}f.isMDXComponent=!0}}]);