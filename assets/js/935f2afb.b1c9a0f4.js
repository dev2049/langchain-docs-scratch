"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[80053],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"sidebar":[{"type":"category","label":"Get started","collapsed":false,"collapsible":false,"items":[{"type":"link","label":"Introduction","href":"/langchain-docs-scratch/docs/get_started/introduction","docId":"get_started/introduction"},{"type":"link","label":"Installation","href":"/langchain-docs-scratch/docs/get_started/installation","docId":"get_started/installation"},{"type":"link","label":"Quickstart","href":"/langchain-docs-scratch/docs/get_started/quickstart","docId":"get_started/quickstart"}],"href":"/langchain-docs-scratch/docs/get_started"},{"type":"category","label":"Modules","collapsed":false,"collapsible":false,"items":[{"type":"category","label":"Model I/\u200bO","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Prompts","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Prompt templates","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Connecting to a Feature Store","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store","docId":"modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store"},{"type":"link","label":"Custom prompt template","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/custom_prompt_template","docId":"modules/model_io/prompts/prompt_templates/custom_prompt_template"},{"type":"link","label":"Few-shot prompt templates","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/few_shot_examples","docId":"modules/model_io/prompts/prompt_templates/few_shot_examples"},{"type":"link","label":"Few shot examples for chat models","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/few_shot_examples_chat","docId":"modules/model_io/prompts/prompt_templates/few_shot_examples_chat"},{"type":"link","label":"Format template output","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/format_output","docId":"modules/model_io/prompts/prompt_templates/format_output"},{"type":"link","label":"Template formats","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/formats","docId":"modules/model_io/prompts/prompt_templates/formats"},{"type":"link","label":"Types of MessagePromptTemplate","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/msg_prompt_templates","docId":"modules/model_io/prompts/prompt_templates/msg_prompt_templates"},{"type":"link","label":"Partial prompt templates","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/partial","docId":"modules/model_io/prompts/prompt_templates/partial"},{"type":"link","label":"Composition","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/prompt_composition","docId":"modules/model_io/prompts/prompt_templates/prompt_composition"},{"type":"link","label":"Serialization","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/prompt_serialization","docId":"modules/model_io/prompts/prompt_templates/prompt_serialization"},{"type":"link","label":"Validate template","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/validate","docId":"modules/model_io/prompts/prompt_templates/validate"}],"href":"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/"},{"type":"category","label":"Example selectors","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Custom example selector","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/example_selectors/custom_example_selector","docId":"modules/model_io/prompts/example_selectors/custom_example_selector"},{"type":"link","label":"Select by length","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/example_selectors/length_based","docId":"modules/model_io/prompts/example_selectors/length_based"},{"type":"link","label":"Select by maximal marginal relevance (MMR)","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/example_selectors/mmr","docId":"modules/model_io/prompts/example_selectors/mmr"},{"type":"link","label":"Select by n-gram overlap","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/example_selectors/ngram_overlap","docId":"modules/model_io/prompts/example_selectors/ngram_overlap"},{"type":"link","label":"Select by similarity","href":"/langchain-docs-scratch/docs/modules/model_io/prompts/example_selectors/similarity","docId":"modules/model_io/prompts/example_selectors/similarity"}],"href":"/langchain-docs-scratch/docs/modules/model_io/prompts/example_selectors/"}],"href":"/langchain-docs-scratch/docs/modules/model_io/prompts/"},{"type":"category","label":"Language models","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"LLMs","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Async API","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/how_to/async_llm","docId":"modules/model_io/models/llms/how_to/async_llm"},{"type":"link","label":"Custom LLM","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/how_to/custom_llm","docId":"modules/model_io/models/llms/how_to/custom_llm"},{"type":"link","label":"Fake LLM","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/how_to/fake_llm","docId":"modules/model_io/models/llms/how_to/fake_llm"},{"type":"link","label":"Human input LLM","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/how_to/human_input_llm","docId":"modules/model_io/models/llms/how_to/human_input_llm"},{"type":"link","label":"Caching","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/how_to/llm_caching","docId":"modules/model_io/models/llms/how_to/llm_caching"},{"type":"link","label":"Serialization","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/how_to/llm_serialization","docId":"modules/model_io/models/llms/how_to/llm_serialization"},{"type":"link","label":"Streaming","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/how_to/streaming_llm","docId":"modules/model_io/models/llms/how_to/streaming_llm"},{"type":"link","label":"Tracking token usage","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/how_to/token_usage_tracking","docId":"modules/model_io/models/llms/how_to/token_usage_tracking"}]},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AI21","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/ai21","docId":"modules/model_io/models/llms/integrations/ai21"},{"type":"link","label":"Aleph Alpha","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/aleph_alpha","docId":"modules/model_io/models/llms/integrations/aleph_alpha"},{"type":"link","label":"Anyscale","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/anyscale","docId":"modules/model_io/models/llms/integrations/anyscale"},{"type":"link","label":"Azure OpenAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/azure_openai_example","docId":"modules/model_io/models/llms/integrations/azure_openai_example"},{"type":"link","label":"Banana","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/banana","docId":"modules/model_io/models/llms/integrations/banana"},{"type":"link","label":"Beam","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/beam","docId":"modules/model_io/models/llms/integrations/beam"},{"type":"link","label":"Bedrock","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/bedrock","docId":"modules/model_io/models/llms/integrations/bedrock"},{"type":"link","label":"CerebriumAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/cerebriumai_example","docId":"modules/model_io/models/llms/integrations/cerebriumai_example"},{"type":"link","label":"Cohere","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/cohere","docId":"modules/model_io/models/llms/integrations/cohere"},{"type":"link","label":"C Transformers","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/ctransformers","docId":"modules/model_io/models/llms/integrations/ctransformers"},{"type":"link","label":"Databricks","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/databricks","docId":"modules/model_io/models/llms/integrations/databricks"},{"type":"link","label":"DeepInfra","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/deepinfra_example","docId":"modules/model_io/models/llms/integrations/deepinfra_example"},{"type":"link","label":"ForefrontAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/forefrontai_example","docId":"modules/model_io/models/llms/integrations/forefrontai_example"},{"type":"link","label":"Google Cloud Platform Vertex AI PaLM","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/google_vertex_ai_palm","docId":"modules/model_io/models/llms/integrations/google_vertex_ai_palm"},{"type":"link","label":"GooseAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/gooseai_example","docId":"modules/model_io/models/llms/integrations/gooseai_example"},{"type":"link","label":"GPT4All","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/gpt4all","docId":"modules/model_io/models/llms/integrations/gpt4all"},{"type":"link","label":"Hugging Face Hub","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/huggingface_hub","docId":"modules/model_io/models/llms/integrations/huggingface_hub"},{"type":"link","label":"Hugging Face Local Pipelines","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/huggingface_pipelines","docId":"modules/model_io/models/llms/integrations/huggingface_pipelines"},{"type":"link","label":"Huggingface TextGen Inference","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/huggingface_textgen_inference","docId":"modules/model_io/models/llms/integrations/huggingface_textgen_inference"},{"type":"link","label":"JSONFormer","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/jsonformer_experimental","docId":"modules/model_io/models/llms/integrations/jsonformer_experimental"},{"type":"link","label":"Llama-cpp","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/llamacpp","docId":"modules/model_io/models/llms/integrations/llamacpp"},{"type":"link","label":"Caching integrations","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/llm_caching","docId":"modules/model_io/models/llms/integrations/llm_caching"},{"type":"link","label":"Manifest","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/manifest","docId":"modules/model_io/models/llms/integrations/manifest"},{"type":"link","label":"Modal","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/modal","docId":"modules/model_io/models/llms/integrations/modal"},{"type":"link","label":"MosaicML","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/mosaicml","docId":"modules/model_io/models/llms/integrations/mosaicml"},{"type":"link","label":"NLP Cloud","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/nlpcloud","docId":"modules/model_io/models/llms/integrations/nlpcloud"},{"type":"link","label":"OpenAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/openai","docId":"modules/model_io/models/llms/integrations/openai"},{"type":"link","label":"OpenLM","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/openlm","docId":"modules/model_io/models/llms/integrations/openlm"},{"type":"link","label":"Petals","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/petals_example","docId":"modules/model_io/models/llms/integrations/petals_example"},{"type":"link","label":"PipelineAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/pipelineai_example","docId":"modules/model_io/models/llms/integrations/pipelineai_example"},{"type":"link","label":"Prediction Guard","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/predictionguard","docId":"modules/model_io/models/llms/integrations/predictionguard"},{"type":"link","label":"PromptLayer OpenAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/promptlayer_openai","docId":"modules/model_io/models/llms/integrations/promptlayer_openai"},{"type":"link","label":"RELLM","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/rellm_experimental","docId":"modules/model_io/models/llms/integrations/rellm_experimental"},{"type":"link","label":"Replicate","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/replicate","docId":"modules/model_io/models/llms/integrations/replicate"},{"type":"link","label":"Runhouse","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/runhouse","docId":"modules/model_io/models/llms/integrations/runhouse"},{"type":"link","label":"SageMakerEndpoint","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/sagemaker","docId":"modules/model_io/models/llms/integrations/sagemaker"},{"type":"link","label":"StochasticAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/stochasticai","docId":"modules/model_io/models/llms/integrations/stochasticai"},{"type":"link","label":"Writer","href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/writer","docId":"modules/model_io/models/llms/integrations/writer"}]}],"href":"/langchain-docs-scratch/docs/modules/model_io/models/llms/"},{"type":"category","label":"Chat models","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"LLMChain","href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/how_to/llm_chain","docId":"modules/model_io/models/chat/how_to/llm_chain"},{"type":"link","label":"Prompts","href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/how_to/prompts","docId":"modules/model_io/models/chat/how_to/prompts"},{"type":"link","label":"Streaming","href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/how_to/streaming","docId":"modules/model_io/models/chat/how_to/streaming"}]},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Anthropic","href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/integrations/anthropic","docId":"modules/model_io/models/chat/integrations/anthropic"},{"type":"link","label":"Azure","href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/integrations/azure_chat_openai","docId":"modules/model_io/models/chat/integrations/azure_chat_openai"},{"type":"link","label":"Google Cloud Platform Vertex AI PaLM","href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/integrations/google_vertex_ai_palm","docId":"modules/model_io/models/chat/integrations/google_vertex_ai_palm"},{"type":"link","label":"OpenAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/integrations/openai","docId":"modules/model_io/models/chat/integrations/openai"},{"type":"link","label":"PromptLayer ChatOpenAI","href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/integrations/promptlayer_chatopenai","docId":"modules/model_io/models/chat/integrations/promptlayer_chatopenai"}]}],"href":"/langchain-docs-scratch/docs/modules/model_io/models/chat/"}],"href":"/langchain-docs-scratch/docs/modules/model_io/models/"},{"type":"category","label":"Output parsers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"List parser","href":"/langchain-docs-scratch/docs/modules/model_io/output_parsers/comma_separated","docId":"modules/model_io/output_parsers/comma_separated"},{"type":"link","label":"Datetime parser","href":"/langchain-docs-scratch/docs/modules/model_io/output_parsers/datetime","docId":"modules/model_io/output_parsers/datetime"},{"type":"link","label":"Enum parser","href":"/langchain-docs-scratch/docs/modules/model_io/output_parsers/enum","docId":"modules/model_io/output_parsers/enum"},{"type":"link","label":"Auto-fixing parser","href":"/langchain-docs-scratch/docs/modules/model_io/output_parsers/output_fixing_parser","docId":"modules/model_io/output_parsers/output_fixing_parser"},{"type":"link","label":"Pydantic (JSON) parser","href":"/langchain-docs-scratch/docs/modules/model_io/output_parsers/pydantic","docId":"modules/model_io/output_parsers/pydantic"},{"type":"link","label":"Retry parser","href":"/langchain-docs-scratch/docs/modules/model_io/output_parsers/retry","docId":"modules/model_io/output_parsers/retry"},{"type":"link","label":"Structured output parser","href":"/langchain-docs-scratch/docs/modules/model_io/output_parsers/structured","docId":"modules/model_io/output_parsers/structured"}],"href":"/langchain-docs-scratch/docs/modules/model_io/output_parsers/"}],"href":"/langchain-docs-scratch/docs/modules/model_io/"},{"type":"category","label":"Data connection","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Document loaders","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"CSV","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/how_to/csv","docId":"modules/data_io/document_loaders/how_to/csv"},{"type":"link","label":"File Directory","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/how_to/file_directory","docId":"modules/data_io/document_loaders/how_to/file_directory"},{"type":"link","label":"HTML","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/how_to/html","docId":"modules/data_io/document_loaders/how_to/html"},{"type":"link","label":"JSON","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/how_to/json","docId":"modules/data_io/document_loaders/how_to/json"},{"type":"link","label":"Markdown","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/how_to/markdown","docId":"modules/data_io/document_loaders/how_to/markdown"},{"type":"link","label":"PDF","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/how_to/pdf","docId":"modules/data_io/document_loaders/how_to/pdf"}]},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Airbyte JSON","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/airbyte_json","docId":"modules/data_io/document_loaders/integrations/airbyte_json"},{"type":"link","label":"Alibaba Cloud MaxCompute","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/alibaba_cloud_maxcompute","docId":"modules/data_io/document_loaders/integrations/alibaba_cloud_maxcompute"},{"type":"link","label":"Apify Dataset","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/apify_dataset","docId":"modules/data_io/document_loaders/integrations/apify_dataset"},{"type":"link","label":"Arxiv","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/arxiv","docId":"modules/data_io/document_loaders/integrations/arxiv"},{"type":"link","label":"AWS S3 Directory","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/aws_s3_directory","docId":"modules/data_io/document_loaders/integrations/aws_s3_directory"},{"type":"link","label":"AWS S3 File","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/aws_s3_file","docId":"modules/data_io/document_loaders/integrations/aws_s3_file"},{"type":"link","label":"AZLyrics","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/azlyrics","docId":"modules/data_io/document_loaders/integrations/azlyrics"},{"type":"link","label":"Azure Blob Storage Container","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/azure_blob_storage_container","docId":"modules/data_io/document_loaders/integrations/azure_blob_storage_container"},{"type":"link","label":"Azure Blob Storage File","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/azure_blob_storage_file","docId":"modules/data_io/document_loaders/integrations/azure_blob_storage_file"},{"type":"link","label":"BibTeX","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/bibtex","docId":"modules/data_io/document_loaders/integrations/bibtex"},{"type":"link","label":"BiliBili","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/bilibili","docId":"modules/data_io/document_loaders/integrations/bilibili"},{"type":"link","label":"Blackboard","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/blackboard","docId":"modules/data_io/document_loaders/integrations/blackboard"},{"type":"link","label":"Blockchain","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/blockchain","docId":"modules/data_io/document_loaders/integrations/blockchain"},{"type":"link","label":"chatgpt_loader","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/chatgpt_loader","docId":"modules/data_io/document_loaders/integrations/chatgpt_loader"},{"type":"link","label":"College Confidential","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/college_confidential","docId":"modules/data_io/document_loaders/integrations/college_confidential"},{"type":"link","label":"Confluence","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/confluence","docId":"modules/data_io/document_loaders/integrations/confluence"},{"type":"link","label":"CoNLL-U","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/conll-u","docId":"modules/data_io/document_loaders/integrations/conll-u"},{"type":"link","label":"Copy Paste","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/copypaste","docId":"modules/data_io/document_loaders/integrations/copypaste"},{"type":"link","label":"Diffbot","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/diffbot","docId":"modules/data_io/document_loaders/integrations/diffbot"},{"type":"link","label":"Discord","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/discord","docId":"modules/data_io/document_loaders/integrations/discord"},{"type":"link","label":"Docugami","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/docugami","docId":"modules/data_io/document_loaders/integrations/docugami"},{"type":"link","label":"DuckDB","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/duckdb","docId":"modules/data_io/document_loaders/integrations/duckdb"},{"type":"link","label":"Email","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/email","docId":"modules/data_io/document_loaders/integrations/email"},{"type":"link","label":"EPub","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/epub","docId":"modules/data_io/document_loaders/integrations/epub"},{"type":"link","label":"EverNote","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/evernote","docId":"modules/data_io/document_loaders/integrations/evernote"},{"type":"category","label":"example_data","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Notebook","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/example_data/notebook","docId":"modules/data_io/document_loaders/integrations/example_data/notebook"}]},{"type":"link","label":"Microsoft Excel","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/excel","docId":"modules/data_io/document_loaders/integrations/excel"},{"type":"link","label":"Facebook Chat","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/facebook_chat","docId":"modules/data_io/document_loaders/integrations/facebook_chat"},{"type":"link","label":"Figma","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/figma","docId":"modules/data_io/document_loaders/integrations/figma"},{"type":"link","label":"Git","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/git","docId":"modules/data_io/document_loaders/integrations/git"},{"type":"link","label":"GitBook","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/gitbook","docId":"modules/data_io/document_loaders/integrations/gitbook"},{"type":"link","label":"GitHub","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/github","docId":"modules/data_io/document_loaders/integrations/github"},{"type":"link","label":"Google BigQuery","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/google_bigquery","docId":"modules/data_io/document_loaders/integrations/google_bigquery"},{"type":"link","label":"Google Cloud Storage Directory","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/google_cloud_storage_directory","docId":"modules/data_io/document_loaders/integrations/google_cloud_storage_directory"},{"type":"link","label":"Google Cloud Storage File","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/google_cloud_storage_file","docId":"modules/data_io/document_loaders/integrations/google_cloud_storage_file"},{"type":"link","label":"Google Drive","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/google_drive","docId":"modules/data_io/document_loaders/integrations/google_drive"},{"type":"link","label":"Gutenberg","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/gutenberg","docId":"modules/data_io/document_loaders/integrations/gutenberg"},{"type":"link","label":"Hacker News","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/hacker_news","docId":"modules/data_io/document_loaders/integrations/hacker_news"},{"type":"link","label":"HuggingFace dataset","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/hugging_face_dataset","docId":"modules/data_io/document_loaders/integrations/hugging_face_dataset"},{"type":"link","label":"iFixit","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/ifixit","docId":"modules/data_io/document_loaders/integrations/ifixit"},{"type":"link","label":"Images","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/image","docId":"modules/data_io/document_loaders/integrations/image"},{"type":"link","label":"Image captions","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/image_captions","docId":"modules/data_io/document_loaders/integrations/image_captions"},{"type":"link","label":"IMSDb","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/imsdb","docId":"modules/data_io/document_loaders/integrations/imsdb"},{"type":"link","label":"Iugu","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/iugu","docId":"modules/data_io/document_loaders/integrations/iugu"},{"type":"link","label":"Joplin","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/joplin","docId":"modules/data_io/document_loaders/integrations/joplin"},{"type":"link","label":"Jupyter Notebook","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/jupyter_notebook","docId":"modules/data_io/document_loaders/integrations/jupyter_notebook"},{"type":"link","label":"Mastodon","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/mastodon","docId":"modules/data_io/document_loaders/integrations/mastodon"},{"type":"link","label":"MediaWikiDump","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/mediawikidump","docId":"modules/data_io/document_loaders/integrations/mediawikidump"},{"type":"link","label":"Microsoft OneDrive","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/microsoft_onedrive","docId":"modules/data_io/document_loaders/integrations/microsoft_onedrive"},{"type":"link","label":"Microsoft PowerPoint","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/microsoft_powerpoint","docId":"modules/data_io/document_loaders/integrations/microsoft_powerpoint"},{"type":"link","label":"Microsoft Word","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/microsoft_word","docId":"modules/data_io/document_loaders/integrations/microsoft_word"},{"type":"link","label":"Modern Treasury","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/modern_treasury","docId":"modules/data_io/document_loaders/integrations/modern_treasury"},{"type":"link","label":"Notion DB 1/2","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/notion","docId":"modules/data_io/document_loaders/integrations/notion"},{"type":"link","label":"Notion DB 2/2","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/notiondb","docId":"modules/data_io/document_loaders/integrations/notiondb"},{"type":"link","label":"Obsidian","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/obsidian","docId":"modules/data_io/document_loaders/integrations/obsidian"},{"type":"link","label":"Open Document Format (ODT)","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/odt","docId":"modules/data_io/document_loaders/integrations/odt"},{"type":"link","label":"Pandas DataFrame","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/pandas_dataframe","docId":"modules/data_io/document_loaders/integrations/pandas_dataframe"},{"type":"link","label":"Psychic","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/psychic","docId":"modules/data_io/document_loaders/integrations/psychic"},{"type":"link","label":"PySpark DataFrame Loader","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/pyspark_dataframe","docId":"modules/data_io/document_loaders/integrations/pyspark_dataframe"},{"type":"link","label":"ReadTheDocs Documentation","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/readthedocs_documentation","docId":"modules/data_io/document_loaders/integrations/readthedocs_documentation"},{"type":"link","label":"Reddit","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/reddit","docId":"modules/data_io/document_loaders/integrations/reddit"},{"type":"link","label":"Roam","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/roam","docId":"modules/data_io/document_loaders/integrations/roam"},{"type":"link","label":"Sitemap","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/sitemap","docId":"modules/data_io/document_loaders/integrations/sitemap"},{"type":"link","label":"Slack","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/slack","docId":"modules/data_io/document_loaders/integrations/slack"},{"type":"link","label":"Spreedly","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/spreedly","docId":"modules/data_io/document_loaders/integrations/spreedly"},{"type":"link","label":"Stripe","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/stripe","docId":"modules/data_io/document_loaders/integrations/stripe"},{"type":"link","label":"Subtitle","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/subtitle","docId":"modules/data_io/document_loaders/integrations/subtitle"},{"type":"link","label":"Telegram","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/telegram","docId":"modules/data_io/document_loaders/integrations/telegram"},{"type":"link","label":"2Markdown","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/tomarkdown","docId":"modules/data_io/document_loaders/integrations/tomarkdown"},{"type":"link","label":"TOML","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/toml","docId":"modules/data_io/document_loaders/integrations/toml"},{"type":"link","label":"Trello","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/trello","docId":"modules/data_io/document_loaders/integrations/trello"},{"type":"link","label":"Twitter","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/twitter","docId":"modules/data_io/document_loaders/integrations/twitter"},{"type":"link","label":"Unstructured File","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/unstructured_file","docId":"modules/data_io/document_loaders/integrations/unstructured_file"},{"type":"link","label":"URL","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/url","docId":"modules/data_io/document_loaders/integrations/url"},{"type":"link","label":"Weather","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/weather","docId":"modules/data_io/document_loaders/integrations/weather"},{"type":"link","label":"WebBaseLoader","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/web_base","docId":"modules/data_io/document_loaders/integrations/web_base"},{"type":"link","label":"WhatsApp Chat","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/whatsapp_chat","docId":"modules/data_io/document_loaders/integrations/whatsapp_chat"},{"type":"link","label":"Wikipedia","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/wikipedia","docId":"modules/data_io/document_loaders/integrations/wikipedia"},{"type":"link","label":"YouTube transcripts","href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/integrations/youtube_transcript","docId":"modules/data_io/document_loaders/integrations/youtube_transcript"}]}],"href":"/langchain-docs-scratch/docs/modules/data_io/document_loaders/"},{"type":"category","label":"Document transformers","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Text splitters","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Split by character","href":"/langchain-docs-scratch/docs/modules/data_io/document_transformers/text_splitters/character_text_splitter","docId":"modules/data_io/document_transformers/text_splitters/character_text_splitter"},{"type":"link","label":"Split code","href":"/langchain-docs-scratch/docs/modules/data_io/document_transformers/text_splitters/code_splitter","docId":"modules/data_io/document_transformers/text_splitters/code_splitter"},{"type":"link","label":"Recursively split by character","href":"/langchain-docs-scratch/docs/modules/data_io/document_transformers/text_splitters/recursive_text_splitter","docId":"modules/data_io/document_transformers/text_splitters/recursive_text_splitter"},{"type":"link","label":"Split by tokens","href":"/langchain-docs-scratch/docs/modules/data_io/document_transformers/text_splitters/split_by_token","docId":"modules/data_io/document_transformers/text_splitters/split_by_token"}]}],"href":"/langchain-docs-scratch/docs/modules/data_io/document_transformers/"},{"type":"category","label":"Text embedding models","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Aleph Alpha","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/aleph_alpha","docId":"modules/data_io/text_embedding/integrations/aleph_alpha"},{"type":"link","label":"AzureOpenAI","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/azureopenai","docId":"modules/data_io/text_embedding/integrations/azureopenai"},{"type":"link","label":"Bedrock Embeddings","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/bedrock","docId":"modules/data_io/text_embedding/integrations/bedrock"},{"type":"link","label":"Cohere","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/cohere","docId":"modules/data_io/text_embedding/integrations/cohere"},{"type":"link","label":"Elasticsearch","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/elasticsearch","docId":"modules/data_io/text_embedding/integrations/elasticsearch"},{"type":"link","label":"Fake Embeddings","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/fake","docId":"modules/data_io/text_embedding/integrations/fake"},{"type":"link","label":"Google Cloud Platform Vertex AI PaLM","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/google_vertex_ai_palm","docId":"modules/data_io/text_embedding/integrations/google_vertex_ai_palm"},{"type":"link","label":"Hugging Face Hub","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/huggingfacehub","docId":"modules/data_io/text_embedding/integrations/huggingfacehub"},{"type":"link","label":"InstructEmbeddings","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/instruct_embeddings","docId":"modules/data_io/text_embedding/integrations/instruct_embeddings"},{"type":"link","label":"Jina","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/jina","docId":"modules/data_io/text_embedding/integrations/jina"},{"type":"link","label":"Llama-cpp","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/llamacpp","docId":"modules/data_io/text_embedding/integrations/llamacpp"},{"type":"link","label":"MiniMax","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/minimax","docId":"modules/data_io/text_embedding/integrations/minimax"},{"type":"link","label":"ModelScope","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/modelscope_hub","docId":"modules/data_io/text_embedding/integrations/modelscope_hub"},{"type":"link","label":"MosaicML embeddings","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/mosaicml","docId":"modules/data_io/text_embedding/integrations/mosaicml"},{"type":"link","label":"OpenAI","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/openai","docId":"modules/data_io/text_embedding/integrations/openai"},{"type":"link","label":"SageMaker Endpoint Embeddings","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/sagemaker-endpoint","docId":"modules/data_io/text_embedding/integrations/sagemaker-endpoint"},{"type":"link","label":"Self Hosted Embeddings","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/self-hosted","docId":"modules/data_io/text_embedding/integrations/self-hosted"},{"type":"link","label":"Sentence Transformers Embeddings","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/sentence_transformers","docId":"modules/data_io/text_embedding/integrations/sentence_transformers"},{"type":"link","label":"TensorflowHub","href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/integrations/tensorflowhub","docId":"modules/data_io/text_embedding/integrations/tensorflowhub"}]}],"href":"/langchain-docs-scratch/docs/modules/data_io/text_embedding/"},{"type":"category","label":"Vector stores","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AnalyticDB","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/analyticdb","docId":"modules/data_io/vectorstores/integrations/analyticdb"},{"type":"link","label":"Annoy","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/annoy","docId":"modules/data_io/vectorstores/integrations/annoy"},{"type":"link","label":"Atlas","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/atlas","docId":"modules/data_io/vectorstores/integrations/atlas"},{"type":"link","label":"Chroma","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/chroma","docId":"modules/data_io/vectorstores/integrations/chroma"},{"type":"link","label":"Deep Lake","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/deeplake","docId":"modules/data_io/vectorstores/integrations/deeplake"},{"type":"link","label":"DocArrayHnswSearch","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/docarray_hnsw","docId":"modules/data_io/vectorstores/integrations/docarray_hnsw"},{"type":"link","label":"DocArrayInMemorySearch","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/docarray_in_memory","docId":"modules/data_io/vectorstores/integrations/docarray_in_memory"},{"type":"link","label":"ElasticSearch","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/elasticsearch","docId":"modules/data_io/vectorstores/integrations/elasticsearch"},{"type":"link","label":"FAISS","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/faiss","docId":"modules/data_io/vectorstores/integrations/faiss"},{"type":"link","label":"LanceDB","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/lancedb","docId":"modules/data_io/vectorstores/integrations/lancedb"},{"type":"link","label":"MatchingEngine","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/matchingengine","docId":"modules/data_io/vectorstores/integrations/matchingengine"},{"type":"link","label":"Milvus","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/milvus","docId":"modules/data_io/vectorstores/integrations/milvus"},{"type":"link","label":"MongoDB Atlas Vector Search","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/mongodb_atlas_vector_search","docId":"modules/data_io/vectorstores/integrations/mongodb_atlas_vector_search"},{"type":"link","label":"MyScale","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/myscale","docId":"modules/data_io/vectorstores/integrations/myscale"},{"type":"link","label":"OpenSearch","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/opensearch","docId":"modules/data_io/vectorstores/integrations/opensearch"},{"type":"link","label":"PGVector","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/pgvector","docId":"modules/data_io/vectorstores/integrations/pgvector"},{"type":"link","label":"Pinecone","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/pinecone","docId":"modules/data_io/vectorstores/integrations/pinecone"},{"type":"link","label":"Qdrant","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/qdrant","docId":"modules/data_io/vectorstores/integrations/qdrant"},{"type":"link","label":"Redis","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/redis","docId":"modules/data_io/vectorstores/integrations/redis"},{"type":"link","label":"SKLearnVectorStore","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/sklearn","docId":"modules/data_io/vectorstores/integrations/sklearn"},{"type":"link","label":"Supabase (Postgres)","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/supabase","docId":"modules/data_io/vectorstores/integrations/supabase"},{"type":"link","label":"Tair","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/tair","docId":"modules/data_io/vectorstores/integrations/tair"},{"type":"link","label":"Typesense","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/typesense","docId":"modules/data_io/vectorstores/integrations/typesense"},{"type":"link","label":"Vectara","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/vectara","docId":"modules/data_io/vectorstores/integrations/vectara"},{"type":"link","label":"Weaviate","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/weaviate","docId":"modules/data_io/vectorstores/integrations/weaviate"},{"type":"link","label":"Zilliz","href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/zilliz","docId":"modules/data_io/vectorstores/integrations/zilliz"}]}],"href":"/langchain-docs-scratch/docs/modules/data_io/vectorstores/"},{"type":"category","label":"Retrievers","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Contextual compression","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/how_to/contextual_compression/","docId":"modules/data_io/retrievers/how_to/contextual_compression/index"},{"type":"category","label":"Self-querying","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Self-querying with Chroma","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/how_to/self_query/chroma_self_query","docId":"modules/data_io/retrievers/how_to/self_query/chroma_self_query"},{"type":"link","label":"Self-querying with Pinecone","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/how_to/self_query/pinecone","docId":"modules/data_io/retrievers/how_to/self_query/pinecone"},{"type":"link","label":"Self-querying with Qdrant","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/how_to/self_query/qdrant_self_query","docId":"modules/data_io/retrievers/how_to/self_query/qdrant_self_query"},{"type":"link","label":"Self-querying with Weaviate","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/how_to/self_query/weaviate_self_query","docId":"modules/data_io/retrievers/how_to/self_query/weaviate_self_query"}],"href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/how_to/self_query/"},{"type":"link","label":"Time-weighted vector store retriever","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/how_to/time_weighted_vectorstore","docId":"modules/data_io/retrievers/how_to/time_weighted_vectorstore"},{"type":"link","label":"Vector store-backed retriever","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/how_to/vectorstore","docId":"modules/data_io/retrievers/how_to/vectorstore"}]},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Arxiv","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/arxiv","docId":"modules/data_io/retrievers/integrations/arxiv"},{"type":"link","label":"Azure Cognitive Search","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/azure_cognitive_search","docId":"modules/data_io/retrievers/integrations/azure_cognitive_search"},{"type":"link","label":"ChatGPT Plugin","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/chatgpt-plugin","docId":"modules/data_io/retrievers/integrations/chatgpt-plugin"},{"type":"link","label":"Cohere Reranker","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/cohere-reranker","docId":"modules/data_io/retrievers/integrations/cohere-reranker"},{"type":"link","label":"Databerry","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/databerry","docId":"modules/data_io/retrievers/integrations/databerry"},{"type":"link","label":"ElasticSearch BM25","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/elastic_search_bm25","docId":"modules/data_io/retrievers/integrations/elastic_search_bm25"},{"type":"link","label":"kNN","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/knn","docId":"modules/data_io/retrievers/integrations/knn"},{"type":"link","label":"Metal","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/metal","docId":"modules/data_io/retrievers/integrations/metal"},{"type":"link","label":"Pinecone Hybrid Search","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/pinecone_hybrid_search","docId":"modules/data_io/retrievers/integrations/pinecone_hybrid_search"},{"type":"link","label":"PubMed Retriever","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/pubmed","docId":"modules/data_io/retrievers/integrations/pubmed"},{"type":"link","label":"SVM","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/svm","docId":"modules/data_io/retrievers/integrations/svm"},{"type":"link","label":"TF-IDF","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/tf_idf","docId":"modules/data_io/retrievers/integrations/tf_idf"},{"type":"link","label":"Vespa","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/vespa","docId":"modules/data_io/retrievers/integrations/vespa"},{"type":"link","label":"Weaviate Hybrid Search","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/weaviate-hybrid","docId":"modules/data_io/retrievers/integrations/weaviate-hybrid"},{"type":"link","label":"Wikipedia","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/wikipedia","docId":"modules/data_io/retrievers/integrations/wikipedia"},{"type":"link","label":"Zep","href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/zep_memorystore","docId":"modules/data_io/retrievers/integrations/zep_memorystore"}]}],"href":"/langchain-docs-scratch/docs/modules/data_io/retrievers/"}],"href":"/langchain-docs-scratch/docs/modules/data_io/"},{"type":"category","label":"Chains","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Async API","href":"/langchain-docs-scratch/docs/modules/chains/how_to/async_chain","docId":"modules/chains/how_to/async_chain"},{"type":"link","label":"Different call methods","href":"/langchain-docs-scratch/docs/modules/chains/how_to/call_methods","docId":"modules/chains/how_to/call_methods"},{"type":"link","label":"Custom chain","href":"/langchain-docs-scratch/docs/modules/chains/how_to/custom_chain","docId":"modules/chains/how_to/custom_chain"},{"type":"link","label":"Debugging chains","href":"/langchain-docs-scratch/docs/modules/chains/how_to/debugging","docId":"modules/chains/how_to/debugging"},{"type":"link","label":"Adding memory (state)","href":"/langchain-docs-scratch/docs/modules/chains/how_to/memory","docId":"modules/chains/how_to/memory"},{"type":"link","label":"Serialization","href":"/langchain-docs-scratch/docs/modules/chains/how_to/serialization","docId":"modules/chains/how_to/serialization"}],"href":"/langchain-docs-scratch/docs/modules/chains/how_to/"},{"type":"category","label":"Foundational","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"LLM","href":"/langchain-docs-scratch/docs/modules/chains/foundational/llm_chain","docId":"modules/chains/foundational/llm_chain"},{"type":"link","label":"Router","href":"/langchain-docs-scratch/docs/modules/chains/foundational/router","docId":"modules/chains/foundational/router"},{"type":"link","label":"Sequential","href":"/langchain-docs-scratch/docs/modules/chains/foundational/sequential_chains","docId":"modules/chains/foundational/sequential_chains"},{"type":"link","label":"Transformation","href":"/langchain-docs-scratch/docs/modules/chains/foundational/transformation","docId":"modules/chains/foundational/transformation"}],"href":"/langchain-docs-scratch/docs/modules/chains/foundational/"},{"type":"category","label":"Documents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Stuff","href":"/langchain-docs-scratch/docs/modules/chains/document/stuff","docId":"modules/chains/document/stuff"},{"type":"link","label":"Refine","href":"/langchain-docs-scratch/docs/modules/chains/document/refine","docId":"modules/chains/document/refine"},{"type":"link","label":"Map reduce","href":"/langchain-docs-scratch/docs/modules/chains/document/map_reduce","docId":"modules/chains/document/map_reduce"},{"type":"link","label":"Map re-rank","href":"/langchain-docs-scratch/docs/modules/chains/document/map_rerank","docId":"modules/chains/document/map_rerank"}],"href":"/langchain-docs-scratch/docs/modules/chains/document/"},{"type":"category","label":"Popular","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"API chains","href":"/langchain-docs-scratch/docs/modules/chains/popular/api","docId":"modules/chains/popular/api"},{"type":"link","label":"Retrieval QA","href":"/langchain-docs-scratch/docs/modules/chains/popular/vector_db_qa","docId":"modules/chains/popular/vector_db_qa"},{"type":"link","label":"Conversational Retrieval QA","href":"/langchain-docs-scratch/docs/modules/chains/popular/chat_vector_db","docId":"modules/chains/popular/chat_vector_db"},{"type":"link","label":"SQL","href":"/langchain-docs-scratch/docs/modules/chains/popular/sqlite","docId":"modules/chains/popular/sqlite"},{"type":"link","label":"Summarization","href":"/langchain-docs-scratch/docs/modules/chains/popular/summarize","docId":"modules/chains/popular/summarize"}],"href":"/langchain-docs-scratch/docs/modules/chains/popular/"},{"type":"category","label":"Additional","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Analyze Document","href":"/langchain-docs-scratch/docs/modules/chains/additional/analyze_document","docId":"modules/chains/additional/analyze_document"},{"type":"link","label":"Self-critique chain with constitutional AI","href":"/langchain-docs-scratch/docs/modules/chains/additional/constitutional_chain","docId":"modules/chains/additional/constitutional_chain"},{"type":"link","label":"FLARE","href":"/langchain-docs-scratch/docs/modules/chains/additional/flare","docId":"modules/chains/additional/flare"},{"type":"link","label":"Loading from LangChainHub","href":"/langchain-docs-scratch/docs/modules/chains/additional/from_hub","docId":"modules/chains/additional/from_hub"},{"type":"link","label":"Graph DB QA chain","href":"/langchain-docs-scratch/docs/modules/chains/additional/graph_cypher_qa","docId":"modules/chains/additional/graph_cypher_qa"},{"type":"link","label":"Graph QA","href":"/langchain-docs-scratch/docs/modules/chains/additional/graph_qa","docId":"modules/chains/additional/graph_qa"},{"type":"link","label":"Hypothetical Document Embeddings","href":"/langchain-docs-scratch/docs/modules/chains/additional/hyde","docId":"modules/chains/additional/hyde"},{"type":"link","label":"Bash chain","href":"/langchain-docs-scratch/docs/modules/chains/additional/llm_bash","docId":"modules/chains/additional/llm_bash"},{"type":"link","label":"Self-checking chain","href":"/langchain-docs-scratch/docs/modules/chains/additional/llm_checker","docId":"modules/chains/additional/llm_checker"},{"type":"link","label":"Math chain","href":"/langchain-docs-scratch/docs/modules/chains/additional/llm_math","docId":"modules/chains/additional/llm_math"},{"type":"link","label":"HTTP request chain","href":"/langchain-docs-scratch/docs/modules/chains/additional/llm_requests","docId":"modules/chains/additional/llm_requests"},{"type":"link","label":"Summarization checker chain","href":"/langchain-docs-scratch/docs/modules/chains/additional/llm_summarization_checker","docId":"modules/chains/additional/llm_summarization_checker"},{"type":"link","label":"Moderation","href":"/langchain-docs-scratch/docs/modules/chains/additional/moderation","docId":"modules/chains/additional/moderation"},{"type":"link","label":"Dynamically selecting from multiple prompts","href":"/langchain-docs-scratch/docs/modules/chains/additional/multi_prompt_router","docId":"modules/chains/additional/multi_prompt_router"},{"type":"link","label":"Dynamically selecting from multiple retrievers","href":"/langchain-docs-scratch/docs/modules/chains/additional/multi_retrieval_qa_router","docId":"modules/chains/additional/multi_retrieval_qa_router"},{"type":"link","label":"OpenAPI chain","href":"/langchain-docs-scratch/docs/modules/chains/additional/openapi","docId":"modules/chains/additional/openapi"},{"type":"link","label":"Program-aided language model (PAL) chain","href":"/langchain-docs-scratch/docs/modules/chains/additional/pal","docId":"modules/chains/additional/pal"},{"type":"link","label":"Document QA","href":"/langchain-docs-scratch/docs/modules/chains/additional/question_answering","docId":"modules/chains/additional/question_answering"},{"type":"link","label":"Vector store-augmented text generation","href":"/langchain-docs-scratch/docs/modules/chains/additional/vector_db_text_generation","docId":"modules/chains/additional/vector_db_text_generation"}],"href":"/langchain-docs-scratch/docs/modules/chains/additional/"}],"href":"/langchain-docs-scratch/docs/modules/chains/"},{"type":"category","label":"Memory","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"How to add Memory to an LLMChain","href":"/langchain-docs-scratch/docs/modules/memory/how_to/adding_memory","docId":"modules/memory/how_to/adding_memory"},{"type":"link","label":"How to add memory to a Multi-Input Chain","href":"/langchain-docs-scratch/docs/modules/memory/how_to/adding_memory_chain_multiple_inputs","docId":"modules/memory/how_to/adding_memory_chain_multiple_inputs"},{"type":"link","label":"How to add Memory to an Agent","href":"/langchain-docs-scratch/docs/modules/memory/how_to/agent_with_memory","docId":"modules/memory/how_to/agent_with_memory"},{"type":"link","label":"Adding Message Memory backed by a database to an Agent","href":"/langchain-docs-scratch/docs/modules/memory/how_to/agent_with_memory_in_db","docId":"modules/memory/how_to/agent_with_memory_in_db"},{"type":"link","label":"Conversation buffer memory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/buffer","docId":"modules/memory/how_to/buffer"},{"type":"link","label":"Conversation buffer window memory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/buffer_window","docId":"modules/memory/how_to/buffer_window"},{"type":"link","label":"How to customize conversational memory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/conversational_customization","docId":"modules/memory/how_to/conversational_customization"},{"type":"link","label":"How to create a custom Memory class","href":"/langchain-docs-scratch/docs/modules/memory/how_to/custom_memory","docId":"modules/memory/how_to/custom_memory"},{"type":"link","label":"Entity memory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/entity_summary_memory","docId":"modules/memory/how_to/entity_summary_memory"},{"type":"link","label":"Conversation Knowledge Graph Memory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/kg","docId":"modules/memory/how_to/kg"},{"type":"link","label":"How to use multiple memory classes in the same chain","href":"/langchain-docs-scratch/docs/modules/memory/how_to/multiple_memory","docId":"modules/memory/how_to/multiple_memory"},{"type":"link","label":"Conversation summary memory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/summary","docId":"modules/memory/how_to/summary"},{"type":"link","label":"ConversationSummaryBufferMemory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/summary_buffer","docId":"modules/memory/how_to/summary_buffer"},{"type":"link","label":"ConversationTokenBufferMemory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/token_buffer","docId":"modules/memory/how_to/token_buffer"},{"type":"link","label":"Vector store-backed memory","href":"/langchain-docs-scratch/docs/modules/memory/how_to/vectorstore_retriever_memory","docId":"modules/memory/how_to/vectorstore_retriever_memory"}]},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Cassandra Chat Message History","href":"/langchain-docs-scratch/docs/modules/memory/integrations/cassandra_chat_message_history","docId":"modules/memory/integrations/cassandra_chat_message_history"},{"type":"link","label":"Dynamodb Chat Message History","href":"/langchain-docs-scratch/docs/modules/memory/integrations/dynamodb_chat_message_history","docId":"modules/memory/integrations/dynamodb_chat_message_history"},{"type":"link","label":"Entity Memory with SQLite storage","href":"/langchain-docs-scratch/docs/modules/memory/integrations/entity_memory_with_sqlite","docId":"modules/memory/integrations/entity_memory_with_sqlite"},{"type":"link","label":"Momento Chat Message History","href":"/langchain-docs-scratch/docs/modules/memory/integrations/momento_chat_message_history","docId":"modules/memory/integrations/momento_chat_message_history"},{"type":"link","label":"Mongodb Chat Message History","href":"/langchain-docs-scratch/docs/modules/memory/integrations/mongodb_chat_message_history","docId":"modules/memory/integrations/mongodb_chat_message_history"},{"type":"link","label":"Mot\xf6rhead Memory","href":"/langchain-docs-scratch/docs/modules/memory/integrations/motorhead_memory","docId":"modules/memory/integrations/motorhead_memory"},{"type":"link","label":"Mot\xf6rhead Memory (Managed)","href":"/langchain-docs-scratch/docs/modules/memory/integrations/motorhead_memory_managed","docId":"modules/memory/integrations/motorhead_memory_managed"},{"type":"link","label":"Postgres Chat Message History","href":"/langchain-docs-scratch/docs/modules/memory/integrations/postgres_chat_message_history","docId":"modules/memory/integrations/postgres_chat_message_history"},{"type":"link","label":"Redis Chat Message History","href":"/langchain-docs-scratch/docs/modules/memory/integrations/redis_chat_message_history","docId":"modules/memory/integrations/redis_chat_message_history"},{"type":"link","label":"Zep Memory","href":"/langchain-docs-scratch/docs/modules/memory/integrations/zep_memory","docId":"modules/memory/integrations/zep_memory"}]}],"href":"/langchain-docs-scratch/docs/modules/memory/"},{"type":"category","label":"Agents","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Agent types","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Conversational agent","href":"/langchain-docs-scratch/docs/modules/agents/agent_types/chat_conversation_agent","docId":"modules/agents/agent_types/chat_conversation_agent"},{"type":"link","label":"Plan and execute","href":"/langchain-docs-scratch/docs/modules/agents/agent_types/plan_and_execute","docId":"modules/agents/agent_types/plan_and_execute"},{"type":"link","label":"ReAct","href":"/langchain-docs-scratch/docs/modules/agents/agent_types/react","docId":"modules/agents/agent_types/react"},{"type":"link","label":"ReAct document store","href":"/langchain-docs-scratch/docs/modules/agents/agent_types/react_docstore","docId":"modules/agents/agent_types/react_docstore"},{"type":"link","label":"Self ask with search","href":"/langchain-docs-scratch/docs/modules/agents/agent_types/self_ask_with_search","docId":"modules/agents/agent_types/self_ask_with_search"}],"href":"/langchain-docs-scratch/docs/modules/agents/agent_types/"},{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Combine agents and vector stores","href":"/langchain-docs-scratch/docs/modules/agents/how_to/agent_vectorstore","docId":"modules/agents/how_to/agent_vectorstore"},{"type":"link","label":"Async API","href":"/langchain-docs-scratch/docs/modules/agents/how_to/async_agent","docId":"modules/agents/how_to/async_agent"},{"type":"link","label":"Create ChatGPT clone","href":"/langchain-docs-scratch/docs/modules/agents/how_to/chatgpt_clone","docId":"modules/agents/how_to/chatgpt_clone"},{"type":"link","label":"Custom agent","href":"/langchain-docs-scratch/docs/modules/agents/how_to/custom_agent","docId":"modules/agents/how_to/custom_agent"},{"type":"link","label":"Custom agent with tool retrieval","href":"/langchain-docs-scratch/docs/modules/agents/how_to/custom_agent_with_tool_retrieval","docId":"modules/agents/how_to/custom_agent_with_tool_retrieval"},{"type":"link","label":"Custom LLM Agent","href":"/langchain-docs-scratch/docs/modules/agents/how_to/custom_llm_agent","docId":"modules/agents/how_to/custom_llm_agent"},{"type":"link","label":"Custom LLM Agent (with a ChatModel)","href":"/langchain-docs-scratch/docs/modules/agents/how_to/custom_llm_chat_agent","docId":"modules/agents/how_to/custom_llm_chat_agent"},{"type":"link","label":"Custom MRKL agent","href":"/langchain-docs-scratch/docs/modules/agents/how_to/custom_mrkl_agent","docId":"modules/agents/how_to/custom_mrkl_agent"},{"type":"link","label":"Custom multi-action agent","href":"/langchain-docs-scratch/docs/modules/agents/how_to/custom_multi_action_agent","docId":"modules/agents/how_to/custom_multi_action_agent"},{"type":"link","label":"Handle parsing errors","href":"/langchain-docs-scratch/docs/modules/agents/how_to/handle_parsing_errors","docId":"modules/agents/how_to/handle_parsing_errors"},{"type":"link","label":"Access intermediate steps","href":"/langchain-docs-scratch/docs/modules/agents/how_to/intermediate_steps","docId":"modules/agents/how_to/intermediate_steps"},{"type":"link","label":"Cap the max number of iterations","href":"/langchain-docs-scratch/docs/modules/agents/how_to/max_iterations","docId":"modules/agents/how_to/max_iterations"},{"type":"link","label":"Timeouts for agents","href":"/langchain-docs-scratch/docs/modules/agents/how_to/max_time_limit","docId":"modules/agents/how_to/max_time_limit"},{"type":"link","label":"Replicating MRKL","href":"/langchain-docs-scratch/docs/modules/agents/how_to/mrkl","docId":"modules/agents/how_to/mrkl"},{"type":"link","label":"Shared memory across agents and tools","href":"/langchain-docs-scratch/docs/modules/agents/how_to/sharedmemory_for_tools","docId":"modules/agents/how_to/sharedmemory_for_tools"},{"type":"link","label":"Streaming final agent output","href":"/langchain-docs-scratch/docs/modules/agents/how_to/streaming_stdout_final_only","docId":"modules/agents/how_to/streaming_stdout_final_only"},{"type":"link","label":"Structured tool chat agent","href":"/langchain-docs-scratch/docs/modules/agents/how_to/structured_chat","docId":"modules/agents/how_to/structured_chat"}]},{"type":"category","label":"Tools","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Defining Custom Tools","href":"/langchain-docs-scratch/docs/modules/agents/tools/how_to/custom_tools","docId":"modules/agents/tools/how_to/custom_tools"},{"type":"link","label":"Human-in-the-loop Tool Validation","href":"/langchain-docs-scratch/docs/modules/agents/tools/how_to/human_approval","docId":"modules/agents/tools/how_to/human_approval"},{"type":"link","label":"Multi-Input Tools","href":"/langchain-docs-scratch/docs/modules/agents/tools/how_to/multi_input_tool","docId":"modules/agents/tools/how_to/multi_input_tool"},{"type":"link","label":"Tool Input Schema","href":"/langchain-docs-scratch/docs/modules/agents/tools/how_to/tool_input_validation","docId":"modules/agents/tools/how_to/tool_input_validation"}]},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Apify","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/apify","docId":"modules/agents/tools/integrations/apify"},{"type":"link","label":"ArXiv API Tool","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/arxiv","docId":"modules/agents/tools/integrations/arxiv"},{"type":"link","label":"awslambda","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/awslambda","docId":"modules/agents/tools/integrations/awslambda"},{"type":"link","label":"Shell Tool","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/bash","docId":"modules/agents/tools/integrations/bash"},{"type":"link","label":"Bing Search","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/bing_search","docId":"modules/agents/tools/integrations/bing_search"},{"type":"link","label":"Brave Search","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/brave_search","docId":"modules/agents/tools/integrations/brave_search"},{"type":"link","label":"ChatGPT Plugins","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/chatgpt_plugins","docId":"modules/agents/tools/integrations/chatgpt_plugins"},{"type":"link","label":"DuckDuckGo Search","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/ddg","docId":"modules/agents/tools/integrations/ddg"},{"type":"link","label":"File System Tools","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/filesystem","docId":"modules/agents/tools/integrations/filesystem"},{"type":"link","label":"Google Places","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/google_places","docId":"modules/agents/tools/integrations/google_places"},{"type":"link","label":"Google Search","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/google_search","docId":"modules/agents/tools/integrations/google_search"},{"type":"link","label":"Google Serper API","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/google_serper","docId":"modules/agents/tools/integrations/google_serper"},{"type":"link","label":"Gradio Tools","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/gradio_tools","docId":"modules/agents/tools/integrations/gradio_tools"},{"type":"link","label":"GraphQL tool","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/graphql","docId":"modules/agents/tools/integrations/graphql"},{"type":"link","label":"huggingface_tools","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/huggingface_tools","docId":"modules/agents/tools/integrations/huggingface_tools"},{"type":"link","label":"Human as a tool","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/human_tools","docId":"modules/agents/tools/integrations/human_tools"},{"type":"link","label":"IFTTT WebHooks","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/ifttt","docId":"modules/agents/tools/integrations/ifttt"},{"type":"link","label":"Metaphor Search","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/metaphor_search","docId":"modules/agents/tools/integrations/metaphor_search"},{"type":"link","label":"OpenWeatherMap API","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/openweathermap","docId":"modules/agents/tools/integrations/openweathermap"},{"type":"link","label":"PubMed Tool","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/pubmed","docId":"modules/agents/tools/integrations/pubmed"},{"type":"link","label":"Requests","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/requests","docId":"modules/agents/tools/integrations/requests"},{"type":"link","label":"SceneXplain","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/sceneXplain","docId":"modules/agents/tools/integrations/sceneXplain"},{"type":"link","label":"Search Tools","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/search_tools","docId":"modules/agents/tools/integrations/search_tools"},{"type":"link","label":"SearxNG Search API","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/searx_search","docId":"modules/agents/tools/integrations/searx_search"},{"type":"link","label":"SerpAPI","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/serpapi","docId":"modules/agents/tools/integrations/serpapi"},{"type":"link","label":"Twilio","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/twilio","docId":"modules/agents/tools/integrations/twilio"},{"type":"link","label":"Wikipedia","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/wikipedia","docId":"modules/agents/tools/integrations/wikipedia"},{"type":"link","label":"Wolfram Alpha","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/wolfram_alpha","docId":"modules/agents/tools/integrations/wolfram_alpha"},{"type":"link","label":"YouTubeSearchTool","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/youtube","docId":"modules/agents/tools/integrations/youtube"},{"type":"link","label":"Zapier Natural Language Actions API","href":"/langchain-docs-scratch/docs/modules/agents/tools/integrations/zapier","docId":"modules/agents/tools/integrations/zapier"}]}],"href":"/langchain-docs-scratch/docs/modules/agents/tools/"},{"type":"category","label":"Toolkits","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Azure Cognitive Services Toolkit","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/azure_cognitive_services","docId":"modules/agents/toolkits/azure_cognitive_services"},{"type":"link","label":"CSV Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/csv","docId":"modules/agents/toolkits/csv"},{"type":"link","label":"Gmail Toolkit","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/gmail","docId":"modules/agents/toolkits/gmail"},{"type":"link","label":"Jira","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/jira","docId":"modules/agents/toolkits/jira"},{"type":"link","label":"JSON Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/json","docId":"modules/agents/toolkits/json"},{"type":"link","label":"OpenAPI agents","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/openapi","docId":"modules/agents/toolkits/openapi"},{"type":"link","label":"Natural Language APIs","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/openapi_nla","docId":"modules/agents/toolkits/openapi_nla"},{"type":"link","label":"Pandas Dataframe Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/pandas","docId":"modules/agents/toolkits/pandas"},{"type":"link","label":"PlayWright Browser Toolkit","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/playwright","docId":"modules/agents/toolkits/playwright"},{"type":"link","label":"PowerBI Dataset Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/powerbi","docId":"modules/agents/toolkits/powerbi"},{"type":"link","label":"Python Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/python","docId":"modules/agents/toolkits/python"},{"type":"link","label":"Spark Dataframe Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/spark","docId":"modules/agents/toolkits/spark"},{"type":"link","label":"Spark SQL Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/spark_sql","docId":"modules/agents/toolkits/spark_sql"},{"type":"link","label":"SQL Database Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/sql_database","docId":"modules/agents/toolkits/sql_database"},{"type":"link","label":"Vectorstore Agent","href":"/langchain-docs-scratch/docs/modules/agents/toolkits/vectorstore","docId":"modules/agents/toolkits/vectorstore"}],"href":"/langchain-docs-scratch/docs/modules/agents/toolkits/"}],"href":"/langchain-docs-scratch/docs/modules/agents/"},{"type":"category","label":"Callbacks","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Async callbacks","href":"/langchain-docs-scratch/docs/modules/callbacks/how_to/async_callbacks","docId":"modules/callbacks/how_to/async_callbacks"},{"type":"link","label":"Custom callback handlers","href":"/langchain-docs-scratch/docs/modules/callbacks/how_to/custom_callbacks","docId":"modules/callbacks/how_to/custom_callbacks"},{"type":"link","label":"Callbacks for custom chains","href":"/langchain-docs-scratch/docs/modules/callbacks/how_to/custom_chain","docId":"modules/callbacks/how_to/custom_chain"},{"type":"link","label":"Logging to file","href":"/langchain-docs-scratch/docs/modules/callbacks/how_to/filecallbackhandler","docId":"modules/callbacks/how_to/filecallbackhandler"},{"type":"link","label":"Multiple callback handlers","href":"/langchain-docs-scratch/docs/modules/callbacks/how_to/multiple_callbacks","docId":"modules/callbacks/how_to/multiple_callbacks"},{"type":"link","label":"Token counting","href":"/langchain-docs-scratch/docs/modules/callbacks/how_to/token_counting","docId":"modules/callbacks/how_to/token_counting"},{"type":"link","label":"Tracing","href":"/langchain-docs-scratch/docs/modules/callbacks/how_to/tracing","docId":"modules/callbacks/how_to/tracing"}]},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Argilla","href":"/langchain-docs-scratch/docs/modules/callbacks/integrations/argilla","docId":"modules/callbacks/integrations/argilla"}]}],"href":"/langchain-docs-scratch/docs/modules/callbacks/"}],"href":"/langchain-docs-scratch/docs/modules"},{"type":"category","label":"Use cases","collapsed":true,"items":[{"type":"category","label":"Agent simulations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"CAMEL Role-Playing Autonomous Cooperative Agents","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/camel_role_playing","docId":"use_cases/agent_simulations/camel_role_playing"},{"type":"link","label":"Generative Agents in LangChain","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/characters","docId":"use_cases/agent_simulations/characters"},{"type":"link","label":"Simulated Environment: Gymnasium","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/gymnasium","docId":"use_cases/agent_simulations/gymnasium"},{"type":"link","label":"Multi-Player Dungeons & Dragons","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/multi_player_dnd","docId":"use_cases/agent_simulations/multi_player_dnd"},{"type":"link","label":"Multi-agent authoritarian speaker selection","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/multiagent_authoritarian","docId":"use_cases/agent_simulations/multiagent_authoritarian"},{"type":"link","label":"Multi-agent decentralized speaker selection","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/multiagent_bidding","docId":"use_cases/agent_simulations/multiagent_bidding"},{"type":"link","label":"Multi-Agent Simulated Environment: Petting Zoo","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/petting_zoo","docId":"use_cases/agent_simulations/petting_zoo"},{"type":"link","label":"Agent Debates with Tools","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/two_agent_debate_tools","docId":"use_cases/agent_simulations/two_agent_debate_tools"},{"type":"link","label":"Two-Player Dungeons & Dragons","href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/two_player_dnd","docId":"use_cases/agent_simulations/two_player_dnd"}],"href":"/langchain-docs-scratch/docs/use_cases/agent_simulations/"},{"type":"category","label":"Agents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"BabyAGI User Guide","href":"/langchain-docs-scratch/docs/use_cases/agents/baby_agi","docId":"use_cases/agents/baby_agi"},{"type":"link","label":"BabyAGI with Tools","href":"/langchain-docs-scratch/docs/use_cases/agents/baby_agi_with_agent","docId":"use_cases/agents/baby_agi_with_agent"},{"type":"link","label":"CAMEL Role-Playing Autonomous Cooperative Agents","href":"/langchain-docs-scratch/docs/use_cases/agents/camel_role_playing","docId":"use_cases/agents/camel_role_playing"},{"type":"link","label":"Custom Agent with PlugIn Retrieval","href":"/langchain-docs-scratch/docs/use_cases/agents/custom_agent_with_plugin_retrieval","docId":"use_cases/agents/custom_agent_with_plugin_retrieval"},{"type":"link","label":"Plug-and-Plai","href":"/langchain-docs-scratch/docs/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai","docId":"use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai"},{"type":"link","label":"multi_modal_output_agent","href":"/langchain-docs-scratch/docs/use_cases/agents/multi_modal_output_agent","docId":"use_cases/agents/multi_modal_output_agent"},{"type":"link","label":"SalesGPT - Your Context-Aware AI Sales Assistant","href":"/langchain-docs-scratch/docs/use_cases/agents/sales_agent_with_context","docId":"use_cases/agents/sales_agent_with_context"},{"type":"link","label":"Wikibase Agent","href":"/langchain-docs-scratch/docs/use_cases/agents/wikibase_agent","docId":"use_cases/agents/wikibase_agent"}],"href":"/langchain-docs-scratch/docs/use_cases/agents/"},{"type":"link","label":"Interacting with APIs","href":"/langchain-docs-scratch/docs/use_cases/apis","docId":"use_cases/apis"},{"type":"category","label":"Autonomous (long-running) agents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AutoGPT","href":"/langchain-docs-scratch/docs/use_cases/autonomous_agents/autogpt","docId":"use_cases/autonomous_agents/autogpt"},{"type":"link","label":"BabyAGI User Guide","href":"/langchain-docs-scratch/docs/use_cases/autonomous_agents/baby_agi","docId":"use_cases/autonomous_agents/baby_agi"},{"type":"link","label":"BabyAGI with Tools","href":"/langchain-docs-scratch/docs/use_cases/autonomous_agents/baby_agi_with_agent","docId":"use_cases/autonomous_agents/baby_agi_with_agent"},{"type":"link","label":"marathon_times","href":"/langchain-docs-scratch/docs/use_cases/autonomous_agents/marathon_times","docId":"use_cases/autonomous_agents/marathon_times"},{"type":"link","label":"Meta-Prompt","href":"/langchain-docs-scratch/docs/use_cases/autonomous_agents/meta_prompt","docId":"use_cases/autonomous_agents/meta_prompt"}],"href":"/langchain-docs-scratch/docs/use_cases/autonomous_agents/"},{"type":"category","label":"Chatbots","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Voice Assistant","href":"/langchain-docs-scratch/docs/use_cases/chatbots/voice_assistant","docId":"use_cases/chatbots/voice_assistant"}],"href":"/langchain-docs-scratch/docs/use_cases/chatbots/"},{"type":"category","label":"Code Understanding","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Use LangChain, GPT and Deep Lake to work with code base","href":"/langchain-docs-scratch/docs/use_cases/code/code-analysis-deeplake","docId":"use_cases/code/code-analysis-deeplake"},{"type":"link","label":"Analysis of Twitter the-algorithm source code with LangChain, GPT4 and Deep Lake","href":"/langchain-docs-scratch/docs/use_cases/code/twitter-the-algorithm-analysis-deeplake","docId":"use_cases/code/twitter-the-algorithm-analysis-deeplake"}],"href":"/langchain-docs-scratch/docs/use_cases/code/"},{"type":"link","label":"Extraction","href":"/langchain-docs-scratch/docs/use_cases/extraction","docId":"use_cases/extraction"},{"type":"category","label":"Multi-modal","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"image_agent","href":"/langchain-docs-scratch/docs/use_cases/multi_modal/image_agent","docId":"use_cases/multi_modal/image_agent"}]},{"type":"category","label":"Question answering over documents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Question answering over a group chat messages","href":"/langchain-docs-scratch/docs/use_cases/question_answering/semantic-search-over-chat","docId":"use_cases/question_answering/semantic-search-over-chat"}],"href":"/langchain-docs-scratch/docs/use_cases/question_answering/"},{"type":"link","label":"Summarization","href":"/langchain-docs-scratch/docs/use_cases/summarization","docId":"use_cases/summarization"},{"type":"link","label":"Analyzing structured data","href":"/langchain-docs-scratch/docs/use_cases/tabular","docId":"use_cases/tabular"}],"collapsible":true,"href":"/langchain-docs-scratch/docs/use_cases"},{"type":"category","label":"Guides","collapsed":true,"items":[{"type":"category","label":"Evaluation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Agent Benchmarking: Search + Calculator","href":"/langchain-docs-scratch/docs/guides/evaluation/agent_benchmarking","docId":"guides/evaluation/agent_benchmarking"},{"type":"link","label":"Agent VectorDB Question Answering Benchmarking","href":"/langchain-docs-scratch/docs/guides/evaluation/agent_vectordb_sota_pg","docId":"guides/evaluation/agent_vectordb_sota_pg"},{"type":"link","label":"Benchmarking Template","href":"/langchain-docs-scratch/docs/guides/evaluation/benchmarking_template","docId":"guides/evaluation/benchmarking_template"},{"type":"link","label":"Data Augmented Question Answering","href":"/langchain-docs-scratch/docs/guides/evaluation/data_augmented_question_answering","docId":"guides/evaluation/data_augmented_question_answering"},{"type":"link","label":"Generic Agent Evaluation","href":"/langchain-docs-scratch/docs/guides/evaluation/generic_agent_evaluation","docId":"guides/evaluation/generic_agent_evaluation"},{"type":"link","label":"Using Hugging Face Datasets","href":"/langchain-docs-scratch/docs/guides/evaluation/huggingface_datasets","docId":"guides/evaluation/huggingface_datasets"},{"type":"link","label":"LLM Math","href":"/langchain-docs-scratch/docs/guides/evaluation/llm_math","docId":"guides/evaluation/llm_math"},{"type":"link","label":"Evaluating an OpenAPI Chain","href":"/langchain-docs-scratch/docs/guides/evaluation/openapi_eval","docId":"guides/evaluation/openapi_eval"},{"type":"link","label":"Question Answering Benchmarking: Paul Graham Essay","href":"/langchain-docs-scratch/docs/guides/evaluation/qa_benchmarking_pg","docId":"guides/evaluation/qa_benchmarking_pg"},{"type":"link","label":"Question Answering Benchmarking: State of the Union Address","href":"/langchain-docs-scratch/docs/guides/evaluation/qa_benchmarking_sota","docId":"guides/evaluation/qa_benchmarking_sota"},{"type":"link","label":"QA Generation","href":"/langchain-docs-scratch/docs/guides/evaluation/qa_generation","docId":"guides/evaluation/qa_generation"},{"type":"link","label":"Question Answering","href":"/langchain-docs-scratch/docs/guides/evaluation/question_answering","docId":"guides/evaluation/question_answering"},{"type":"link","label":"SQL Question Answering Benchmarking: Chinook","href":"/langchain-docs-scratch/docs/guides/evaluation/sql_qa_benchmarking_chinook","docId":"guides/evaluation/sql_qa_benchmarking_chinook"}],"href":"/langchain-docs-scratch/docs/guides/evaluation/"},{"type":"link","label":"Model Comparison","href":"/langchain-docs-scratch/docs/guides/model_laboratory","docId":"guides/model_laboratory"},{"type":"category","label":"Tracing","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Tracing Walkthrough","href":"/langchain-docs-scratch/docs/guides/tracing/agent_with_tracing","docId":"guides/tracing/agent_with_tracing"}],"href":"/langchain-docs-scratch/docs/guides/tracing/"}],"collapsible":true,"href":"/langchain-docs-scratch/docs/guides"},{"type":"category","label":"Ecosystem","collapsed":true,"items":[{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"WandB Tracing","href":"/langchain-docs-scratch/docs/ecosystem/integrations/agent_with_wandb_tracing","docId":"ecosystem/integrations/agent_with_wandb_tracing"},{"type":"link","label":"AI21 Labs","href":"/langchain-docs-scratch/docs/ecosystem/integrations/ai21","docId":"ecosystem/integrations/ai21"},{"type":"link","label":"Aim","href":"/langchain-docs-scratch/docs/ecosystem/integrations/aim_tracking","docId":"ecosystem/integrations/aim_tracking"},{"type":"link","label":"Airbyte","href":"/langchain-docs-scratch/docs/ecosystem/integrations/airbyte","docId":"ecosystem/integrations/airbyte"},{"type":"link","label":"Aleph Alpha","href":"/langchain-docs-scratch/docs/ecosystem/integrations/aleph_alpha","docId":"ecosystem/integrations/aleph_alpha"},{"type":"link","label":"AnalyticDB","href":"/langchain-docs-scratch/docs/ecosystem/integrations/analyticdb","docId":"ecosystem/integrations/analyticdb"},{"type":"link","label":"Annoy","href":"/langchain-docs-scratch/docs/ecosystem/integrations/annoy","docId":"ecosystem/integrations/annoy"},{"type":"link","label":"Anyscale","href":"/langchain-docs-scratch/docs/ecosystem/integrations/anyscale","docId":"ecosystem/integrations/anyscale"},{"type":"link","label":"Apify","href":"/langchain-docs-scratch/docs/ecosystem/integrations/apify","docId":"ecosystem/integrations/apify"},{"type":"link","label":"Argilla","href":"/langchain-docs-scratch/docs/ecosystem/integrations/argilla","docId":"ecosystem/integrations/argilla"},{"type":"link","label":"Arxiv","href":"/langchain-docs-scratch/docs/ecosystem/integrations/arxiv","docId":"ecosystem/integrations/arxiv"},{"type":"link","label":"AtlasDB","href":"/langchain-docs-scratch/docs/ecosystem/integrations/atlas","docId":"ecosystem/integrations/atlas"},{"type":"link","label":"AWS S3 Directory","href":"/langchain-docs-scratch/docs/ecosystem/integrations/aws_s3","docId":"ecosystem/integrations/aws_s3"},{"type":"link","label":"AZLyrics","href":"/langchain-docs-scratch/docs/ecosystem/integrations/azlyrics","docId":"ecosystem/integrations/azlyrics"},{"type":"link","label":"Azure Blob Storage","href":"/langchain-docs-scratch/docs/ecosystem/integrations/azure_blob_storage","docId":"ecosystem/integrations/azure_blob_storage"},{"type":"link","label":"Azure Cognitive Search","href":"/langchain-docs-scratch/docs/ecosystem/integrations/azure_cognitive_search_","docId":"ecosystem/integrations/azure_cognitive_search_"},{"type":"link","label":"Azure OpenAI","href":"/langchain-docs-scratch/docs/ecosystem/integrations/azure_openai","docId":"ecosystem/integrations/azure_openai"},{"type":"link","label":"Banana","href":"/langchain-docs-scratch/docs/ecosystem/integrations/bananadev","docId":"ecosystem/integrations/bananadev"},{"type":"link","label":"Beam","href":"/langchain-docs-scratch/docs/ecosystem/integrations/beam","docId":"ecosystem/integrations/beam"},{"type":"link","label":"Bedrock","href":"/langchain-docs-scratch/docs/ecosystem/integrations/bedrock","docId":"ecosystem/integrations/bedrock"},{"type":"link","label":"BiliBili","href":"/langchain-docs-scratch/docs/ecosystem/integrations/bilibili","docId":"ecosystem/integrations/bilibili"},{"type":"link","label":"Blackboard","href":"/langchain-docs-scratch/docs/ecosystem/integrations/blackboard","docId":"ecosystem/integrations/blackboard"},{"type":"link","label":"Cassandra","href":"/langchain-docs-scratch/docs/ecosystem/integrations/cassandra","docId":"ecosystem/integrations/cassandra"},{"type":"link","label":"CerebriumAI","href":"/langchain-docs-scratch/docs/ecosystem/integrations/cerebriumai","docId":"ecosystem/integrations/cerebriumai"},{"type":"link","label":"Chroma","href":"/langchain-docs-scratch/docs/ecosystem/integrations/chroma","docId":"ecosystem/integrations/chroma"},{"type":"link","label":"ClearML","href":"/langchain-docs-scratch/docs/ecosystem/integrations/clearml_tracking","docId":"ecosystem/integrations/clearml_tracking"},{"type":"link","label":"Cohere","href":"/langchain-docs-scratch/docs/ecosystem/integrations/cohere","docId":"ecosystem/integrations/cohere"},{"type":"link","label":"College Confidential","href":"/langchain-docs-scratch/docs/ecosystem/integrations/college_confidential","docId":"ecosystem/integrations/college_confidential"},{"type":"link","label":"Comet","href":"/langchain-docs-scratch/docs/ecosystem/integrations/comet_tracking","docId":"ecosystem/integrations/comet_tracking"},{"type":"link","label":"Confluence","href":"/langchain-docs-scratch/docs/ecosystem/integrations/confluence","docId":"ecosystem/integrations/confluence"},{"type":"link","label":"C Transformers","href":"/langchain-docs-scratch/docs/ecosystem/integrations/ctransformers","docId":"ecosystem/integrations/ctransformers"},{"type":"link","label":"Databerry","href":"/langchain-docs-scratch/docs/ecosystem/integrations/databerry","docId":"ecosystem/integrations/databerry"},{"type":"link","label":"Databricks","href":"/langchain-docs-scratch/docs/ecosystem/integrations/databricks","docId":"ecosystem/integrations/databricks"},{"type":"link","label":"DeepInfra","href":"/langchain-docs-scratch/docs/ecosystem/integrations/deepinfra","docId":"ecosystem/integrations/deepinfra"},{"type":"link","label":"Deep Lake","href":"/langchain-docs-scratch/docs/ecosystem/integrations/deeplake","docId":"ecosystem/integrations/deeplake"},{"type":"link","label":"Diffbot","href":"/langchain-docs-scratch/docs/ecosystem/integrations/diffbot","docId":"ecosystem/integrations/diffbot"},{"type":"link","label":"Discord","href":"/langchain-docs-scratch/docs/ecosystem/integrations/discord","docId":"ecosystem/integrations/discord"},{"type":"link","label":"Docugami","href":"/langchain-docs-scratch/docs/ecosystem/integrations/docugami","docId":"ecosystem/integrations/docugami"},{"type":"link","label":"DuckDB","href":"/langchain-docs-scratch/docs/ecosystem/integrations/duckdb","docId":"ecosystem/integrations/duckdb"},{"type":"link","label":"Elasticsearch","href":"/langchain-docs-scratch/docs/ecosystem/integrations/elasticsearch","docId":"ecosystem/integrations/elasticsearch"},{"type":"link","label":"EverNote","href":"/langchain-docs-scratch/docs/ecosystem/integrations/evernote","docId":"ecosystem/integrations/evernote"},{"type":"link","label":"Facebook Chat","href":"/langchain-docs-scratch/docs/ecosystem/integrations/facebook_chat","docId":"ecosystem/integrations/facebook_chat"},{"type":"link","label":"Figma","href":"/langchain-docs-scratch/docs/ecosystem/integrations/figma","docId":"ecosystem/integrations/figma"},{"type":"link","label":"ForefrontAI","href":"/langchain-docs-scratch/docs/ecosystem/integrations/forefrontai","docId":"ecosystem/integrations/forefrontai"},{"type":"link","label":"Git","href":"/langchain-docs-scratch/docs/ecosystem/integrations/git","docId":"ecosystem/integrations/git"},{"type":"link","label":"GitBook","href":"/langchain-docs-scratch/docs/ecosystem/integrations/gitbook","docId":"ecosystem/integrations/gitbook"},{"type":"link","label":"Google BigQuery","href":"/langchain-docs-scratch/docs/ecosystem/integrations/google_bigquery","docId":"ecosystem/integrations/google_bigquery"},{"type":"link","label":"Google Cloud Storage","href":"/langchain-docs-scratch/docs/ecosystem/integrations/google_cloud_storage","docId":"ecosystem/integrations/google_cloud_storage"},{"type":"link","label":"Google Drive","href":"/langchain-docs-scratch/docs/ecosystem/integrations/google_drive","docId":"ecosystem/integrations/google_drive"},{"type":"link","label":"Google Search","href":"/langchain-docs-scratch/docs/ecosystem/integrations/google_search","docId":"ecosystem/integrations/google_search"},{"type":"link","label":"Google Serper","href":"/langchain-docs-scratch/docs/ecosystem/integrations/google_serper","docId":"ecosystem/integrations/google_serper"},{"type":"link","label":"GooseAI","href":"/langchain-docs-scratch/docs/ecosystem/integrations/gooseai","docId":"ecosystem/integrations/gooseai"},{"type":"link","label":"GPT4All","href":"/langchain-docs-scratch/docs/ecosystem/integrations/gpt4all","docId":"ecosystem/integrations/gpt4all"},{"type":"link","label":"Graphsignal","href":"/langchain-docs-scratch/docs/ecosystem/integrations/graphsignal","docId":"ecosystem/integrations/graphsignal"},{"type":"link","label":"Gutenberg","href":"/langchain-docs-scratch/docs/ecosystem/integrations/gutenberg","docId":"ecosystem/integrations/gutenberg"},{"type":"link","label":"Hacker News","href":"/langchain-docs-scratch/docs/ecosystem/integrations/hacker_news","docId":"ecosystem/integrations/hacker_news"},{"type":"link","label":"Hazy Research","href":"/langchain-docs-scratch/docs/ecosystem/integrations/hazy_research","docId":"ecosystem/integrations/hazy_research"},{"type":"link","label":"Helicone","href":"/langchain-docs-scratch/docs/ecosystem/integrations/helicone","docId":"ecosystem/integrations/helicone"},{"type":"link","label":"Hugging Face","href":"/langchain-docs-scratch/docs/ecosystem/integrations/huggingface","docId":"ecosystem/integrations/huggingface"},{"type":"link","label":"iFixit","href":"/langchain-docs-scratch/docs/ecosystem/integrations/ifixit","docId":"ecosystem/integrations/ifixit"},{"type":"link","label":"IMSDb","href":"/langchain-docs-scratch/docs/ecosystem/integrations/imsdb","docId":"ecosystem/integrations/imsdb"},{"type":"link","label":"Jina","href":"/langchain-docs-scratch/docs/ecosystem/integrations/jina","docId":"ecosystem/integrations/jina"},{"type":"link","label":"LanceDB","href":"/langchain-docs-scratch/docs/ecosystem/integrations/lancedb","docId":"ecosystem/integrations/lancedb"},{"type":"link","label":"Llama.cpp","href":"/langchain-docs-scratch/docs/ecosystem/integrations/llamacpp","docId":"ecosystem/integrations/llamacpp"},{"type":"link","label":"MediaWikiDump","href":"/langchain-docs-scratch/docs/ecosystem/integrations/mediawikidump","docId":"ecosystem/integrations/mediawikidump"},{"type":"link","label":"Metal","href":"/langchain-docs-scratch/docs/ecosystem/integrations/metal","docId":"ecosystem/integrations/metal"},{"type":"link","label":"Microsoft OneDrive","href":"/langchain-docs-scratch/docs/ecosystem/integrations/microsoft_onedrive","docId":"ecosystem/integrations/microsoft_onedrive"},{"type":"link","label":"Microsoft PowerPoint","href":"/langchain-docs-scratch/docs/ecosystem/integrations/microsoft_powerpoint","docId":"ecosystem/integrations/microsoft_powerpoint"},{"type":"link","label":"Microsoft Word","href":"/langchain-docs-scratch/docs/ecosystem/integrations/microsoft_word","docId":"ecosystem/integrations/microsoft_word"},{"type":"link","label":"Milvus","href":"/langchain-docs-scratch/docs/ecosystem/integrations/milvus","docId":"ecosystem/integrations/milvus"},{"type":"link","label":"MLflow","href":"/langchain-docs-scratch/docs/ecosystem/integrations/mlflow_tracking","docId":"ecosystem/integrations/mlflow_tracking"},{"type":"link","label":"Modal","href":"/langchain-docs-scratch/docs/ecosystem/integrations/modal","docId":"ecosystem/integrations/modal"},{"type":"link","label":"ModelScope","href":"/langchain-docs-scratch/docs/ecosystem/integrations/modelscope","docId":"ecosystem/integrations/modelscope"},{"type":"link","label":"Modern Treasury","href":"/langchain-docs-scratch/docs/ecosystem/integrations/modern_treasury","docId":"ecosystem/integrations/modern_treasury"},{"type":"link","label":"Momento","href":"/langchain-docs-scratch/docs/ecosystem/integrations/momento","docId":"ecosystem/integrations/momento"},{"type":"link","label":"MyScale","href":"/langchain-docs-scratch/docs/ecosystem/integrations/myscale","docId":"ecosystem/integrations/myscale"},{"type":"link","label":"NLPCloud","href":"/langchain-docs-scratch/docs/ecosystem/integrations/nlpcloud","docId":"ecosystem/integrations/nlpcloud"},{"type":"link","label":"Notion DB","href":"/langchain-docs-scratch/docs/ecosystem/integrations/notion","docId":"ecosystem/integrations/notion"},{"type":"link","label":"Obsidian","href":"/langchain-docs-scratch/docs/ecosystem/integrations/obsidian","docId":"ecosystem/integrations/obsidian"},{"type":"link","label":"OpenAI","href":"/langchain-docs-scratch/docs/ecosystem/integrations/openai","docId":"ecosystem/integrations/openai"},{"type":"link","label":"OpenSearch","href":"/langchain-docs-scratch/docs/ecosystem/integrations/opensearch","docId":"ecosystem/integrations/opensearch"},{"type":"link","label":"OpenWeatherMap","href":"/langchain-docs-scratch/docs/ecosystem/integrations/openweathermap","docId":"ecosystem/integrations/openweathermap"},{"type":"link","label":"Petals","href":"/langchain-docs-scratch/docs/ecosystem/integrations/petals","docId":"ecosystem/integrations/petals"},{"type":"link","label":"PGVector","href":"/langchain-docs-scratch/docs/ecosystem/integrations/pgvector","docId":"ecosystem/integrations/pgvector"},{"type":"link","label":"Pinecone","href":"/langchain-docs-scratch/docs/ecosystem/integrations/pinecone","docId":"ecosystem/integrations/pinecone"},{"type":"link","label":"PipelineAI","href":"/langchain-docs-scratch/docs/ecosystem/integrations/pipelineai","docId":"ecosystem/integrations/pipelineai"},{"type":"link","label":"Prediction Guard","href":"/langchain-docs-scratch/docs/ecosystem/integrations/predictionguard","docId":"ecosystem/integrations/predictionguard"},{"type":"link","label":"PromptLayer","href":"/langchain-docs-scratch/docs/ecosystem/integrations/promptlayer","docId":"ecosystem/integrations/promptlayer"},{"type":"link","label":"Psychic","href":"/langchain-docs-scratch/docs/ecosystem/integrations/psychic","docId":"ecosystem/integrations/psychic"},{"type":"link","label":"Qdrant","href":"/langchain-docs-scratch/docs/ecosystem/integrations/qdrant","docId":"ecosystem/integrations/qdrant"},{"type":"link","label":"Rebuff","href":"/langchain-docs-scratch/docs/ecosystem/integrations/rebuff","docId":"ecosystem/integrations/rebuff"},{"type":"link","label":"Reddit","href":"/langchain-docs-scratch/docs/ecosystem/integrations/reddit","docId":"ecosystem/integrations/reddit"},{"type":"link","label":"Redis","href":"/langchain-docs-scratch/docs/ecosystem/integrations/redis","docId":"ecosystem/integrations/redis"},{"type":"link","label":"Replicate","href":"/langchain-docs-scratch/docs/ecosystem/integrations/replicate","docId":"ecosystem/integrations/replicate"},{"type":"link","label":"Roam","href":"/langchain-docs-scratch/docs/ecosystem/integrations/roam","docId":"ecosystem/integrations/roam"},{"type":"link","label":"Runhouse","href":"/langchain-docs-scratch/docs/ecosystem/integrations/runhouse","docId":"ecosystem/integrations/runhouse"},{"type":"link","label":"RWKV-4","href":"/langchain-docs-scratch/docs/ecosystem/integrations/rwkv","docId":"ecosystem/integrations/rwkv"},{"type":"link","label":"SageMaker Endpoint","href":"/langchain-docs-scratch/docs/ecosystem/integrations/sagemaker_endpoint","docId":"ecosystem/integrations/sagemaker_endpoint"},{"type":"link","label":"SearxNG Search API","href":"/langchain-docs-scratch/docs/ecosystem/integrations/searx","docId":"ecosystem/integrations/searx"},{"type":"link","label":"SerpAPI","href":"/langchain-docs-scratch/docs/ecosystem/integrations/serpapi","docId":"ecosystem/integrations/serpapi"},{"type":"link","label":"scikit-learn","href":"/langchain-docs-scratch/docs/ecosystem/integrations/sklearn","docId":"ecosystem/integrations/sklearn"},{"type":"link","label":"Slack","href":"/langchain-docs-scratch/docs/ecosystem/integrations/slack","docId":"ecosystem/integrations/slack"},{"type":"link","label":"spaCy","href":"/langchain-docs-scratch/docs/ecosystem/integrations/spacy","docId":"ecosystem/integrations/spacy"},{"type":"link","label":"Spreedly","href":"/langchain-docs-scratch/docs/ecosystem/integrations/spreedly","docId":"ecosystem/integrations/spreedly"},{"type":"link","label":"StochasticAI","href":"/langchain-docs-scratch/docs/ecosystem/integrations/stochasticai","docId":"ecosystem/integrations/stochasticai"},{"type":"link","label":"Stripe","href":"/langchain-docs-scratch/docs/ecosystem/integrations/stripe","docId":"ecosystem/integrations/stripe"},{"type":"link","label":"Tair","href":"/langchain-docs-scratch/docs/ecosystem/integrations/tair","docId":"ecosystem/integrations/tair"},{"type":"link","label":"Telegram","href":"/langchain-docs-scratch/docs/ecosystem/integrations/telegram","docId":"ecosystem/integrations/telegram"},{"type":"link","label":"2Markdown","href":"/langchain-docs-scratch/docs/ecosystem/integrations/tomarkdown","docId":"ecosystem/integrations/tomarkdown"},{"type":"link","label":"Trello","href":"/langchain-docs-scratch/docs/ecosystem/integrations/trello","docId":"ecosystem/integrations/trello"},{"type":"link","label":"Twitter","href":"/langchain-docs-scratch/docs/ecosystem/integrations/twitter","docId":"ecosystem/integrations/twitter"},{"type":"link","label":"Unstructured","href":"/langchain-docs-scratch/docs/ecosystem/integrations/unstructured","docId":"ecosystem/integrations/unstructured"},{"type":"category","label":"vectara","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Chat Over Documents with Vectara","href":"/langchain-docs-scratch/docs/ecosystem/integrations/vectara/vectara_chat","docId":"ecosystem/integrations/vectara/vectara_chat"},{"type":"link","label":"Vectara Text Generation","href":"/langchain-docs-scratch/docs/ecosystem/integrations/vectara/vectara_text_generation","docId":"ecosystem/integrations/vectara/vectara_text_generation"}]},{"type":"link","label":"Vectara","href":"/langchain-docs-scratch/docs/ecosystem/integrations/vectara","docId":"ecosystem/integrations/vectara"},{"type":"link","label":"Vespa","href":"/langchain-docs-scratch/docs/ecosystem/integrations/vespa","docId":"ecosystem/integrations/vespa"},{"type":"link","label":"Weights & Biases","href":"/langchain-docs-scratch/docs/ecosystem/integrations/wandb_tracking","docId":"ecosystem/integrations/wandb_tracking"},{"type":"link","label":"Weather","href":"/langchain-docs-scratch/docs/ecosystem/integrations/weather","docId":"ecosystem/integrations/weather"},{"type":"link","label":"Weaviate","href":"/langchain-docs-scratch/docs/ecosystem/integrations/weaviate","docId":"ecosystem/integrations/weaviate"},{"type":"link","label":"WhatsApp","href":"/langchain-docs-scratch/docs/ecosystem/integrations/whatsapp","docId":"ecosystem/integrations/whatsapp"},{"type":"link","label":"WhyLabs","href":"/langchain-docs-scratch/docs/ecosystem/integrations/whylabs_profiling","docId":"ecosystem/integrations/whylabs_profiling"},{"type":"link","label":"Wikipedia","href":"/langchain-docs-scratch/docs/ecosystem/integrations/wikipedia","docId":"ecosystem/integrations/wikipedia"},{"type":"link","label":"Wolfram Alpha","href":"/langchain-docs-scratch/docs/ecosystem/integrations/wolfram_alpha","docId":"ecosystem/integrations/wolfram_alpha"},{"type":"link","label":"Writer","href":"/langchain-docs-scratch/docs/ecosystem/integrations/writer","docId":"ecosystem/integrations/writer"},{"type":"link","label":"Yeager.ai","href":"/langchain-docs-scratch/docs/ecosystem/integrations/yeagerai","docId":"ecosystem/integrations/yeagerai"},{"type":"link","label":"YouTube","href":"/langchain-docs-scratch/docs/ecosystem/integrations/youtube","docId":"ecosystem/integrations/youtube"},{"type":"link","label":"Zep","href":"/langchain-docs-scratch/docs/ecosystem/integrations/zep","docId":"ecosystem/integrations/zep"},{"type":"link","label":"Zilliz","href":"/langchain-docs-scratch/docs/ecosystem/integrations/zilliz","docId":"ecosystem/integrations/zilliz"}],"href":"/langchain-docs-scratch/docs/ecosystem/integrations/"},{"type":"link","label":"Dependents","href":"/langchain-docs-scratch/docs/ecosystem/dependents","docId":"ecosystem/dependents"},{"type":"link","label":"Deployments","href":"/langchain-docs-scratch/docs/ecosystem/deployments","docId":"ecosystem/deployments"},{"type":"link","label":"YouTube tutorials","href":"/langchain-docs-scratch/docs/ecosystem/youtube","docId":"ecosystem/youtube"},{"type":"link","label":"Gallery","href":"https://github.com/kyrolabs/awesome-langchain"}],"collapsible":true,"href":"/langchain-docs-scratch/docs/ecosystem"}]},"docs":{"ecosystem/dependents":{"id":"ecosystem/dependents","title":"Dependents","description":"Dependents stats for hwchase17/langchain","sidebar":"sidebar"},"ecosystem/deployments":{"id":"ecosystem/deployments","title":"Deployments","description":"So, you\'ve created a really cool chain - now what? How do you deploy it and make it easily shareable with the world?","sidebar":"sidebar"},"ecosystem/integrations/agent_with_wandb_tracing":{"id":"ecosystem/integrations/agent_with_wandb_tracing","title":"WandB Tracing","description":"There are two recommended ways to trace your LangChains:","sidebar":"sidebar"},"ecosystem/integrations/ai21":{"id":"ecosystem/integrations/ai21","title":"AI21 Labs","description":"This page covers how to use the AI21 ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/aim_tracking":{"id":"ecosystem/integrations/aim_tracking","title":"Aim","description":"Aim makes it super easy to visualize and debug LangChain executions. Aim tracks inputs and outputs of LLMs and tools, as well as actions of agents.","sidebar":"sidebar"},"ecosystem/integrations/airbyte":{"id":"ecosystem/integrations/airbyte","title":"Airbyte","description":"Airbyte is a data integration platform for ELT pipelines from APIs,","sidebar":"sidebar"},"ecosystem/integrations/aleph_alpha":{"id":"ecosystem/integrations/aleph_alpha","title":"Aleph Alpha","description":"Aleph Alpha was founded in 2019 with the mission to research and build the foundational technology for an era of strong AI. The team of international scientists, engineers, and innovators researches, develops, and deploys transformative AI like large language and multimodal models and runs the fastest European commercial AI cluster.","sidebar":"sidebar"},"ecosystem/integrations/analyticdb":{"id":"ecosystem/integrations/analyticdb","title":"AnalyticDB","description":"This page covers how to use the AnalyticDB ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/annoy":{"id":"ecosystem/integrations/annoy","title":"Annoy","description":"Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mmapped into memory so that many processes may share the same data.","sidebar":"sidebar"},"ecosystem/integrations/anyscale":{"id":"ecosystem/integrations/anyscale","title":"Anyscale","description":"This page covers how to use the Anyscale ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/apify":{"id":"ecosystem/integrations/apify","title":"Apify","description":"This page covers how to use Apify within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/argilla":{"id":"ecosystem/integrations/argilla","title":"Argilla","description":"Argilla - Open-source data platform for LLMs","sidebar":"sidebar"},"ecosystem/integrations/arxiv":{"id":"ecosystem/integrations/arxiv","title":"Arxiv","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics,","sidebar":"sidebar"},"ecosystem/integrations/atlas":{"id":"ecosystem/integrations/atlas","title":"AtlasDB","description":"This page covers how to use Nomic\'s Atlas ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/aws_s3":{"id":"ecosystem/integrations/aws_s3","title":"AWS S3 Directory","description":"Amazon Simple Storage Service (Amazon S3) is an object storage service.","sidebar":"sidebar"},"ecosystem/integrations/azlyrics":{"id":"ecosystem/integrations/azlyrics","title":"AZLyrics","description":"AZLyrics is a large, legal, every day growing collection of lyrics.","sidebar":"sidebar"},"ecosystem/integrations/azure_blob_storage":{"id":"ecosystem/integrations/azure_blob_storage","title":"Azure Blob Storage","description":"Azure Blob Storage is Microsoft\'s object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn\'t adhere to a particular data model or definition, such as text or binary data.","sidebar":"sidebar"},"ecosystem/integrations/azure_cognitive_search_":{"id":"ecosystem/integrations/azure_cognitive_search_","title":"Azure Cognitive Search","description":"Azure Cognitive Search (formerly known as Azure Search) is a cloud search service that gives developers infrastructure, APIs, and tools for building a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.","sidebar":"sidebar"},"ecosystem/integrations/azure_openai":{"id":"ecosystem/integrations/azure_openai","title":"Azure OpenAI","description":"Microsoft Azure, often referred to as Azure is a cloud computing platform run by Microsoft, which offers access, management, and development of applications and services through global data centers. It provides a range of capabilities, including software as a service (SaaS), platform as a service (PaaS), and infrastructure as a service (IaaS). Microsoft Azure supports many programming languages, tools, and frameworks, including Microsoft-specific and third-party software and systems.","sidebar":"sidebar"},"ecosystem/integrations/bananadev":{"id":"ecosystem/integrations/bananadev","title":"Banana","description":"This page covers how to use the Banana ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/beam":{"id":"ecosystem/integrations/beam","title":"Beam","description":"This page covers how to use Beam within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/bedrock":{"id":"ecosystem/integrations/bedrock","title":"Bedrock","description":"Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case.","sidebar":"sidebar"},"ecosystem/integrations/bilibili":{"id":"ecosystem/integrations/bilibili","title":"BiliBili","description":"Bilibili is one of the most beloved long-form video sites in China.","sidebar":"sidebar"},"ecosystem/integrations/blackboard":{"id":"ecosystem/integrations/blackboard","title":"Blackboard","description":"Blackboard Learn (previously the Blackboard Learning Management System)","sidebar":"sidebar"},"ecosystem/integrations/cassandra":{"id":"ecosystem/integrations/cassandra","title":"Cassandra","description":"Cassandra is a free and open-source, distributed, wide-column","sidebar":"sidebar"},"ecosystem/integrations/cerebriumai":{"id":"ecosystem/integrations/cerebriumai","title":"CerebriumAI","description":"This page covers how to use the CerebriumAI ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/chroma":{"id":"ecosystem/integrations/chroma","title":"Chroma","description":"Chroma is a database for building AI applications with embeddings.","sidebar":"sidebar"},"ecosystem/integrations/clearml_tracking":{"id":"ecosystem/integrations/clearml_tracking","title":"ClearML","description":"ClearML is a ML/DL development and production suite, it contains 5 main modules:","sidebar":"sidebar"},"ecosystem/integrations/cohere":{"id":"ecosystem/integrations/cohere","title":"Cohere","description":"Cohere is a Canadian startup that provides natural language processing models","sidebar":"sidebar"},"ecosystem/integrations/college_confidential":{"id":"ecosystem/integrations/college_confidential","title":"College Confidential","description":"College Confidential gives information on 3,800+ colleges and universities.","sidebar":"sidebar"},"ecosystem/integrations/comet_tracking":{"id":"ecosystem/integrations/comet_tracking","title":"Comet","description":"In this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.","sidebar":"sidebar"},"ecosystem/integrations/confluence":{"id":"ecosystem/integrations/confluence","title":"Confluence","description":"Confluence is a wiki collaboration platform that saves and organizes all of the project-related material. Confluence is a knowledge base that primarily handles content management activities.","sidebar":"sidebar"},"ecosystem/integrations/ctransformers":{"id":"ecosystem/integrations/ctransformers","title":"C Transformers","description":"This page covers how to use the C Transformers library within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/databerry":{"id":"ecosystem/integrations/databerry","title":"Databerry","description":"Databerry is an open source document retrieval platform that helps to connect your personal data with Large Language Models.","sidebar":"sidebar"},"ecosystem/integrations/databricks":{"id":"ecosystem/integrations/databricks","title":"Databricks","description":"This notebook covers how to connect to the Databricks runtimes and Databricks SQL using the SQLDatabase wrapper of LangChain.","sidebar":"sidebar"},"ecosystem/integrations/deepinfra":{"id":"ecosystem/integrations/deepinfra","title":"DeepInfra","description":"This page covers how to use the DeepInfra ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/deeplake":{"id":"ecosystem/integrations/deeplake","title":"Deep Lake","description":"This page covers how to use the Deep Lake ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/diffbot":{"id":"ecosystem/integrations/diffbot","title":"Diffbot","description":"Diffbot is a service to read web pages. Unlike traditional web scraping tools,","sidebar":"sidebar"},"ecosystem/integrations/discord":{"id":"ecosystem/integrations/discord","title":"Discord","description":"Discord is a VoIP and instant messaging social platform. Users have the ability to communicate","sidebar":"sidebar"},"ecosystem/integrations/docugami":{"id":"ecosystem/integrations/docugami","title":"Docugami","description":"Docugami converts business documents into a Document XML Knowledge Graph, generating forests","sidebar":"sidebar"},"ecosystem/integrations/duckdb":{"id":"ecosystem/integrations/duckdb","title":"DuckDB","description":"DuckDB is an in-process SQL OLAP database management system.","sidebar":"sidebar"},"ecosystem/integrations/elasticsearch":{"id":"ecosystem/integrations/elasticsearch","title":"Elasticsearch","description":"Elasticsearch is a distributed, RESTful search and analytics engine.","sidebar":"sidebar"},"ecosystem/integrations/evernote":{"id":"ecosystem/integrations/evernote","title":"EverNote","description":"EverNote is intended for archiving and creating notes in which photos, audio and saved web content can be embedded. Notes are stored in virtual \\"notebooks\\" and can be tagged, annotated, edited, searched, and exported.","sidebar":"sidebar"},"ecosystem/integrations/facebook_chat":{"id":"ecosystem/integrations/facebook_chat","title":"Facebook Chat","description":"Messenger) is an American proprietary instant messaging app and","sidebar":"sidebar"},"ecosystem/integrations/figma":{"id":"ecosystem/integrations/figma","title":"Figma","description":"Figma is a collaborative web application for interface design.","sidebar":"sidebar"},"ecosystem/integrations/forefrontai":{"id":"ecosystem/integrations/forefrontai","title":"ForefrontAI","description":"This page covers how to use the ForefrontAI ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/git":{"id":"ecosystem/integrations/git","title":"Git","description":"Git is a distributed version control system that tracks changes in any set of computer files, usually used for coordinating work among programmers collaboratively developing source code during software development.","sidebar":"sidebar"},"ecosystem/integrations/gitbook":{"id":"ecosystem/integrations/gitbook","title":"GitBook","description":"GitBook is a modern documentation platform where teams can document everything from products to internal knowledge bases and APIs.","sidebar":"sidebar"},"ecosystem/integrations/google_bigquery":{"id":"ecosystem/integrations/google_bigquery","title":"Google BigQuery","description":"Google BigQuery is a serverless and cost-effective enterprise data warehouse that works across clouds and scales with your data.","sidebar":"sidebar"},"ecosystem/integrations/google_cloud_storage":{"id":"ecosystem/integrations/google_cloud_storage","title":"Google Cloud Storage","description":"Google Cloud Storage is a managed service for storing unstructured data.","sidebar":"sidebar"},"ecosystem/integrations/google_drive":{"id":"ecosystem/integrations/google_drive","title":"Google Drive","description":"Google Drive is a file storage and synchronization service developed by Google.","sidebar":"sidebar"},"ecosystem/integrations/google_search":{"id":"ecosystem/integrations/google_search","title":"Google Search","description":"This page covers how to use the Google Search API within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/google_serper":{"id":"ecosystem/integrations/google_serper","title":"Google Serper","description":"This page covers how to use the Serper Google Search API within LangChain. Serper is a low-cost Google Search API that can be used to add answer box, knowledge graph, and organic results data from Google Search.","sidebar":"sidebar"},"ecosystem/integrations/gooseai":{"id":"ecosystem/integrations/gooseai","title":"GooseAI","description":"This page covers how to use the GooseAI ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/gpt4all":{"id":"ecosystem/integrations/gpt4all","title":"GPT4All","description":"This page covers how to use the GPT4All wrapper within LangChain. The tutorial is divided into two parts: installation and setup, followed by usage with an example.","sidebar":"sidebar"},"ecosystem/integrations/graphsignal":{"id":"ecosystem/integrations/graphsignal","title":"Graphsignal","description":"This page covers how to use Graphsignal to trace and monitor LangChain. Graphsignal enables full visibility into your application. It provides latency breakdowns by chains and tools, exceptions with full context, data monitoring, compute/GPU utilization, OpenAI cost analytics, and more.","sidebar":"sidebar"},"ecosystem/integrations/gutenberg":{"id":"ecosystem/integrations/gutenberg","title":"Gutenberg","description":"Project Gutenberg is an online library of free eBooks.","sidebar":"sidebar"},"ecosystem/integrations/hacker_news":{"id":"ecosystem/integrations/hacker_news","title":"Hacker News","description":"Hacker News (sometimes abbreviated as HN) is a social news","sidebar":"sidebar"},"ecosystem/integrations/hazy_research":{"id":"ecosystem/integrations/hazy_research","title":"Hazy Research","description":"This page covers how to use the Hazy Research ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/helicone":{"id":"ecosystem/integrations/helicone","title":"Helicone","description":"This page covers how to use the Helicone ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/huggingface":{"id":"ecosystem/integrations/huggingface","title":"Hugging Face","description":"This page covers how to use the Hugging Face ecosystem (including the Hugging Face Hub) within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/ifixit":{"id":"ecosystem/integrations/ifixit","title":"iFixit","description":"iFixit is the largest, open repair community on the web. The site contains nearly 100k","sidebar":"sidebar"},"ecosystem/integrations/imsdb":{"id":"ecosystem/integrations/imsdb","title":"IMSDb","description":"IMSDb is the Internet Movie Script Database.","sidebar":"sidebar"},"ecosystem/integrations/index":{"id":"ecosystem/integrations/index","title":"Integrations","description":"","sidebar":"sidebar"},"ecosystem/integrations/jina":{"id":"ecosystem/integrations/jina","title":"Jina","description":"This page covers how to use the Jina ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/lancedb":{"id":"ecosystem/integrations/lancedb","title":"LanceDB","description":"This page covers how to use LanceDB within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/llamacpp":{"id":"ecosystem/integrations/llamacpp","title":"Llama.cpp","description":"This page covers how to use llama.cpp within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/mediawikidump":{"id":"ecosystem/integrations/mediawikidump","title":"MediaWikiDump","description":"MediaWiki XML Dumps contain the content of a wiki","sidebar":"sidebar"},"ecosystem/integrations/metal":{"id":"ecosystem/integrations/metal","title":"Metal","description":"This page covers how to use Metal within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/microsoft_onedrive":{"id":"ecosystem/integrations/microsoft_onedrive","title":"Microsoft OneDrive","description":"Microsoft OneDrive (formerly SkyDrive) is a file-hosting service operated by Microsoft.","sidebar":"sidebar"},"ecosystem/integrations/microsoft_powerpoint":{"id":"ecosystem/integrations/microsoft_powerpoint","title":"Microsoft PowerPoint","description":"Microsoft PowerPoint is a presentation program by Microsoft.","sidebar":"sidebar"},"ecosystem/integrations/microsoft_word":{"id":"ecosystem/integrations/microsoft_word","title":"Microsoft Word","description":"Microsoft Word is a word processor developed by Microsoft.","sidebar":"sidebar"},"ecosystem/integrations/milvus":{"id":"ecosystem/integrations/milvus","title":"Milvus","description":"This page covers how to use the Milvus ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/mlflow_tracking":{"id":"ecosystem/integrations/mlflow_tracking","title":"MLflow","description":"This notebook goes over how to track your LangChain experiments into your MLflow Server","sidebar":"sidebar"},"ecosystem/integrations/modal":{"id":"ecosystem/integrations/modal","title":"Modal","description":"This page covers how to use the Modal ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/modelscope":{"id":"ecosystem/integrations/modelscope","title":"ModelScope","description":"This page covers how to use the modelscope ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/modern_treasury":{"id":"ecosystem/integrations/modern_treasury","title":"Modern Treasury","description":"Modern Treasury simplifies complex payment operations. It is a unified platform to power products and processes that move money.","sidebar":"sidebar"},"ecosystem/integrations/momento":{"id":"ecosystem/integrations/momento","title":"Momento","description":"Momento Cache is the world\'s first truly serverless caching service. It provides instant elasticity, scale-to-zero","sidebar":"sidebar"},"ecosystem/integrations/myscale":{"id":"ecosystem/integrations/myscale","title":"MyScale","description":"This page covers how to use MyScale vector database within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/nlpcloud":{"id":"ecosystem/integrations/nlpcloud","title":"NLPCloud","description":"This page covers how to use the NLPCloud ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/notion":{"id":"ecosystem/integrations/notion","title":"Notion DB","description":"Notion is a collaboration platform with modified Markdown support that integrates kanban","sidebar":"sidebar"},"ecosystem/integrations/obsidian":{"id":"ecosystem/integrations/obsidian","title":"Obsidian","description":"Obsidian is a powerful and extensible knowledge base","sidebar":"sidebar"},"ecosystem/integrations/openai":{"id":"ecosystem/integrations/openai","title":"OpenAI","description":"OpenAI is American artificial intelligence (AI) research laboratory","sidebar":"sidebar"},"ecosystem/integrations/opensearch":{"id":"ecosystem/integrations/opensearch","title":"OpenSearch","description":"This page covers how to use the OpenSearch ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/openweathermap":{"id":"ecosystem/integrations/openweathermap","title":"OpenWeatherMap","description":"OpenWeatherMap provides all essential weather data for a specific location:","sidebar":"sidebar"},"ecosystem/integrations/petals":{"id":"ecosystem/integrations/petals","title":"Petals","description":"This page covers how to use the Petals ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/pgvector":{"id":"ecosystem/integrations/pgvector","title":"PGVector","description":"This page covers how to use the Postgres PGVector ecosystem within LangChain","sidebar":"sidebar"},"ecosystem/integrations/pinecone":{"id":"ecosystem/integrations/pinecone","title":"Pinecone","description":"This page covers how to use the Pinecone ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/pipelineai":{"id":"ecosystem/integrations/pipelineai","title":"PipelineAI","description":"This page covers how to use the PipelineAI ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/predictionguard":{"id":"ecosystem/integrations/predictionguard","title":"Prediction Guard","description":"This page covers how to use the Prediction Guard ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/promptlayer":{"id":"ecosystem/integrations/promptlayer","title":"PromptLayer","description":"This page covers how to use PromptLayer within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/psychic":{"id":"ecosystem/integrations/psychic","title":"Psychic","description":"Psychic is a platform for integrating with SaaS tools like Notion, Zendesk,","sidebar":"sidebar"},"ecosystem/integrations/qdrant":{"id":"ecosystem/integrations/qdrant","title":"Qdrant","description":"This page covers how to use the Qdrant ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/rebuff":{"id":"ecosystem/integrations/rebuff","title":"Rebuff","description":"Rebuff is a self-hardening prompt injection detector.","sidebar":"sidebar"},"ecosystem/integrations/reddit":{"id":"ecosystem/integrations/reddit","title":"Reddit","description":"Reddit is an American social news aggregation, content rating, and discussion website.","sidebar":"sidebar"},"ecosystem/integrations/redis":{"id":"ecosystem/integrations/redis","title":"Redis","description":"This page covers how to use the Redis ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/replicate":{"id":"ecosystem/integrations/replicate","title":"Replicate","description":"This page covers how to run models on Replicate within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/roam":{"id":"ecosystem/integrations/roam","title":"Roam","description":"ROAM is a note-taking tool for networked thought, designed to create a personal knowledge base.","sidebar":"sidebar"},"ecosystem/integrations/runhouse":{"id":"ecosystem/integrations/runhouse","title":"Runhouse","description":"This page covers how to use the Runhouse ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/rwkv":{"id":"ecosystem/integrations/rwkv","title":"RWKV-4","description":"This page covers how to use the RWKV-4 wrapper within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/sagemaker_endpoint":{"id":"ecosystem/integrations/sagemaker_endpoint","title":"SageMaker Endpoint","description":"Amazon SageMaker is a system that can build, train, and deploy machine learning (ML) models with fully managed infrastructure, tools, and workflows.","sidebar":"sidebar"},"ecosystem/integrations/searx":{"id":"ecosystem/integrations/searx","title":"SearxNG Search API","description":"This page covers how to use the SearxNG search API within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/serpapi":{"id":"ecosystem/integrations/serpapi","title":"SerpAPI","description":"This page covers how to use the SerpAPI search APIs within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/sklearn":{"id":"ecosystem/integrations/sklearn","title":"scikit-learn","description":"This page covers how to use the scikit-learn package within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/slack":{"id":"ecosystem/integrations/slack","title":"Slack","description":"Slack is an instant messaging program.","sidebar":"sidebar"},"ecosystem/integrations/spacy":{"id":"ecosystem/integrations/spacy","title":"spaCy","description":"spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.","sidebar":"sidebar"},"ecosystem/integrations/spreedly":{"id":"ecosystem/integrations/spreedly","title":"Spreedly","description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","sidebar":"sidebar"},"ecosystem/integrations/stochasticai":{"id":"ecosystem/integrations/stochasticai","title":"StochasticAI","description":"This page covers how to use the StochasticAI ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/stripe":{"id":"ecosystem/integrations/stripe","title":"Stripe","description":"Stripe is an Irish-American financial services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"sidebar"},"ecosystem/integrations/tair":{"id":"ecosystem/integrations/tair","title":"Tair","description":"This page covers how to use the Tair ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/telegram":{"id":"ecosystem/integrations/telegram","title":"Telegram","description":"Telegram Messenger is a globally accessible freemium, cross-platform, encrypted, cloud-based and centralized instant messaging service. The application also provides optional end-to-end encrypted chats and video calling, VoIP, file sharing and several other features.","sidebar":"sidebar"},"ecosystem/integrations/tomarkdown":{"id":"ecosystem/integrations/tomarkdown","title":"2Markdown","description":"2markdown service transforms website content into structured markdown files.","sidebar":"sidebar"},"ecosystem/integrations/trello":{"id":"ecosystem/integrations/trello","title":"Trello","description":"Trello is a web-based project management and collaboration tool that allows individuals and teams to organize and track their tasks and projects. It provides a visual interface known as a \\"board\\" where users can create lists and cards to represent their tasks and activities.","sidebar":"sidebar"},"ecosystem/integrations/twitter":{"id":"ecosystem/integrations/twitter","title":"Twitter","description":"Twitter is an online social media and social networking service.","sidebar":"sidebar"},"ecosystem/integrations/unstructured":{"id":"ecosystem/integrations/unstructured","title":"Unstructured","description":"The unstructured package from","sidebar":"sidebar"},"ecosystem/integrations/vectara":{"id":"ecosystem/integrations/vectara","title":"Vectara","description":"What is Vectara?","sidebar":"sidebar"},"ecosystem/integrations/vectara/vectara_chat":{"id":"ecosystem/integrations/vectara/vectara_chat","title":"Chat Over Documents with Vectara","description":"This notebook is based on the chatvectordb notebook, but using Vectara as the vector database.","sidebar":"sidebar"},"ecosystem/integrations/vectara/vectara_text_generation":{"id":"ecosystem/integrations/vectara/vectara_text_generation","title":"Vectara Text Generation","description":"This notebook is based on chatvectordb and adapted to Vectara.","sidebar":"sidebar"},"ecosystem/integrations/vespa":{"id":"ecosystem/integrations/vespa","title":"Vespa","description":"Vespa is a fully featured search engine and vector database.","sidebar":"sidebar"},"ecosystem/integrations/wandb_tracking":{"id":"ecosystem/integrations/wandb_tracking","title":"Weights & Biases","description":"This notebook goes over how to track your LangChain experiments into one centralized Weights and Biases dashboard. To learn more about prompt engineering and the callback please refer to this Report which explains both alongside the resultant dashboards you can expect to see.","sidebar":"sidebar"},"ecosystem/integrations/weather":{"id":"ecosystem/integrations/weather","title":"Weather","description":"OpenWeatherMap is an open source weather service provider.","sidebar":"sidebar"},"ecosystem/integrations/weaviate":{"id":"ecosystem/integrations/weaviate","title":"Weaviate","description":"This page covers how to use the Weaviate ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/whatsapp":{"id":"ecosystem/integrations/whatsapp","title":"WhatsApp","description":"WhatsApp (also called WhatsApp Messenger) is a freeware, cross-platform, centralized instant messaging (IM) and voice-over-IP (VoIP) service. It allows users to send text and voice messages, make voice and video calls, and share images, documents, user locations, and other content.","sidebar":"sidebar"},"ecosystem/integrations/whylabs_profiling":{"id":"ecosystem/integrations/whylabs_profiling","title":"WhyLabs","description":"WhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:","sidebar":"sidebar"},"ecosystem/integrations/wikipedia":{"id":"ecosystem/integrations/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"sidebar"},"ecosystem/integrations/wolfram_alpha":{"id":"ecosystem/integrations/wolfram_alpha","title":"Wolfram Alpha","description":"WolframAlpha is an answer engine developed by Wolfram Research.","sidebar":"sidebar"},"ecosystem/integrations/writer":{"id":"ecosystem/integrations/writer","title":"Writer","description":"This page covers how to use the Writer ecosystem within LangChain.","sidebar":"sidebar"},"ecosystem/integrations/yeagerai":{"id":"ecosystem/integrations/yeagerai","title":"Yeager.ai","description":"This page covers how to use Yeager.ai to generate LangChain tools and agents.","sidebar":"sidebar"},"ecosystem/integrations/youtube":{"id":"ecosystem/integrations/youtube","title":"YouTube","description":"YouTube is an online video sharing and social media platform created by Google.","sidebar":"sidebar"},"ecosystem/integrations/zep":{"id":"ecosystem/integrations/zep","title":"Zep","description":"Zep - A long-term memory store for LLM applications.","sidebar":"sidebar"},"ecosystem/integrations/zilliz":{"id":"ecosystem/integrations/zilliz","title":"Zilliz","description":"Zilliz Cloud is a fully managed service on cloud for LF AI Milvus\xae,","sidebar":"sidebar"},"ecosystem/youtube":{"id":"ecosystem/youtube","title":"YouTube tutorials","description":"This is a collection of LangChain videos on YouTube.","sidebar":"sidebar"},"get_started/installation":{"id":"get_started/installation","title":"Installation","description":"","sidebar":"sidebar"},"get_started/introduction":{"id":"get_started/introduction","title":"Introduction","description":"LangChain is a framework for developing applications powered by language models. It enables applications that are:","sidebar":"sidebar"},"get_started/quickstart":{"id":"get_started/quickstart","title":"Quickstart","description":"Installation","sidebar":"sidebar"},"guides/evaluation/agent_benchmarking":{"id":"guides/evaluation/agent_benchmarking","title":"Agent Benchmarking: Search + Calculator","description":"Here we go over how to benchmark performance of an agent on tasks where it has access to a calculator and a search tool.","sidebar":"sidebar"},"guides/evaluation/agent_vectordb_sota_pg":{"id":"guides/evaluation/agent_vectordb_sota_pg","title":"Agent VectorDB Question Answering Benchmarking","description":"Here we go over how to benchmark performance on a question answering task using an agent to route between multiple vectordatabases.","sidebar":"sidebar"},"guides/evaluation/benchmarking_template":{"id":"guides/evaluation/benchmarking_template","title":"Benchmarking Template","description":"This is an example notebook that can be used to create a benchmarking notebook for a task of your choice. Evaluation is really hard, and so we greatly welcome any contributions that can make it easier for people to experiment","sidebar":"sidebar"},"guides/evaluation/data_augmented_question_answering":{"id":"guides/evaluation/data_augmented_question_answering","title":"Data Augmented Question Answering","description":"This notebook uses some generic prompts/language models to evaluate an question answering system that uses other sources of data besides what is in the model. For example, this can be used to evaluate a question answering system over your proprietary data.","sidebar":"sidebar"},"guides/evaluation/generic_agent_evaluation":{"id":"guides/evaluation/generic_agent_evaluation","title":"Generic Agent Evaluation","description":"Good evaluation is key for quickly iterating on your agent\'s prompts and tools. Here we provide an example of how to use the TrajectoryEvalChain to evaluate your agent.","sidebar":"sidebar"},"guides/evaluation/huggingface_datasets":{"id":"guides/evaluation/huggingface_datasets","title":"Using Hugging Face Datasets","description":"This example shows how to use Hugging Face datasets to evaluate models. Specifically, we show how to load examples to evaluate models on from Hugging Face\'s dataset package.","sidebar":"sidebar"},"guides/evaluation/index":{"id":"guides/evaluation/index","title":"Evaluation","description":"This section of documentation covers how we approach and think about evaluation in LangChain.","sidebar":"sidebar"},"guides/evaluation/llm_math":{"id":"guides/evaluation/llm_math","title":"LLM Math","description":"Evaluating chains that know how to do math.","sidebar":"sidebar"},"guides/evaluation/openapi_eval":{"id":"guides/evaluation/openapi_eval","title":"Evaluating an OpenAPI Chain","description":"This notebook goes over ways to semantically evaluate an OpenAPI Chain, which calls an endpoint defined by the OpenAPI specification using purely natural language.","sidebar":"sidebar"},"guides/evaluation/qa_benchmarking_pg":{"id":"guides/evaluation/qa_benchmarking_pg","title":"Question Answering Benchmarking: Paul Graham Essay","description":"Here we go over how to benchmark performance on a question answering task over a Paul Graham essay.","sidebar":"sidebar"},"guides/evaluation/qa_benchmarking_sota":{"id":"guides/evaluation/qa_benchmarking_sota","title":"Question Answering Benchmarking: State of the Union Address","description":"Here we go over how to benchmark performance on a question answering task over a state of the union address.","sidebar":"sidebar"},"guides/evaluation/qa_generation":{"id":"guides/evaluation/qa_generation","title":"QA Generation","description":"This notebook shows how to use the QAGenerationChain to come up with question-answer pairs over a specific document.","sidebar":"sidebar"},"guides/evaluation/question_answering":{"id":"guides/evaluation/question_answering","title":"Question Answering","description":"This notebook covers how to evaluate generic question answering problems. This is a situation where you have an example containing a question and its corresponding ground truth answer, and you want to measure how well the language model does at answering those questions.","sidebar":"sidebar"},"guides/evaluation/sql_qa_benchmarking_chinook":{"id":"guides/evaluation/sql_qa_benchmarking_chinook","title":"SQL Question Answering Benchmarking: Chinook","description":"Here we go over how to benchmark performance on a question answering task over a SQL database.","sidebar":"sidebar"},"guides/model_laboratory":{"id":"guides/model_laboratory","title":"Model Comparison","description":"Constructing your language model application will likely involved choosing between many different options of prompts, models, and even chains to use. When doing so, you will want to compare these different options on different inputs in an easy, flexible, and intuitive way.","sidebar":"sidebar"},"guides/tracing/agent_with_tracing":{"id":"guides/tracing/agent_with_tracing","title":"Tracing Walkthrough","description":"There are two recommended ways to trace your LangChains:","sidebar":"sidebar"},"guides/tracing/index":{"id":"guides/tracing/index","title":"Tracing","description":"By enabling tracing in your LangChain runs, you\u2019ll be able to more effectively visualize, step through, and debug your chains and agents.","sidebar":"sidebar"},"modules/agents/agent_types/chat_conversation_agent":{"id":"modules/agents/agent_types/chat_conversation_agent","title":"Conversational agent","description":"This walkthrough demonstrates how to use an agent optimized for conversation. Other agents are often optimized for using tools to figure out the best response, which is not ideal in a conversational setting where you may want the agent to be able to chat with the user as well.","sidebar":"sidebar"},"modules/agents/agent_types/index":{"id":"modules/agents/agent_types/index","title":"Agent types","description":"Action agents","sidebar":"sidebar"},"modules/agents/agent_types/plan_and_execute":{"id":"modules/agents/agent_types/plan_and_execute","title":"Plan and execute","description":"Plan and execute agents accomplish an objective by first planning what to do, then executing the sub tasks. This idea is largely inspired by BabyAGI and then the \\"Plan-and-Solve\\" paper.","sidebar":"sidebar"},"modules/agents/agent_types/react":{"id":"modules/agents/agent_types/react","title":"ReAct","description":"This walkthrough showcases using an agent to implement the ReAct logic.","sidebar":"sidebar"},"modules/agents/agent_types/react_docstore":{"id":"modules/agents/agent_types/react_docstore","title":"ReAct document store","description":"This walkthrough showcases using an agent to implement the ReAct logic for working with document store specifically.","sidebar":"sidebar"},"modules/agents/agent_types/self_ask_with_search":{"id":"modules/agents/agent_types/self_ask_with_search","title":"Self ask with search","description":"This walkthrough showcases the Self Ask With Search chain.","sidebar":"sidebar"},"modules/agents/how_to/agent_vectorstore":{"id":"modules/agents/how_to/agent_vectorstore","title":"Combine agents and vector stores","description":"This notebook covers how to combine agents and vectorstores. The use case for this is that you\'ve ingested your data into a vectorstore and want to interact with it in an agentic manner.","sidebar":"sidebar"},"modules/agents/how_to/async_agent":{"id":"modules/agents/how_to/async_agent","title":"Async API","description":"LangChain provides async support for Agents by leveraging the asyncio library.","sidebar":"sidebar"},"modules/agents/how_to/chatgpt_clone":{"id":"modules/agents/how_to/chatgpt_clone","title":"Create ChatGPT clone","description":"This chain replicates ChatGPT by combining (1) a specific prompt, and (2) the concept of memory.","sidebar":"sidebar"},"modules/agents/how_to/custom_agent":{"id":"modules/agents/how_to/custom_agent","title":"Custom agent","description":"This notebook goes through how to create your own custom agent.","sidebar":"sidebar"},"modules/agents/how_to/custom_agent_with_tool_retrieval":{"id":"modules/agents/how_to/custom_agent_with_tool_retrieval","title":"Custom agent with tool retrieval","description":"This notebook builds off of this notebook and assumes familiarity with how agents work.","sidebar":"sidebar"},"modules/agents/how_to/custom_llm_agent":{"id":"modules/agents/how_to/custom_llm_agent","title":"Custom LLM Agent","description":"This notebook goes through how to create your own custom LLM agent.","sidebar":"sidebar"},"modules/agents/how_to/custom_llm_chat_agent":{"id":"modules/agents/how_to/custom_llm_chat_agent","title":"Custom LLM Agent (with a ChatModel)","description":"This notebook goes through how to create your own custom agent based on a chat model.","sidebar":"sidebar"},"modules/agents/how_to/custom_mrkl_agent":{"id":"modules/agents/how_to/custom_mrkl_agent","title":"Custom MRKL agent","description":"This notebook goes through how to create your own custom MRKL agent.","sidebar":"sidebar"},"modules/agents/how_to/custom_multi_action_agent":{"id":"modules/agents/how_to/custom_multi_action_agent","title":"Custom multi-action agent","description":"This notebook goes through how to create your own custom agent.","sidebar":"sidebar"},"modules/agents/how_to/handle_parsing_errors":{"id":"modules/agents/how_to/handle_parsing_errors","title":"Handle parsing errors","description":"Occasionally the LLM cannot determine what step to take because it outputs format in incorrect form to be handled by the output parser. In this case, by default the agent errors. But you can easily control this functionality with handleparsingerrors! Let\'s explore how.","sidebar":"sidebar"},"modules/agents/how_to/intermediate_steps":{"id":"modules/agents/how_to/intermediate_steps","title":"Access intermediate steps","description":"In order to get more visibility into what an agent is doing, we can also return intermediate steps. This comes in the form of an extra key in the return value, which is a list of (action, observation) tuples.","sidebar":"sidebar"},"modules/agents/how_to/max_iterations":{"id":"modules/agents/how_to/max_iterations","title":"Cap the max number of iterations","description":"This notebook walks through how to cap an agent at taking a certain number of steps. This can be useful to ensure that they do not go haywire and take too many steps.","sidebar":"sidebar"},"modules/agents/how_to/max_time_limit":{"id":"modules/agents/how_to/max_time_limit","title":"Timeouts for agents","description":"This notebook walks through how to cap an agent executor after a certain amount of time. This can be useful for safeguarding against long running agent runs.","sidebar":"sidebar"},"modules/agents/how_to/mrkl":{"id":"modules/agents/how_to/mrkl","title":"Replicating MRKL","description":"This walkthrough demonstrates how to replicate the MRKL system using agents.","sidebar":"sidebar"},"modules/agents/how_to/sharedmemory_for_tools":{"id":"modules/agents/how_to/sharedmemory_for_tools","title":"Shared memory across agents and tools","description":"This notebook goes over adding memory to both of an Agent and its tools. Before going through this notebook, please walk through the following notebooks, as this will build on top of both of them:","sidebar":"sidebar"},"modules/agents/how_to/streaming_stdout_final_only":{"id":"modules/agents/how_to/streaming_stdout_final_only","title":"Streaming final agent output","description":"If you only want the final output of an agent to be streamed, you can use the callback `FinalStreamingStdOutCallbackHandler`.","sidebar":"sidebar"},"modules/agents/how_to/structured_chat":{"id":"modules/agents/how_to/structured_chat","title":"Structured tool chat agent","description":"This notebook walks through using a chat agent capable of using multi-input tools.","sidebar":"sidebar"},"modules/agents/index":{"id":"modules/agents/index","title":"Agents","description":"Some applications require a flexible chain of calls to LLMs and other tools based on user input. The Agent interface provides the flexibility for such applications. An agent has access to a suite of tools, and determines which ones to use depending on the user input. Agents can use multiple tools, and use the output of one tool as the input to the next.","sidebar":"sidebar"},"modules/agents/toolkits/azure_cognitive_services":{"id":"modules/agents/toolkits/azure_cognitive_services","title":"Azure Cognitive Services Toolkit","description":"This toolkit is used to interact with the Azure Cognitive Services API to achieve some multimodal capabilities.","sidebar":"sidebar"},"modules/agents/toolkits/csv":{"id":"modules/agents/toolkits/csv","title":"CSV Agent","description":"This notebook shows how to use agents to interact with a csv. It is mostly optimized for question answering.","sidebar":"sidebar"},"modules/agents/toolkits/gmail":{"id":"modules/agents/toolkits/gmail","title":"Gmail Toolkit","description":"This notebook walks through connecting a LangChain email to the Gmail API.","sidebar":"sidebar"},"modules/agents/toolkits/index":{"id":"modules/agents/toolkits/index","title":"Toolkits","description":"Toolkits are collections of tools that are designed to be used together for specific tasks and have convenience loading methods.","sidebar":"sidebar"},"modules/agents/toolkits/jira":{"id":"modules/agents/toolkits/jira","title":"Jira","description":"This notebook goes over how to use the Jira tool.","sidebar":"sidebar"},"modules/agents/toolkits/json":{"id":"modules/agents/toolkits/json","title":"JSON Agent","description":"This notebook showcases an agent designed to interact with large JSON/dict objects. This is useful when you want to answer questions about a JSON blob that\'s too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user\'s question.","sidebar":"sidebar"},"modules/agents/toolkits/openapi":{"id":"modules/agents/toolkits/openapi","title":"OpenAPI agents","description":"We can construct agents to consume arbitrary APIs, here APIs conformant to the OpenAPI/Swagger specification.","sidebar":"sidebar"},"modules/agents/toolkits/openapi_nla":{"id":"modules/agents/toolkits/openapi_nla","title":"Natural Language APIs","description":"Natural Language API Toolkits (NLAToolkits) permit LangChain Agents to efficiently plan and combine calls across endpoints. This notebook demonstrates a sample composition of the Speak, Klarna, and Spoonacluar APIs.","sidebar":"sidebar"},"modules/agents/toolkits/pandas":{"id":"modules/agents/toolkits/pandas","title":"Pandas Dataframe Agent","description":"This notebook shows how to use agents to interact with a pandas dataframe. It is mostly optimized for question answering.","sidebar":"sidebar"},"modules/agents/toolkits/playwright":{"id":"modules/agents/toolkits/playwright","title":"PlayWright Browser Toolkit","description":"This toolkit is used to interact with the browser. While other tools (like the Requests tools) are fine for static sites, Browser toolkits let your agent navigate the web and interact with dynamically rendered sites. Some tools bundled within the Browser toolkit include:","sidebar":"sidebar"},"modules/agents/toolkits/powerbi":{"id":"modules/agents/toolkits/powerbi","title":"PowerBI Dataset Agent","description":"This notebook showcases an agent designed to interact with a Power BI Dataset. The agent is designed to answer more general questions about a dataset, as well as recover from errors.","sidebar":"sidebar"},"modules/agents/toolkits/python":{"id":"modules/agents/toolkits/python","title":"Python Agent","description":"This notebook showcases an agent designed to write and execute python code to answer a question.","sidebar":"sidebar"},"modules/agents/toolkits/spark":{"id":"modules/agents/toolkits/spark","title":"Spark Dataframe Agent","description":"This notebook shows how to use agents to interact with a Spark dataframe and Spark Connect. It is mostly optimized for question answering.","sidebar":"sidebar"},"modules/agents/toolkits/spark_sql":{"id":"modules/agents/toolkits/spark_sql","title":"Spark SQL Agent","description":"This notebook shows how to use agents to interact with a Spark SQL. Similar to SQL Database Agent, it is designed to address general inquiries about Spark SQL and facilitate error recovery.","sidebar":"sidebar"},"modules/agents/toolkits/sql_database":{"id":"modules/agents/toolkits/sql_database","title":"SQL Database Agent","description":"This notebook showcases an agent designed to interact with a sql databases. The agent builds off of SQLDatabaseChain and is designed to answer more general questions about a database, as well as recover from errors.","sidebar":"sidebar"},"modules/agents/toolkits/vectorstore":{"id":"modules/agents/toolkits/vectorstore","title":"Vectorstore Agent","description":"This notebook showcases an agent designed to retrieve information from one or more vectorstores, either with or without sources.","sidebar":"sidebar"},"modules/agents/tools/how_to/custom_tools":{"id":"modules/agents/tools/how_to/custom_tools","title":"Defining Custom Tools","description":"When constructing your own agent, you will need to provide it with a list of Tools that it can use. Besides the actual function that is called, the Tool consists of several components:","sidebar":"sidebar"},"modules/agents/tools/how_to/human_approval":{"id":"modules/agents/tools/how_to/human_approval","title":"Human-in-the-loop Tool Validation","description":"This walkthrough demonstrates how to add Human validation to any Tool. We\'ll do this using the HumanApprovalCallbackhandler.","sidebar":"sidebar"},"modules/agents/tools/how_to/multi_input_tool":{"id":"modules/agents/tools/how_to/multi_input_tool","title":"Multi-Input Tools","description":"This notebook shows how to use a tool that requires multiple inputs with an agent. The recommended way to do so is with the StructuredTool class.","sidebar":"sidebar"},"modules/agents/tools/how_to/tool_input_validation":{"id":"modules/agents/tools/how_to/tool_input_validation","title":"Tool Input Schema","description":"By default, tools infer the argument schema by inspecting the function signature. For more strict requirements, custom input schema can be specified, along with custom validation logic.","sidebar":"sidebar"},"modules/agents/tools/index":{"id":"modules/agents/tools/index","title":"Tools","description":"Tools are interfaces that an agent can use to interact with the world.","sidebar":"sidebar"},"modules/agents/tools/integrations/apify":{"id":"modules/agents/tools/integrations/apify","title":"Apify","description":"This notebook shows how to use the Apify integration for LangChain.","sidebar":"sidebar"},"modules/agents/tools/integrations/arxiv":{"id":"modules/agents/tools/integrations/arxiv","title":"ArXiv API Tool","description":"This notebook goes over how to use the arxiv component.","sidebar":"sidebar"},"modules/agents/tools/integrations/awslambda":{"id":"modules/agents/tools/integrations/awslambda","title":"awslambda","description":"AWS Lambda API","sidebar":"sidebar"},"modules/agents/tools/integrations/bash":{"id":"modules/agents/tools/integrations/bash","title":"Shell Tool","description":"Giving agents access to the shell is powerful (though risky outside a sandboxed environment).","sidebar":"sidebar"},"modules/agents/tools/integrations/bing_search":{"id":"modules/agents/tools/integrations/bing_search","title":"Bing Search","description":"This notebook goes over how to use the bing search component.","sidebar":"sidebar"},"modules/agents/tools/integrations/brave_search":{"id":"modules/agents/tools/integrations/brave_search","title":"Brave Search","description":"This notebook goes over how to use the Brave Search tool.","sidebar":"sidebar"},"modules/agents/tools/integrations/chatgpt_plugins":{"id":"modules/agents/tools/integrations/chatgpt_plugins","title":"ChatGPT Plugins","description":"This example shows how to use ChatGPT Plugins within LangChain abstractions.","sidebar":"sidebar"},"modules/agents/tools/integrations/ddg":{"id":"modules/agents/tools/integrations/ddg","title":"DuckDuckGo Search","description":"This notebook goes over how to use the duck-duck-go search component.","sidebar":"sidebar"},"modules/agents/tools/integrations/filesystem":{"id":"modules/agents/tools/integrations/filesystem","title":"File System Tools","description":"LangChain provides tools for interacting with a local file system out of the box. This notebook walks through some of them.","sidebar":"sidebar"},"modules/agents/tools/integrations/google_places":{"id":"modules/agents/tools/integrations/google_places","title":"Google Places","description":"This notebook goes through how to use Google Places API","sidebar":"sidebar"},"modules/agents/tools/integrations/google_search":{"id":"modules/agents/tools/integrations/google_search","title":"Google Search","description":"This notebook goes over how to use the google search component.","sidebar":"sidebar"},"modules/agents/tools/integrations/google_serper":{"id":"modules/agents/tools/integrations/google_serper","title":"Google Serper API","description":"This notebook goes over how to use the Google Serper component to search the web. First you need to sign up for a free account at serper.dev and get your api key.","sidebar":"sidebar"},"modules/agents/tools/integrations/gradio_tools":{"id":"modules/agents/tools/integrations/gradio_tools","title":"Gradio Tools","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM\'s fingers \ud83e\uddbe","sidebar":"sidebar"},"modules/agents/tools/integrations/graphql":{"id":"modules/agents/tools/integrations/graphql","title":"GraphQL tool","description":"This Jupyter Notebook demonstrates how to use the BaseGraphQLTool component with an Agent.","sidebar":"sidebar"},"modules/agents/tools/integrations/huggingface_tools":{"id":"modules/agents/tools/integrations/huggingface_tools","title":"huggingface_tools","description":"HuggingFace Tools","sidebar":"sidebar"},"modules/agents/tools/integrations/human_tools":{"id":"modules/agents/tools/integrations/human_tools","title":"Human as a tool","description":"Human are AGI so they can certainly be used as a tool to help out AI agent","sidebar":"sidebar"},"modules/agents/tools/integrations/ifttt":{"id":"modules/agents/tools/integrations/ifttt","title":"IFTTT WebHooks","description":"This notebook shows how to use IFTTT Webhooks.","sidebar":"sidebar"},"modules/agents/tools/integrations/metaphor_search":{"id":"modules/agents/tools/integrations/metaphor_search","title":"Metaphor Search","description":"This notebook goes over how to use Metaphor search.","sidebar":"sidebar"},"modules/agents/tools/integrations/openweathermap":{"id":"modules/agents/tools/integrations/openweathermap","title":"OpenWeatherMap API","description":"This notebook goes over how to use the OpenWeatherMap component to fetch weather information.","sidebar":"sidebar"},"modules/agents/tools/integrations/pubmed":{"id":"modules/agents/tools/integrations/pubmed","title":"PubMed Tool","description":"This notebook goes over how to use PubMed as a tool","sidebar":"sidebar"},"modules/agents/tools/integrations/requests":{"id":"modules/agents/tools/integrations/requests","title":"Requests","description":"The web contains a lot of information that LLMs do not have access to. In order to easily let LLMs interact with that information, we provide a wrapper around the Python Requests module that takes in a URL and fetches data from that URL.","sidebar":"sidebar"},"modules/agents/tools/integrations/sceneXplain":{"id":"modules/agents/tools/integrations/sceneXplain","title":"SceneXplain","description":"SceneXplain is an ImageCaptioning service accessible through the SceneXplain Tool.","sidebar":"sidebar"},"modules/agents/tools/integrations/search_tools":{"id":"modules/agents/tools/integrations/search_tools","title":"Search Tools","description":"This notebook shows off usage of various search tools.","sidebar":"sidebar"},"modules/agents/tools/integrations/searx_search":{"id":"modules/agents/tools/integrations/searx_search","title":"SearxNG Search API","description":"This notebook goes over how to use a self hosted SearxNG search API to search the web.","sidebar":"sidebar"},"modules/agents/tools/integrations/serpapi":{"id":"modules/agents/tools/integrations/serpapi","title":"SerpAPI","description":"This notebook goes over how to use the SerpAPI component to search the web.","sidebar":"sidebar"},"modules/agents/tools/integrations/twilio":{"id":"modules/agents/tools/integrations/twilio","title":"Twilio","description":"This notebook goes over how to use the Twilio API wrapper to send a text message.","sidebar":"sidebar"},"modules/agents/tools/integrations/wikipedia":{"id":"modules/agents/tools/integrations/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"sidebar"},"modules/agents/tools/integrations/wolfram_alpha":{"id":"modules/agents/tools/integrations/wolfram_alpha","title":"Wolfram Alpha","description":"This notebook goes over how to use the wolfram alpha component.","sidebar":"sidebar"},"modules/agents/tools/integrations/youtube":{"id":"modules/agents/tools/integrations/youtube","title":"YouTubeSearchTool","description":"This notebook shows how to use a tool to search YouTube","sidebar":"sidebar"},"modules/agents/tools/integrations/zapier":{"id":"modules/agents/tools/integrations/zapier","title":"Zapier Natural Language Actions API","description":"\\\\","sidebar":"sidebar"},"modules/callbacks/how_to/async_callbacks":{"id":"modules/callbacks/how_to/async_callbacks","title":"Async callbacks","description":"If you are planning to use the async API, it is recommended to use AsyncCallbackHandler to avoid blocking the runloop.","sidebar":"sidebar"},"modules/callbacks/how_to/custom_callbacks":{"id":"modules/callbacks/how_to/custom_callbacks","title":"Custom callback handlers","description":"You can create a custom handler to set on the object as well. In the example below, we\'ll implement streaming with a custom handler.","sidebar":"sidebar"},"modules/callbacks/how_to/custom_chain":{"id":"modules/callbacks/how_to/custom_chain","title":"Callbacks for custom chains","description":"When you create a custom chain you can easily set it up to use the same callback system as all the built-in chains.","sidebar":"sidebar"},"modules/callbacks/how_to/filecallbackhandler":{"id":"modules/callbacks/how_to/filecallbackhandler","title":"Logging to file","description":"This example shows how to print logs to file. It shows how to use the FileCallbackHandler, which does the same thing as StdOutCallbackHandler, but instead writes the output to file. It also uses the loguru library to log other outputs that are not captured by the handler.","sidebar":"sidebar"},"modules/callbacks/how_to/multiple_callbacks":{"id":"modules/callbacks/how_to/multiple_callbacks","title":"Multiple callback handlers","description":"In the previous examples, we passed in callback handlers upon creation of an object by using callbacks=. In this case, the callbacks will be scoped to that particular object.","sidebar":"sidebar"},"modules/callbacks/how_to/token_counting":{"id":"modules/callbacks/how_to/token_counting","title":"Token counting","description":"LangChain offers a context manager that allows you to count tokens.","sidebar":"sidebar"},"modules/callbacks/how_to/tracing":{"id":"modules/callbacks/how_to/tracing","title":"Tracing","description":"There are two recommended ways to trace your LangChains:","sidebar":"sidebar"},"modules/callbacks/index":{"id":"modules/callbacks/index","title":"Callbacks","description":"LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. This is useful for logging, monitoring, streaming, and other tasks.","sidebar":"sidebar"},"modules/callbacks/integrations/argilla":{"id":"modules/callbacks/integrations/argilla","title":"Argilla","description":"Argilla - Open-source data platform for LLMs","sidebar":"sidebar"},"modules/chains/additional/analyze_document":{"id":"modules/chains/additional/analyze_document","title":"Analyze Document","description":"The AnalyzeDocumentChain can be used as an end-to-end to chain. This chain takes in a single document, splits it up, and then runs it through a CombineDocumentsChain.","sidebar":"sidebar"},"modules/chains/additional/constitutional_chain":{"id":"modules/chains/additional/constitutional_chain","title":"Self-critique chain with constitutional AI","description":"The ConstitutionalChain is a chain that ensures the output of a language model adheres to a predefined set of constitutional principles. By incorporating specific rules and guidelines, the ConstitutionalChain filters and modifies the generated content to align with these principles, thus providing more controlled, ethical, and contextually appropriate responses. This mechanism helps maintain the integrity of the output while minimizing the risk of generating content that may violate guidelines, be offensive, or deviate from the desired context.","sidebar":"sidebar"},"modules/chains/additional/flare":{"id":"modules/chains/additional/flare","title":"FLARE","description":"This notebook is an implementation of Forward-Looking Active REtrieval augmented generation (FLARE).","sidebar":"sidebar"},"modules/chains/additional/from_hub":{"id":"modules/chains/additional/from_hub","title":"Loading from LangChainHub","description":"This notebook covers how to load chains from LangChainHub.","sidebar":"sidebar"},"modules/chains/additional/graph_cypher_qa":{"id":"modules/chains/additional/graph_cypher_qa","title":"Graph DB QA chain","description":"This notebook shows how to use LLMs to provide a natural language interface to a graph database you can query with the Cypher query language.","sidebar":"sidebar"},"modules/chains/additional/graph_qa":{"id":"modules/chains/additional/graph_qa","title":"Graph QA","description":"This notebook goes over how to do question answering over a graph data structure.","sidebar":"sidebar"},"modules/chains/additional/hyde":{"id":"modules/chains/additional/hyde","title":"Hypothetical Document Embeddings","description":"This notebook goes over how to use Hypothetical Document Embeddings (HyDE), as described in this paper.","sidebar":"sidebar"},"modules/chains/additional/index":{"id":"modules/chains/additional/index","title":"Additional","description":"","sidebar":"sidebar"},"modules/chains/additional/llm_bash":{"id":"modules/chains/additional/llm_bash","title":"Bash chain","description":"This notebook showcases using LLMs and a bash process to perform simple filesystem commands.","sidebar":"sidebar"},"modules/chains/additional/llm_checker":{"id":"modules/chains/additional/llm_checker","title":"Self-checking chain","description":"This notebook showcases how to use LLMCheckerChain.","sidebar":"sidebar"},"modules/chains/additional/llm_math":{"id":"modules/chains/additional/llm_math","title":"Math chain","description":"This notebook showcases using LLMs and Python REPLs to do complex word math problems.","sidebar":"sidebar"},"modules/chains/additional/llm_requests":{"id":"modules/chains/additional/llm_requests","title":"HTTP request chain","description":"Using the request library to get HTML results from a URL and then an LLM to parse results","sidebar":"sidebar"},"modules/chains/additional/llm_summarization_checker":{"id":"modules/chains/additional/llm_summarization_checker","title":"Summarization checker chain","description":"This notebook shows some examples of LLMSummarizationCheckerChain in use with different types of texts.  It has a few distinct differences from the LLMCheckerChain, in that it doesn\'t have any assumptions to the format of the input text (or summary).","sidebar":"sidebar"},"modules/chains/additional/moderation":{"id":"modules/chains/additional/moderation","title":"Moderation","description":"This notebook walks through examples of how to use a moderation chain, and several common ways for doing so. Moderation chains are useful for detecting text that could be hateful, violent, etc. This can be useful to apply on both user input, but also on the output of a Language Model. Some API providers, like OpenAI, specifically prohibit you, or your end users, from generating some types of harmful content. To comply with this (and to just generally prevent your application from being harmful) you may often want to append a moderation chain to any LLMChains, in order to make sure any output the LLM generates is not harmful.","sidebar":"sidebar"},"modules/chains/additional/multi_prompt_router":{"id":"modules/chains/additional/multi_prompt_router","title":"Dynamically selecting from multiple prompts","description":"This notebook demonstrates how to use the RouterChain paradigm to create a chain that dynamically selects the prompt to use for a given input. Specifically we show how to use the MultiPromptChain to create a question-answering chain that selects the prompt which is most relevant for a given question, and then answers the question using that prompt.","sidebar":"sidebar"},"modules/chains/additional/multi_retrieval_qa_router":{"id":"modules/chains/additional/multi_retrieval_qa_router","title":"Dynamically selecting from multiple retrievers","description":"This notebook demonstrates how to use the RouterChain paradigm to create a chain that dynamically selects which Retrieval system to use. Specifically we show how to use the MultiRetrievalQAChain to create a question-answering chain that selects the retrieval QA chain which is most relevant for a given question, and then answers the question using it.","sidebar":"sidebar"},"modules/chains/additional/openapi":{"id":"modules/chains/additional/openapi","title":"OpenAPI chain","description":"This notebook shows an example of using an OpenAPI chain to call an endpoint in natural language, and get back a response in natural language.","sidebar":"sidebar"},"modules/chains/additional/pal":{"id":"modules/chains/additional/pal","title":"Program-aided language model (PAL) chain","description":"Implements Program-Aided Language Models, as in https://arxiv.org/pdf/2211.10435.pdf.","sidebar":"sidebar"},"modules/chains/additional/question_answering":{"id":"modules/chains/additional/question_answering","title":"Document QA","description":"Here we walk through how to use LangChain for question answering over a list of documents. Under the hood we\'ll be using our Document chains.","sidebar":"sidebar"},"modules/chains/additional/vector_db_text_generation":{"id":"modules/chains/additional/vector_db_text_generation","title":"Vector store-augmented text generation","description":"This notebook walks through how to use LangChain for text generation over a vector index. This is useful if we want to generate text that is able to draw from a large body of custom text, for example, generating blog posts that have an understanding of previous blog posts written, or product tutorials that can refer to product documentation.","sidebar":"sidebar"},"modules/chains/document/index":{"id":"modules/chains/document/index","title":"Documents","description":"These are the core chains for working with Documents. They are useful for summarizing documents, answering questions over documents, extracting information from documents, and more.","sidebar":"sidebar"},"modules/chains/document/map_reduce":{"id":"modules/chains/document/map_reduce","title":"Map reduce","description":"The map reduce documents chain first applies an LLM chain to each document individually (the Map step), treating the chain output as a new document. It then passes all the new documents to a separate combine documents chain to get a single output (the Reduce step). It can optionally first compress, or collapse, the mapped documents to make sure that they fit in the combine documents chain (which will often pass them to an LLM). This compression step is performed recursively if necessary.","sidebar":"sidebar"},"modules/chains/document/map_rerank":{"id":"modules/chains/document/map_rerank","title":"Map re-rank","description":"The map re-rank documents chain runs an initial prompt on each document, that not only tries to complete a task but also gives a score for how certain it is in its answer. The highest scoring response is returned.","sidebar":"sidebar"},"modules/chains/document/refine":{"id":"modules/chains/document/refine","title":"Refine","description":"The refine documents chain constructs a response by looping over the input documents and iteratively updating its answer. For each document, it passes all non-document inputs, the current document, and the latest intermediate answer to an LLM chain to get a new answer.","sidebar":"sidebar"},"modules/chains/document/stuff":{"id":"modules/chains/document/stuff","title":"Stuff","description":"The stuff documents chain (\\"stuff\\" as in \\"to stuff\\" or \\"to fill\\") is the most straightforward of the document chains. It takes a list of documents, inserts them all into a prompt and passes that prompt to an LLM.","sidebar":"sidebar"},"modules/chains/foundational/index":{"id":"modules/chains/foundational/index","title":"Foundational","description":"","sidebar":"sidebar"},"modules/chains/foundational/llm_chain":{"id":"modules/chains/foundational/llm_chain","title":"LLM","description":"An LLMChain is a simple chain that adds some functionality around language models. It is used widely throughout LangChain, including in other chains and agents.","sidebar":"sidebar"},"modules/chains/foundational/router":{"id":"modules/chains/foundational/router","title":"Router","description":"This notebook demonstrates how to use the RouterChain paradigm to create a chain that dynamically selects the next chain to use for a given input.","sidebar":"sidebar"},"modules/chains/foundational/sequential_chains":{"id":"modules/chains/foundational/sequential_chains","title":"Sequential","description":"The next step after calling a language model is make a series of calls to a language model. This is particularly useful when you want to take the output from one call and use it as the input to another.","sidebar":"sidebar"},"modules/chains/foundational/transformation":{"id":"modules/chains/foundational/transformation","title":"Transformation","description":"This notebook showcases using a generic transformation chain.","sidebar":"sidebar"},"modules/chains/how_to/async_chain":{"id":"modules/chains/how_to/async_chain","title":"Async API","description":"LangChain provides async support for Chains by leveraging the asyncio library.","sidebar":"sidebar"},"modules/chains/how_to/call_methods":{"id":"modules/chains/how_to/call_methods","title":"Different call methods","description":"All classes inherited from Chain offer a few ways of running chain logic. The most direct one is by using call:","sidebar":"sidebar"},"modules/chains/how_to/custom_chain":{"id":"modules/chains/how_to/custom_chain","title":"Custom chain","description":"To implement your own custom chain you can subclass Chain and implement the following methods:","sidebar":"sidebar"},"modules/chains/how_to/debugging":{"id":"modules/chains/how_to/debugging","title":"Debugging chains","description":"It can be hard to debug a Chain object solely from its output as most Chain objects involve a fair amount of input prompt preprocessing and LLM output post-processing.","sidebar":"sidebar"},"modules/chains/how_to/index":{"id":"modules/chains/how_to/index","title":"How to","description":"","sidebar":"sidebar"},"modules/chains/how_to/memory":{"id":"modules/chains/how_to/memory","title":"Adding memory (state)","description":"Chains can be initialized with a Memory object, which will persist data across calls to the chain. This makes a Chain stateful.","sidebar":"sidebar"},"modules/chains/how_to/serialization":{"id":"modules/chains/how_to/serialization","title":"Serialization","description":"This notebook covers how to serialize chains to and from disk. The serialization format we use is json or yaml. Currently, only some chains support this type of serialization. We will grow the number of supported chains over time.","sidebar":"sidebar"},"modules/chains/index":{"id":"modules/chains/index","title":"Chains","description":"Using an LLM in isolation is fine for simple applications,","sidebar":"sidebar"},"modules/chains/popular/api":{"id":"modules/chains/popular/api","title":"API chains","description":"APIChain enables using LLMs to interact with APIs to retrieve relevant information. Construct the chain by providing a question relevant to the provided API documentation.","sidebar":"sidebar"},"modules/chains/popular/chat_vector_db":{"id":"modules/chains/popular/chat_vector_db","title":"Conversational Retrieval QA","description":"The ConversationalRetrievalQA chain builds on RetrievalQAChain to provide a chat history component.","sidebar":"sidebar"},"modules/chains/popular/index":{"id":"modules/chains/popular/index","title":"Popular","description":"","sidebar":"sidebar"},"modules/chains/popular/sqlite":{"id":"modules/chains/popular/sqlite","title":"SQL","description":"This example demonstrates the use of the SQLDatabaseChain for answering questions over a SQL database.","sidebar":"sidebar"},"modules/chains/popular/summarize":{"id":"modules/chains/popular/summarize","title":"Summarization","description":"A summarization chain can be used to summarize multiple documents. One way is to input multiple smaller documents, after they have been divided into chunks, and operate over them with a MapReduceDocumentsChain. You can also choose instead for the chain that does summarization to be a StuffDocumentsChain, or a RefineDocumentsChain.","sidebar":"sidebar"},"modules/chains/popular/vector_db_qa":{"id":"modules/chains/popular/vector_db_qa","title":"Retrieval QA","description":"This example showcases question answering over an index.","sidebar":"sidebar"},"modules/data_io/document_loaders/how_to/csv":{"id":"modules/data_io/document_loaders/how_to/csv","title":"CSV","description":"A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.","sidebar":"sidebar"},"modules/data_io/document_loaders/how_to/file_directory":{"id":"modules/data_io/document_loaders/how_to/file_directory","title":"File Directory","description":"This covers how to load all documents in a directory.","sidebar":"sidebar"},"modules/data_io/document_loaders/how_to/html":{"id":"modules/data_io/document_loaders/how_to/html","title":"HTML","description":"The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser.","sidebar":"sidebar"},"modules/data_io/document_loaders/how_to/json":{"id":"modules/data_io/document_loaders/how_to/json","title":"JSON","description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute\u2013value pairs and arrays (or other serializable values).","sidebar":"sidebar"},"modules/data_io/document_loaders/how_to/markdown":{"id":"modules/data_io/document_loaders/how_to/markdown","title":"Markdown","description":"Markdown is a lightweight markup language for creating formatted text using a plain-text editor.","sidebar":"sidebar"},"modules/data_io/document_loaders/how_to/pdf":{"id":"modules/data_io/document_loaders/how_to/pdf","title":"PDF","description":"Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.","sidebar":"sidebar"},"modules/data_io/document_loaders/index":{"id":"modules/data_io/document_loaders/index","title":"Document loaders","description":"Use document loaders to load data from a source as Document\'s. A Document is a piece of text","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/airbyte_json":{"id":"modules/data_io/document_loaders/integrations/airbyte_json","title":"Airbyte JSON","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/alibaba_cloud_maxcompute":{"id":"modules/data_io/document_loaders/integrations/alibaba_cloud_maxcompute","title":"Alibaba Cloud MaxCompute","description":"Alibaba Cloud MaxCompute (previously known as ODPS) is a general purpose, fully managed, multi-tenancy data processing platform for large-scale data warehousing. MaxCompute supports various data importing solutions and distributed computing models, enabling users to effectively query massive datasets, reduce production costs, and ensure data security.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/apify_dataset":{"id":"modules/data_io/document_loaders/integrations/apify_dataset","title":"Apify Dataset","description":"Apify Dataset is a scaleable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of Apify Actors\u2014serverless cloud programs for varius web scraping, crawling, and data extraction use cases.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/arxiv":{"id":"modules/data_io/document_loaders/integrations/arxiv","title":"Arxiv","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/aws_s3_directory":{"id":"modules/data_io/document_loaders/integrations/aws_s3_directory","title":"AWS S3 Directory","description":"Amazon Simple Storage Service (Amazon S3) is an object storage service","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/aws_s3_file":{"id":"modules/data_io/document_loaders/integrations/aws_s3_file","title":"AWS S3 File","description":"Amazon Simple Storage Service (Amazon S3) is an object storage service.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/azlyrics":{"id":"modules/data_io/document_loaders/integrations/azlyrics","title":"AZLyrics","description":"AZLyrics is a large, legal, every day growing collection of lyrics.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/azure_blob_storage_container":{"id":"modules/data_io/document_loaders/integrations/azure_blob_storage_container","title":"Azure Blob Storage Container","description":"Azure Blob Storage is Microsoft\'s object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn\'t adhere to a particular data model or definition, such as text or binary data.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/azure_blob_storage_file":{"id":"modules/data_io/document_loaders/integrations/azure_blob_storage_file","title":"Azure Blob Storage File","description":"Azure Files offers fully managed file shares in the cloud that are accessible via the industry standard Server Message Block (SMB) protocol, Network File System (NFS) protocol, and Azure Files REST API.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/bibtex":{"id":"modules/data_io/document_loaders/integrations/bibtex","title":"BibTeX","description":"BibTeX is a file format and reference management system commonly used in conjunction with LaTeX typesetting. It serves as a way to organize and store bibliographic information for academic and research documents.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/bilibili":{"id":"modules/data_io/document_loaders/integrations/bilibili","title":"BiliBili","description":"Bilibili is one of the most beloved long-form video sites in China.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/blackboard":{"id":"modules/data_io/document_loaders/integrations/blackboard","title":"Blackboard","description":"Blackboard Learn (previously the Blackboard Learning Management System) is a web-based virtual learning environment and learning management system developed by Blackboard Inc. The software features course management, customizable open architecture, and scalable design that allows integration with student information systems and authentication protocols. It may be installed on local servers, hosted by Blackboard ASP Solutions, or provided as Software as a Service hosted on Amazon Web Services. Its main purposes are stated to include the addition of online elements to courses traditionally delivered face-to-face and development of completely online courses with few or no face-to-face meetings","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/blockchain":{"id":"modules/data_io/document_loaders/integrations/blockchain","title":"Blockchain","description":"Overview","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/chatgpt_loader":{"id":"modules/data_io/document_loaders/integrations/chatgpt_loader","title":"chatgpt_loader","description":"ChatGPT Data","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/college_confidential":{"id":"modules/data_io/document_loaders/integrations/college_confidential","title":"College Confidential","description":"College Confidential gives information on 3,800+ colleges and universities.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/confluence":{"id":"modules/data_io/document_loaders/integrations/confluence","title":"Confluence","description":"Confluence is a wiki collaboration platform that saves and organizes all of the project-related material. Confluence is a knowledge base that primarily handles content management activities.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/conll-u":{"id":"modules/data_io/document_loaders/integrations/conll-u","title":"CoNLL-U","description":"CoNLL-U is revised version of the CoNLL-X format. Annotations are encoded in plain text files (UTF-8, normalized to NFC, using only the LF character as line break, including an LF character at the end of file) with three types of lines:","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/copypaste":{"id":"modules/data_io/document_loaders/integrations/copypaste","title":"Copy Paste","description":"This notebook covers how to load a document object from something you just want to copy and paste. In this case, you don\'t even need to use a DocumentLoader, but rather can just construct the Document directly.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/diffbot":{"id":"modules/data_io/document_loaders/integrations/diffbot","title":"Diffbot","description":"Unlike traditional web scraping tools, Diffbot doesn\'t require any rules to read the content on a page.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/discord":{"id":"modules/data_io/document_loaders/integrations/discord","title":"Discord","description":"Discord is a VoIP and instant messaging social platform. Users have the ability to communicate with voice calls, video calls, text messaging, media and files in private chats or as part of communities called \\"servers\\". A server is a collection of persistent chat rooms and voice channels which can be accessed via invite links.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/docugami":{"id":"modules/data_io/document_loaders/integrations/docugami","title":"Docugami","description":"This notebook covers how to load documents from Docugami. It provides the advantages of using this system over alternative data loaders.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/duckdb":{"id":"modules/data_io/document_loaders/integrations/duckdb","title":"DuckDB","description":"DuckDB is an in-process SQL OLAP database management system.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/email":{"id":"modules/data_io/document_loaders/integrations/email","title":"Email","description":"This notebook shows how to load email (.eml) or Microsoft Outlook (.msg) files.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/epub":{"id":"modules/data_io/document_loaders/integrations/epub","title":"EPub","description":"EPUB is an e-book file format that uses the \\".epub\\" file extension. The term is short for electronic publication and is sometimes styled ePub. EPUB is supported by many e-readers, and compatible software is available for most smartphones, tablets, and computers.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/evernote":{"id":"modules/data_io/document_loaders/integrations/evernote","title":"EverNote","description":"EverNote is intended for archiving and creating notes in which photos, audio and saved web content can be embedded. Notes are stored in virtual \\"notebooks\\" and can be tagged, annotated, edited, searched, and exported.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/example_data/notebook":{"id":"modules/data_io/document_loaders/integrations/example_data/notebook","title":"Notebook","description":"This notebook covers how to load data from an .ipynb notebook into a format suitable by LangChain.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/excel":{"id":"modules/data_io/document_loaders/integrations/excel","title":"Microsoft Excel","description":"The UnstructuredExcelLoader is used to load Microsoft Excel files. The loader works with both .xlsx and .xls files. The page content will be the raw text of the Excel file. If you use the loader in \\"elements\\" mode, an HTML representation of the Excel file will be available in the document metadata under the textashtml key.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/facebook_chat":{"id":"modules/data_io/document_loaders/integrations/facebook_chat","title":"Facebook Chat","description":"Messenger) is an American proprietary instant messaging app and platform developed by Meta Platforms. Originally developed as Facebook Chat in 2008, the company revamped its messaging service in 2010.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/figma":{"id":"modules/data_io/document_loaders/integrations/figma","title":"Figma","description":"Figma is a collaborative web application for interface design.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/git":{"id":"modules/data_io/document_loaders/integrations/git","title":"Git","description":"Git is a distributed version control system that tracks changes in any set of computer files, usually used for coordinating work among programmers collaboratively developing source code during software development.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/gitbook":{"id":"modules/data_io/document_loaders/integrations/gitbook","title":"GitBook","description":"GitBook is a modern documentation platform where teams can document everything from products to internal knowledge bases and APIs.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/github":{"id":"modules/data_io/document_loaders/integrations/github","title":"GitHub","description":"This notebooks shows how you can load issues and pull requests (PRs) for a given repository on GitHub. We will use the LangChain Python repository as an example.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/google_bigquery":{"id":"modules/data_io/document_loaders/integrations/google_bigquery","title":"Google BigQuery","description":"Google BigQuery is a serverless and cost-effective enterprise data warehouse that works across clouds and scales with your data.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/google_cloud_storage_directory":{"id":"modules/data_io/document_loaders/integrations/google_cloud_storage_directory","title":"Google Cloud Storage Directory","description":"Google Cloud Storage is a managed service for storing unstructured data.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/google_cloud_storage_file":{"id":"modules/data_io/document_loaders/integrations/google_cloud_storage_file","title":"Google Cloud Storage File","description":"Google Cloud Storage is a managed service for storing unstructured data.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/google_drive":{"id":"modules/data_io/document_loaders/integrations/google_drive","title":"Google Drive","description":"Google Drive is a file storage and synchronization service developed by Google.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/gutenberg":{"id":"modules/data_io/document_loaders/integrations/gutenberg","title":"Gutenberg","description":"Project Gutenberg is an online library of free eBooks.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/hacker_news":{"id":"modules/data_io/document_loaders/integrations/hacker_news","title":"Hacker News","description":"Hacker News (sometimes abbreviated as HN) is a social news website focusing on computer science and entrepreneurship. It is run by the investment fund and startup incubator Y Combinator. In general, content that can be submitted is defined as \\"anything that gratifies one\'s intellectual curiosity.\\"","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/hugging_face_dataset":{"id":"modules/data_io/document_loaders/integrations/hugging_face_dataset","title":"HuggingFace dataset","description":"The Hugging Face Hub is home to over 5,000 datasets in more than 100 languages that can be used for a broad range of tasks across NLP, Computer Vision, and Audio. They used for a diverse range of tasks such as translation,","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/ifixit":{"id":"modules/data_io/document_loaders/integrations/ifixit","title":"iFixit","description":"iFixit is the largest, open repair community on the web. The site contains nearly 100k repair manuals, 200k Questions & Answers on 42k devices, and all the data is licensed under CC-BY-NC-SA 3.0.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/image":{"id":"modules/data_io/document_loaders/integrations/image","title":"Images","description":"This covers how to load images such as JPG or PNG into a document format that we can use downstream.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/image_captions":{"id":"modules/data_io/document_loaders/integrations/image_captions","title":"Image captions","description":"By default, the loader utilizes the pre-trained Salesforce BLIP image captioning model.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/imsdb":{"id":"modules/data_io/document_loaders/integrations/imsdb","title":"IMSDb","description":"IMSDb is the Internet Movie Script Database.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/iugu":{"id":"modules/data_io/document_loaders/integrations/iugu","title":"Iugu","description":"Iugu is a Brazilian services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/joplin":{"id":"modules/data_io/document_loaders/integrations/joplin","title":"Joplin","description":"Joplin is an open source note-taking app. Capture your thoughts and securely access them from any device.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/jupyter_notebook":{"id":"modules/data_io/document_loaders/integrations/jupyter_notebook","title":"Jupyter Notebook","description":"Jupyter Notebook (formerly IPython Notebook) is a web-based interactive computational environment for creating notebook documents.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/mastodon":{"id":"modules/data_io/document_loaders/integrations/mastodon","title":"Mastodon","description":"Mastodon is a federated social media and social networking service.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/mediawikidump":{"id":"modules/data_io/document_loaders/integrations/mediawikidump","title":"MediaWikiDump","description":"MediaWiki XML Dumps contain the content of a wiki (wiki pages with all their revisions), without the site-related data. A XML dump does not create a full backup of the wiki database, the dump does not contain user accounts, images, edit logs, etc.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/microsoft_onedrive":{"id":"modules/data_io/document_loaders/integrations/microsoft_onedrive","title":"Microsoft OneDrive","description":"Microsoft OneDrive (formerly SkyDrive) is a file hosting service operated by Microsoft.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/microsoft_powerpoint":{"id":"modules/data_io/document_loaders/integrations/microsoft_powerpoint","title":"Microsoft PowerPoint","description":"Microsoft PowerPoint is a presentation program by Microsoft.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/microsoft_word":{"id":"modules/data_io/document_loaders/integrations/microsoft_word","title":"Microsoft Word","description":"Microsoft Word is a word processor developed by Microsoft.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/modern_treasury":{"id":"modules/data_io/document_loaders/integrations/modern_treasury","title":"Modern Treasury","description":"Modern Treasury simplifies complex payment operations. It is a unified platform to power products and processes that move money.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/notion":{"id":"modules/data_io/document_loaders/integrations/notion","title":"Notion DB 1/2","description":"Notion is a collaboration platform with modified Markdown support that integrates kanban boards, tasks, wikis and databases. It is an all-in-one workspace for notetaking, knowledge and data management, and project and task management.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/notiondb":{"id":"modules/data_io/document_loaders/integrations/notiondb","title":"Notion DB 2/2","description":"Notion is a collaboration platform with modified Markdown support that integrates kanban boards, tasks, wikis and databases. It is an all-in-one workspace for notetaking, knowledge and data management, and project and task management.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/obsidian":{"id":"modules/data_io/document_loaders/integrations/obsidian","title":"Obsidian","description":"Obsidian is a powerful and extensible knowledge base","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/odt":{"id":"modules/data_io/document_loaders/integrations/odt","title":"Open Document Format (ODT)","description":"The Open Document Format for Office Applications (ODF), also known as OpenDocument, is an open file format for word processing documents, spreadsheets, presentations and graphics and using ZIP-compressed XML files. It was developed with the aim of providing an open, XML-based file format specification for office applications.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/pandas_dataframe":{"id":"modules/data_io/document_loaders/integrations/pandas_dataframe","title":"Pandas DataFrame","description":"This notebook goes over how to load data from a pandas DataFrame.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/psychic":{"id":"modules/data_io/document_loaders/integrations/psychic","title":"Psychic","description":"This notebook covers how to load documents from Psychic. See here for more details.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/pyspark_dataframe":{"id":"modules/data_io/document_loaders/integrations/pyspark_dataframe","title":"PySpark DataFrame Loader","description":"This notebook goes over how to load data from a PySpark DataFrame.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/readthedocs_documentation":{"id":"modules/data_io/document_loaders/integrations/readthedocs_documentation","title":"ReadTheDocs Documentation","description":"Read the Docs is an open-sourced free software documentation hosting platform. It generates documentation written with the Sphinx documentation generator.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/reddit":{"id":"modules/data_io/document_loaders/integrations/reddit","title":"Reddit","description":"Reddit is an American social news aggregation, content rating, and discussion website.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/roam":{"id":"modules/data_io/document_loaders/integrations/roam","title":"Roam","description":"ROAM is a note-taking tool for networked thought, designed to create a personal knowledge base.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/sitemap":{"id":"modules/data_io/document_loaders/integrations/sitemap","title":"Sitemap","description":"Extends from the WebBaseLoader, SitemapLoader loads a sitemap from a given URL, and then scrape and load all pages in the sitemap, returning each page as a Document.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/slack":{"id":"modules/data_io/document_loaders/integrations/slack","title":"Slack","description":"Slack is an instant messaging program.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/spreedly":{"id":"modules/data_io/document_loaders/integrations/spreedly","title":"Spreedly","description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/stripe":{"id":"modules/data_io/document_loaders/integrations/stripe","title":"Stripe","description":"Stripe is an Irish-American financial services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/subtitle":{"id":"modules/data_io/document_loaders/integrations/subtitle","title":"Subtitle","description":"The SubRip file format is described on the Matroska multimedia container format website as \\"perhaps the most basic of all subtitle formats.\\" SubRip (SubRip Text) files are named with the extension .srt, and contain formatted lines of plain text in groups separated by a blank line. Subtitles are numbered sequentially, starting at 1. The timecode format used is hoursseconds,milliseconds with time units fixed to two zero-padded digits and fractions fixed to three zero-padded digits (0000,000). The fractional separator used is the comma, since the program was written in France.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/telegram":{"id":"modules/data_io/document_loaders/integrations/telegram","title":"Telegram","description":"Telegram Messenger is a globally accessible freemium, cross-platform, encrypted, cloud-based and centralized instant messaging service. The application also provides optional end-to-end encrypted chats and video calling, VoIP, file sharing and several other features.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/tomarkdown":{"id":"modules/data_io/document_loaders/integrations/tomarkdown","title":"2Markdown","description":"2markdown service transforms website content into structured markdown files.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/toml":{"id":"modules/data_io/document_loaders/integrations/toml","title":"TOML","description":"TOML is a file format for configuration files. It is intended to be easy to read and write, and is designed to map unambiguously to a dictionary. Its specification is open-source. TOML is implemented in many programming languages. The name TOML is an acronym for \\"Tom\'s Obvious, Minimal Language\\" referring to its creator, Tom Preston-Werner.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/trello":{"id":"modules/data_io/document_loaders/integrations/trello","title":"Trello","description":"Trello is a web-based project management and collaboration tool that allows individuals and teams to organize and track their tasks and projects. It provides a visual interface known as a \\"board\\" where users can create lists and cards to represent their tasks and activities.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/twitter":{"id":"modules/data_io/document_loaders/integrations/twitter","title":"Twitter","description":"Twitter is an online social media and social networking service.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/unstructured_file":{"id":"modules/data_io/document_loaders/integrations/unstructured_file","title":"Unstructured File","description":"This notebook covers how to use Unstructured package to load files of many types. Unstructured currently supports loading of text files, powerpoints, html, pdfs, images, and more.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/url":{"id":"modules/data_io/document_loaders/integrations/url","title":"URL","description":"This covers how to load HTML documents from a list of URLs into a document format that we can use downstream.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/weather":{"id":"modules/data_io/document_loaders/integrations/weather","title":"Weather","description":"OpenWeatherMap is an open source weather service provider","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/web_base":{"id":"modules/data_io/document_loaders/integrations/web_base","title":"WebBaseLoader","description":"This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/whatsapp_chat":{"id":"modules/data_io/document_loaders/integrations/whatsapp_chat","title":"WhatsApp Chat","description":"WhatsApp (also called WhatsApp Messenger) is a freeware, cross-platform, centralized instant messaging (IM) and voice-over-IP (VoIP) service. It allows users to send text and voice messages, make voice and video calls, and share images, documents, user locations, and other content.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/wikipedia":{"id":"modules/data_io/document_loaders/integrations/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"sidebar"},"modules/data_io/document_loaders/integrations/youtube_transcript":{"id":"modules/data_io/document_loaders/integrations/youtube_transcript","title":"YouTube transcripts","description":"YouTube is an online video sharing and social media platform created by Google.","sidebar":"sidebar"},"modules/data_io/document_transformers/index":{"id":"modules/data_io/document_transformers/index","title":"Document transformers","description":"Once you\'ve loaded documents, you\'ll often want to transform them to better suit your application. The simplest example","sidebar":"sidebar"},"modules/data_io/document_transformers/text_splitters/character_text_splitter":{"id":"modules/data_io/document_transformers/text_splitters/character_text_splitter","title":"Split by character","description":"This is the simplest method. This splits based on characters (by default \\"\\\\n\\\\n\\") and measure chunk length by number of characters.","sidebar":"sidebar"},"modules/data_io/document_transformers/text_splitters/code_splitter":{"id":"modules/data_io/document_transformers/text_splitters/code_splitter","title":"Split code","description":"CodeTextSplitter allows you to split your code with multiple language support. Import enum Language and specify the language.","sidebar":"sidebar"},"modules/data_io/document_transformers/text_splitters/recursive_text_splitter":{"id":"modules/data_io/document_transformers/text_splitters/recursive_text_splitter","title":"Recursively split by character","description":"This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\\"\\\\n\\\\n\\", \\"\\\\n\\", \\" \\", \\"\\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.","sidebar":"sidebar"},"modules/data_io/document_transformers/text_splitters/split_by_token":{"id":"modules/data_io/document_transformers/text_splitters/split_by_token","title":"Split by tokens","description":"Language models have a token limit. You should not exceed the token limit. When you split your text into chunks it is therefore a good idea to count the number of tokens. There are many tokenizers. When you count tokens in your text you should use the same tokenizer as used in the language model.","sidebar":"sidebar"},"modules/data_io/index":{"id":"modules/data_io/index","title":"Data connection","description":"Many LLM applications require user-specific data that is not part of the model\'s training set. LangChain gives you the","sidebar":"sidebar"},"modules/data_io/retrievers/how_to/contextual_compression/index":{"id":"modules/data_io/retrievers/how_to/contextual_compression/index","title":"Contextual compression","description":"One challenge with retrieval is that usually you don\'t know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.","sidebar":"sidebar"},"modules/data_io/retrievers/how_to/self_query/chroma_self_query":{"id":"modules/data_io/retrievers/how_to/self_query/chroma_self_query","title":"Self-querying with Chroma","description":"Chroma is a database for building AI applications with embeddings.","sidebar":"sidebar"},"modules/data_io/retrievers/how_to/self_query/index":{"id":"modules/data_io/retrievers/how_to/self_query/index","title":"Self-querying","description":"A self-querying retriever is one that, as the name suggests, has the ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a structured query and then applies that structured query to it\'s underlying VectorStore. This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documented, but to also extract filters from the user query on the metadata of stored documents and to execute those filters.","sidebar":"sidebar"},"modules/data_io/retrievers/how_to/self_query/pinecone":{"id":"modules/data_io/retrievers/how_to/self_query/pinecone","title":"Self-querying with Pinecone","description":"In the walkthrough we\'ll demo the SelfQueryRetriever with a Pinecone vector store.","sidebar":"sidebar"},"modules/data_io/retrievers/how_to/self_query/qdrant_self_query":{"id":"modules/data_io/retrievers/how_to/self_query/qdrant_self_query","title":"Self-querying with Qdrant","description":"Qdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful","sidebar":"sidebar"},"modules/data_io/retrievers/how_to/self_query/weaviate_self_query":{"id":"modules/data_io/retrievers/how_to/self_query/weaviate_self_query","title":"Self-querying with Weaviate","description":"Creating a Weaviate vectorstore","sidebar":"sidebar"},"modules/data_io/retrievers/how_to/time_weighted_vectorstore":{"id":"modules/data_io/retrievers/how_to/time_weighted_vectorstore","title":"Time-weighted vector store retriever","description":"This retriever uses a combination of semantic similarity and a time decay.","sidebar":"sidebar"},"modules/data_io/retrievers/how_to/vectorstore":{"id":"modules/data_io/retrievers/how_to/vectorstore","title":"Vector store-backed retriever","description":"A vector store retriever is a retriever that uses a vector store to retrieve documents. It is a lightweight wrapper around the Vector Store class to make it conform to the Retriever interface.","sidebar":"sidebar"},"modules/data_io/retrievers/index":{"id":"modules/data_io/retrievers/index","title":"Retrievers","description":"A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/arxiv":{"id":"modules/data_io/retrievers/integrations/arxiv","title":"Arxiv","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/azure_cognitive_search":{"id":"modules/data_io/retrievers/integrations/azure_cognitive_search","title":"Azure Cognitive Search","description":"Azure Cognitive Search (formerly known as Azure Search) is a cloud search service that gives developers infrastructure, APIs, and tools for building a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/chatgpt-plugin":{"id":"modules/data_io/retrievers/integrations/chatgpt-plugin","title":"ChatGPT Plugin","description":"OpenAI plugins connect ChatGPT to third-party applications. These plugins enable ChatGPT to interact with APIs defined by developers, enhancing ChatGPT\'s capabilities and allowing it to perform a wide range of actions.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/cohere-reranker":{"id":"modules/data_io/retrievers/integrations/cohere-reranker","title":"Cohere Reranker","description":"Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/databerry":{"id":"modules/data_io/retrievers/integrations/databerry","title":"Databerry","description":"Databerry platform brings data from anywhere (Datsources: Text, PDF, Word, PowerPpoint, Excel, Notion, Airtable, Google Sheets, etc..) into Datastores (container of multiple Datasources).","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/elastic_search_bm25":{"id":"modules/data_io/retrievers/integrations/elastic_search_bm25","title":"ElasticSearch BM25","description":"Elasticsearch is a distributed, RESTful search and analytics engine. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/knn":{"id":"modules/data_io/retrievers/integrations/knn","title":"kNN","description":"In statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover. It is used for classification and regression.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/metal":{"id":"modules/data_io/retrievers/integrations/metal","title":"Metal","description":"Metal is a managed service for ML Embeddings.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/pinecone_hybrid_search":{"id":"modules/data_io/retrievers/integrations/pinecone_hybrid_search","title":"Pinecone Hybrid Search","description":"Pinecone is a vector database with broad functionality.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/pubmed":{"id":"modules/data_io/retrievers/integrations/pubmed","title":"PubMed Retriever","description":"This notebook goes over how to use PubMed as a retriever","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/svm":{"id":"modules/data_io/retrievers/integrations/svm","title":"SVM","description":"Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/tf_idf":{"id":"modules/data_io/retrievers/integrations/tf_idf","title":"TF-IDF","description":"TF-IDF means term-frequency times inverse document-frequency.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/vespa":{"id":"modules/data_io/retrievers/integrations/vespa","title":"Vespa","description":"Vespa is a fully featured search engine and vector database. It supports vector search (ANN), lexical search, and search in structured data, all in the same query.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/weaviate-hybrid":{"id":"modules/data_io/retrievers/integrations/weaviate-hybrid","title":"Weaviate Hybrid Search","description":"Weaviate is an open source vector database.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/wikipedia":{"id":"modules/data_io/retrievers/integrations/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"sidebar"},"modules/data_io/retrievers/integrations/zep_memorystore":{"id":"modules/data_io/retrievers/integrations/zep_memorystore","title":"Zep","description":"Zep - A long-term memory store for LLM applications.","sidebar":"sidebar"},"modules/data_io/text_embedding/index":{"id":"modules/data_io/text_embedding/index","title":"Text embedding models","description":"The Embeddings class is a class designed for interfacing with text embedding models. There are lots of embedding model providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/aleph_alpha":{"id":"modules/data_io/text_embedding/integrations/aleph_alpha","title":"Aleph Alpha","description":"There are two possible ways to use Aleph Alpha\'s semantic embeddings. If you have texts with a dissimilar structure (e.g. a Document and a Query) you would want to use asymmetric embeddings. Conversely, for texts with comparable structures, symmetric embeddings are the suggested approach.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/azureopenai":{"id":"modules/data_io/text_embedding/integrations/azureopenai","title":"AzureOpenAI","description":"Let\'s load the OpenAI Embedding class with environment variables set to indicate to use Azure endpoints.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/bedrock":{"id":"modules/data_io/text_embedding/integrations/bedrock","title":"Bedrock Embeddings","description":"","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/cohere":{"id":"modules/data_io/text_embedding/integrations/cohere","title":"Cohere","description":"Let\'s load the Cohere Embedding class.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/elasticsearch":{"id":"modules/data_io/text_embedding/integrations/elasticsearch","title":"Elasticsearch","description":"Walkthrough of how to generate embeddings using a hosted embedding model in Elasticsearch","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/fake":{"id":"modules/data_io/text_embedding/integrations/fake","title":"Fake Embeddings","description":"LangChain also provides a fake embedding class. You can use this to test your pipelines.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/google_vertex_ai_palm":{"id":"modules/data_io/text_embedding/integrations/google_vertex_ai_palm","title":"Google Cloud Platform Vertex AI PaLM","description":"Note: This is seperate from the Google PaLM integration. Google has chosen to offer an enterprise version of PaLM through GCP, and this supports the models made available through there.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/huggingfacehub":{"id":"modules/data_io/text_embedding/integrations/huggingfacehub","title":"Hugging Face Hub","description":"Let\'s load the Hugging Face Embedding class.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/instruct_embeddings":{"id":"modules/data_io/text_embedding/integrations/instruct_embeddings","title":"InstructEmbeddings","description":"Let\'s load the HuggingFace instruct Embeddings class.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/jina":{"id":"modules/data_io/text_embedding/integrations/jina","title":"Jina","description":"Let\'s load the Jina Embedding class.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/llamacpp":{"id":"modules/data_io/text_embedding/integrations/llamacpp","title":"Llama-cpp","description":"This notebook goes over how to use Llama-cpp embeddings within LangChain","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/minimax":{"id":"modules/data_io/text_embedding/integrations/minimax","title":"MiniMax","description":"MiniMax offers an embeddings service.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/modelscope_hub":{"id":"modules/data_io/text_embedding/integrations/modelscope_hub","title":"ModelScope","description":"Let\'s load the ModelScope Embedding class.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/mosaicml":{"id":"modules/data_io/text_embedding/integrations/mosaicml","title":"MosaicML embeddings","description":"MosaicML offers a managed inference service. You can either use a variety of open source models, or deploy your own.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/openai":{"id":"modules/data_io/text_embedding/integrations/openai","title":"OpenAI","description":"Let\'s load the OpenAI Embedding class.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/sagemaker-endpoint":{"id":"modules/data_io/text_embedding/integrations/sagemaker-endpoint","title":"SageMaker Endpoint Embeddings","description":"Let\'s load the SageMaker Endpoints Embeddings class. The class can be used if you host, e.g. your own Hugging Face model on SageMaker.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/self-hosted":{"id":"modules/data_io/text_embedding/integrations/self-hosted","title":"Self Hosted Embeddings","description":"Let\'s load the SelfHostedEmbeddings, SelfHostedHuggingFaceEmbeddings, and SelfHostedHuggingFaceInstructEmbeddings classes.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/sentence_transformers":{"id":"modules/data_io/text_embedding/integrations/sentence_transformers","title":"Sentence Transformers Embeddings","description":"SentenceTransformers embeddings are called using the HuggingFaceEmbeddings integration. We have also added an alias for SentenceTransformerEmbeddings for users who are more familiar with directly using that package.","sidebar":"sidebar"},"modules/data_io/text_embedding/integrations/tensorflowhub":{"id":"modules/data_io/text_embedding/integrations/tensorflowhub","title":"TensorflowHub","description":"Let\'s load the TensorflowHub Embedding class.","sidebar":"sidebar"},"modules/data_io/vectorstores/index":{"id":"modules/data_io/vectorstores/index","title":"Vector stores","description":"One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/analyticdb":{"id":"modules/data_io/vectorstores/integrations/analyticdb","title":"AnalyticDB","description":"AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/annoy":{"id":"modules/data_io/vectorstores/integrations/annoy","title":"Annoy","description":"Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mmapped into memory so that many processes may share the same data.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/atlas":{"id":"modules/data_io/vectorstores/integrations/atlas","title":"Atlas","description":"Atlas is a platform for interacting with both small and internet scale unstructured datasets by Nomic.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/chroma":{"id":"modules/data_io/vectorstores/integrations/chroma","title":"Chroma","description":"Chroma is a database for building AI applications with embeddings.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/deeplake":{"id":"modules/data_io/vectorstores/integrations/deeplake","title":"Deep Lake","description":"Deep Lake as a Multi-Modal Vector Store that stores embeddings and their metadata including text, jsons, images, audio, video, and more. It saves the data locally, in your cloud, or on Activeloop storage. It performs hybrid search including embeddings and their attributes.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/docarray_hnsw":{"id":"modules/data_io/vectorstores/integrations/docarray_hnsw","title":"DocArrayHnswSearch","description":"DocArrayHnswSearch is a lightweight Document Index implementation provided by Docarray that runs fully locally and is best suited for small- to medium-sized datasets. It stores vectors on disk in hnswlib, and stores all other data in SQLite.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/docarray_in_memory":{"id":"modules/data_io/vectorstores/integrations/docarray_in_memory","title":"DocArrayInMemorySearch","description":"DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory. It is a great starting point for small datasets, where you may not want to launch a database server.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/elasticsearch":{"id":"modules/data_io/vectorstores/integrations/elasticsearch","title":"ElasticSearch","description":"Elasticsearch is a distributed, RESTful search and analytics engine. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/faiss":{"id":"modules/data_io/vectorstores/integrations/faiss","title":"FAISS","description":"Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/lancedb":{"id":"modules/data_io/vectorstores/integrations/lancedb","title":"LanceDB","description":"LanceDB is an open-source database for vector-search built with persistent storage, which greatly simplifies retrevial, filtering and management of embeddings. Fully open source.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/matchingengine":{"id":"modules/data_io/vectorstores/integrations/matchingengine","title":"MatchingEngine","description":"This notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/milvus":{"id":"modules/data_io/vectorstores/integrations/milvus","title":"Milvus","description":"Milvus is a database that stores, indexes, and manages massive embedding vectors generated by deep neural networks and other machine learning (ML) models.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/mongodb_atlas_vector_search":{"id":"modules/data_io/vectorstores/integrations/mongodb_atlas_vector_search","title":"MongoDB Atlas Vector Search","description":"MongoDB Atlas is a document database managed in the cloud. It also enables Lucene and its vector search feature.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/myscale":{"id":"modules/data_io/vectorstores/integrations/myscale","title":"MyScale","description":"MyScale is a cloud-based database optimized for AI applications and solutions, built on the open-source ClickHouse.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/opensearch":{"id":"modules/data_io/vectorstores/integrations/opensearch","title":"OpenSearch","description":"OpenSearch is a scalable, flexible, and extensible open-source software suite for search, analytics, and observability applications licensed under Apache 2.0. OpenSearch is a distributed search and analytics engine based on Apache Lucene.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/pgvector":{"id":"modules/data_io/vectorstores/integrations/pgvector","title":"PGVector","description":"PGVector is an open-source vector similarity search for Postgres","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/pinecone":{"id":"modules/data_io/vectorstores/integrations/pinecone","title":"Pinecone","description":"Pinecone is a vector database with broad functionality.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/qdrant":{"id":"modules/data_io/vectorstores/integrations/qdrant","title":"Qdrant","description":"Qdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/redis":{"id":"modules/data_io/vectorstores/integrations/redis","title":"Redis","description":"Redis (Remote Dictionary Server) is an in-memory data structure store, used as a distributed, in-memory key\u2013value database, cache and message broker, with optional durability.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/sklearn":{"id":"modules/data_io/vectorstores/integrations/sklearn","title":"SKLearnVectorStore","description":"scikit-learn is an open source collection of machine learning algorithms, including some implementations of the k nearest neighbors. SKLearnVectorStore wraps this implementation and adds the possibility to persist the vector store in json, bson (binary json) or Apache Parquet format.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/supabase":{"id":"modules/data_io/vectorstores/integrations/supabase","title":"Supabase (Postgres)","description":"Supabase is an open source Firebase alternative. Supabase is built on top of PostgreSQL, which offers strong SQL querying capabilities and enables a simple interface with already-existing tools and frameworks.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/tair":{"id":"modules/data_io/vectorstores/integrations/tair","title":"Tair","description":"Tair is a cloud native in-memory database service developed by Alibaba Cloud.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/typesense":{"id":"modules/data_io/vectorstores/integrations/typesense","title":"Typesense","description":"Typesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/vectara":{"id":"modules/data_io/vectorstores/integrations/vectara","title":"Vectara","description":"Vectara is a API platform for building LLM-powered applications. It provides a simple to use API for document indexing and query that is managed by Vectara and is optimized for performance and accuracy.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/weaviate":{"id":"modules/data_io/vectorstores/integrations/weaviate","title":"Weaviate","description":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML-models, and scale seamlessly into billions of data objects.","sidebar":"sidebar"},"modules/data_io/vectorstores/integrations/zilliz":{"id":"modules/data_io/vectorstores/integrations/zilliz","title":"Zilliz","description":"Zilliz Cloud is a fully managed service on cloud for LF AI Milvus\xae,","sidebar":"sidebar"},"modules/memory/how_to/adding_memory":{"id":"modules/memory/how_to/adding_memory","title":"How to add Memory to an LLMChain","description":"This notebook goes over how to use the Memory class with an LLMChain. For the purposes of this walkthrough, we will add  the ConversationBufferMemory class, although this can be any memory class.","sidebar":"sidebar"},"modules/memory/how_to/adding_memory_chain_multiple_inputs":{"id":"modules/memory/how_to/adding_memory_chain_multiple_inputs","title":"How to add memory to a Multi-Input Chain","description":"Most memory objects assume a single input. In this notebook, we go over how to add memory to a chain that has multiple inputs. As an example of such a chain, we will add memory to a question/answering chain. This chain takes as inputs both related documents and a user question.","sidebar":"sidebar"},"modules/memory/how_to/agent_with_memory":{"id":"modules/memory/how_to/agent_with_memory","title":"How to add Memory to an Agent","description":"This notebook goes over adding memory to an Agent. Before going through this notebook, please walkthrough the following notebooks, as this will build on top of both of them:","sidebar":"sidebar"},"modules/memory/how_to/agent_with_memory_in_db":{"id":"modules/memory/how_to/agent_with_memory_in_db","title":"Adding Message Memory backed by a database to an Agent","description":"This notebook goes over adding memory to an Agent where the memory uses an external message store. Before going through this notebook, please walkthrough the following notebooks, as this will build on top of both of them:","sidebar":"sidebar"},"modules/memory/how_to/buffer":{"id":"modules/memory/how_to/buffer","title":"Conversation buffer memory","description":"This notebook shows how to use ConversationBufferMemory. This memory allows for storing of messages and then extracts the messages in a variable.","sidebar":"sidebar"},"modules/memory/how_to/buffer_window":{"id":"modules/memory/how_to/buffer_window","title":"Conversation buffer window memory","description":"ConversationBufferWindowMemory keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large","sidebar":"sidebar"},"modules/memory/how_to/conversational_customization":{"id":"modules/memory/how_to/conversational_customization","title":"How to customize conversational memory","description":"This notebook walks through a few ways to customize conversational memory.","sidebar":"sidebar"},"modules/memory/how_to/custom_memory":{"id":"modules/memory/how_to/custom_memory","title":"How to create a custom Memory class","description":"Although there are a few predefined types of memory in LangChain, it is highly possible you will want to add your own type of memory that is optimal for your application. This notebook covers how to do that.","sidebar":"sidebar"},"modules/memory/how_to/entity_summary_memory":{"id":"modules/memory/how_to/entity_summary_memory","title":"Entity memory","description":"Entity Memory remembers given facts about specific entities in a conversation. It extracts information on entities (using an LLM) and builds up its knowledge about that entity over time (also using an LLM).","sidebar":"sidebar"},"modules/memory/how_to/kg":{"id":"modules/memory/how_to/kg","title":"Conversation Knowledge Graph Memory","description":"This type of memory uses a knowledge graph to recreate memory.","sidebar":"sidebar"},"modules/memory/how_to/multiple_memory":{"id":"modules/memory/how_to/multiple_memory","title":"How to use multiple memory classes in the same chain","description":"It is also possible to use multiple memory classes in the same chain. To combine multiple memory classes, we can initialize the CombinedMemory class, and then use that.","sidebar":"sidebar"},"modules/memory/how_to/summary":{"id":"modules/memory/how_to/summary","title":"Conversation summary memory","description":"Now let\'s take a look at using a slightly more complex type of memory - ConversationSummaryMemory. This type of memory creates a summary of the conversation over time. This can be useful for condensing information from the conversation over time.","sidebar":"sidebar"},"modules/memory/how_to/summary_buffer":{"id":"modules/memory/how_to/summary_buffer","title":"ConversationSummaryBufferMemory","description":"ConversationSummaryBufferMemory combines the last two ideas. It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both. Unlike the previous implementation though, it uses token length rather than number of interactions to determine when to flush interactions.","sidebar":"sidebar"},"modules/memory/how_to/token_buffer":{"id":"modules/memory/how_to/token_buffer","title":"ConversationTokenBufferMemory","description":"ConversationTokenBufferMemory keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions.","sidebar":"sidebar"},"modules/memory/how_to/vectorstore_retriever_memory":{"id":"modules/memory/how_to/vectorstore_retriever_memory","title":"Vector store-backed memory","description":"VectorStoreRetrieverMemory stores memories in a VectorDB and queries the top-K most \\"salient\\" docs every time it is called.","sidebar":"sidebar"},"modules/memory/index":{"id":"modules/memory/index","title":"Memory","description":"By default, Chains and Agents are stateless,","sidebar":"sidebar"},"modules/memory/integrations/cassandra_chat_message_history":{"id":"modules/memory/integrations/cassandra_chat_message_history","title":"Cassandra Chat Message History","description":"This notebook goes over how to use Cassandra to store chat message history.","sidebar":"sidebar"},"modules/memory/integrations/dynamodb_chat_message_history":{"id":"modules/memory/integrations/dynamodb_chat_message_history","title":"Dynamodb Chat Message History","description":"This notebook goes over how to use Dynamodb to store chat message history.","sidebar":"sidebar"},"modules/memory/integrations/entity_memory_with_sqlite":{"id":"modules/memory/integrations/entity_memory_with_sqlite","title":"Entity Memory with SQLite storage","description":"In this walkthrough we\'ll create a simple conversation chain which uses ConversationEntityMemory backed by a SqliteEntityStore.","sidebar":"sidebar"},"modules/memory/integrations/momento_chat_message_history":{"id":"modules/memory/integrations/momento_chat_message_history","title":"Momento Chat Message History","description":"This notebook goes over how to use Momento Cache to store chat message history using the MomentoChatMessageHistory class. See the Momento docs for more detail on how to get set up with Momento.","sidebar":"sidebar"},"modules/memory/integrations/mongodb_chat_message_history":{"id":"modules/memory/integrations/mongodb_chat_message_history","title":"Mongodb Chat Message History","description":"This notebook goes over how to use Mongodb to store chat message history.","sidebar":"sidebar"},"modules/memory/integrations/motorhead_memory":{"id":"modules/memory/integrations/motorhead_memory","title":"Mot\xf6rhead Memory","description":"Mot\xf6rhead is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications.","sidebar":"sidebar"},"modules/memory/integrations/motorhead_memory_managed":{"id":"modules/memory/integrations/motorhead_memory_managed","title":"Mot\xf6rhead Memory (Managed)","description":"Mot\xf6rhead is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications.","sidebar":"sidebar"},"modules/memory/integrations/postgres_chat_message_history":{"id":"modules/memory/integrations/postgres_chat_message_history","title":"Postgres Chat Message History","description":"This notebook goes over how to use Postgres to store chat message history.","sidebar":"sidebar"},"modules/memory/integrations/redis_chat_message_history":{"id":"modules/memory/integrations/redis_chat_message_history","title":"Redis Chat Message History","description":"This notebook goes over how to use Redis to store chat message history.","sidebar":"sidebar"},"modules/memory/integrations/zep_memory":{"id":"modules/memory/integrations/zep_memory","title":"Zep Memory","description":"REACT Agent Chat Message History Example","sidebar":"sidebar"},"modules/model_io/index":{"id":"modules/model_io/index","title":"Model I/O","description":"The core element of any language model application is...the model. LangChain gives you the building blocks to interface with any language model.","sidebar":"sidebar"},"modules/model_io/models/chat/how_to/llm_chain":{"id":"modules/model_io/models/chat/how_to/llm_chain","title":"LLMChain","description":"You can use the existing LLMChain in a very similar way to before - provide a prompt and a model.","sidebar":"sidebar"},"modules/model_io/models/chat/how_to/prompts":{"id":"modules/model_io/models/chat/how_to/prompts","title":"Prompts","description":"Prompts for Chat models are built around messages, instead of just plain text.","sidebar":"sidebar"},"modules/model_io/models/chat/how_to/streaming":{"id":"modules/model_io/models/chat/how_to/streaming","title":"Streaming","description":"Some Chat models provide a streaming response. This means that instead of waiting for the entire response to be returned, you can start processing it as soon as it\'s available. This is useful if you want to display the response to the user as it\'s being generated, or if you want to process the response as it\'s being generated.","sidebar":"sidebar"},"modules/model_io/models/chat/index":{"id":"modules/model_io/models/chat/index","title":"Chat models","description":"Chat models are a variation on language models.","sidebar":"sidebar"},"modules/model_io/models/chat/integrations/anthropic":{"id":"modules/model_io/models/chat/integrations/anthropic","title":"Anthropic","description":"This notebook covers how to get started with Anthropic chat models.","sidebar":"sidebar"},"modules/model_io/models/chat/integrations/azure_chat_openai":{"id":"modules/model_io/models/chat/integrations/azure_chat_openai","title":"Azure","description":"This notebook goes over how to connect to an Azure hosted OpenAI endpoint","sidebar":"sidebar"},"modules/model_io/models/chat/integrations/google_vertex_ai_palm":{"id":"modules/model_io/models/chat/integrations/google_vertex_ai_palm","title":"Google Cloud Platform Vertex AI PaLM","description":"Note: This is seperate from the Google PaLM integration. Google has chosen to offer an enterprise version of PaLM through GCP, and this supports the models made available through there.","sidebar":"sidebar"},"modules/model_io/models/chat/integrations/openai":{"id":"modules/model_io/models/chat/integrations/openai","title":"OpenAI","description":"This notebook covers how to get started with OpenAI chat models.","sidebar":"sidebar"},"modules/model_io/models/chat/integrations/promptlayer_chatopenai":{"id":"modules/model_io/models/chat/integrations/promptlayer_chatopenai","title":"PromptLayer ChatOpenAI","description":"This example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.","sidebar":"sidebar"},"modules/model_io/models/index":{"id":"modules/model_io/models/index","title":"Language models","description":"LangChain provides interfaces and integrations for two types of models:","sidebar":"sidebar"},"modules/model_io/models/llms/how_to/async_llm":{"id":"modules/model_io/models/llms/how_to/async_llm","title":"Async API","description":"LangChain provides async support for LLMs by leveraging the asyncio library.","sidebar":"sidebar"},"modules/model_io/models/llms/how_to/custom_llm":{"id":"modules/model_io/models/llms/how_to/custom_llm","title":"Custom LLM","description":"This notebook goes over how to create a custom LLM wrapper, in case you want to use your own LLM or a different wrapper than one that is supported in LangChain.","sidebar":"sidebar"},"modules/model_io/models/llms/how_to/fake_llm":{"id":"modules/model_io/models/llms/how_to/fake_llm","title":"Fake LLM","description":"We expose a fake LLM class that can be used for testing. This allows you to mock out calls to the LLM and simulate what would happen if the LLM responded in a certain way.","sidebar":"sidebar"},"modules/model_io/models/llms/how_to/human_input_llm":{"id":"modules/model_io/models/llms/how_to/human_input_llm","title":"Human input LLM","description":"Similar to the fake LLM, LangChain provides a pseudo LLM class that can be used for testing, debugging, or educational purposes. This allows you to mock out calls to the LLM and simulate how a human would respond if they received the prompts.","sidebar":"sidebar"},"modules/model_io/models/llms/how_to/llm_caching":{"id":"modules/model_io/models/llms/how_to/llm_caching","title":"Caching","description":"LangChain provides an optional caching layer for LLMs. This is useful for two reasons:","sidebar":"sidebar"},"modules/model_io/models/llms/how_to/llm_serialization":{"id":"modules/model_io/models/llms/how_to/llm_serialization","title":"Serialization","description":"This notebook walks through how to write and read an LLM Configuration to and from disk. This is useful if you want to save the configuration for a given LLM (e.g., the provider, the temperature, etc).","sidebar":"sidebar"},"modules/model_io/models/llms/how_to/streaming_llm":{"id":"modules/model_io/models/llms/how_to/streaming_llm","title":"Streaming","description":"Some LLMs provide a streaming response. This means that instead of waiting for the entire response to be returned, you can start processing it as soon as it\'s available. This is useful if you want to display the response to the user as it\'s being generated, or if you want to process the response as it\'s being generated.","sidebar":"sidebar"},"modules/model_io/models/llms/how_to/token_usage_tracking":{"id":"modules/model_io/models/llms/how_to/token_usage_tracking","title":"Tracking token usage","description":"This notebook goes over how to track your token usage for specific calls. It is currently only implemented for the OpenAI API.","sidebar":"sidebar"},"modules/model_io/models/llms/index":{"id":"modules/model_io/models/llms/index","title":"LLMs","description":"Large Language Models (LLMs) are a core component of LangChain.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/ai21":{"id":"modules/model_io/models/llms/integrations/ai21","title":"AI21","description":"AI21 Studio provides API access to Jurassic-2 large language models.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/aleph_alpha":{"id":"modules/model_io/models/llms/integrations/aleph_alpha","title":"Aleph Alpha","description":"The Luminous series is a family of large language models.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/anyscale":{"id":"modules/model_io/models/llms/integrations/anyscale","title":"Anyscale","description":"Anyscale is a fully-managed Ray platform, on which you can build, deploy, and manage scalable AI and Python applications","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/azure_openai_example":{"id":"modules/model_io/models/llms/integrations/azure_openai_example","title":"Azure OpenAI","description":"This notebook goes over how to use Langchain with Azure OpenAI.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/banana":{"id":"modules/model_io/models/llms/integrations/banana","title":"Banana","description":"Banana is focused on building the machine learning infrastructure.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/beam":{"id":"modules/model_io/models/llms/integrations/beam","title":"Beam","description":"Calls the Beam API wrapper to deploy and make subsequent calls to an instance of the gpt2 LLM in a cloud deployment. Requires installation of the Beam library and registration of Beam Client ID and Client Secret. By calling the wrapper an instance of the model is created and run, with returned text relating to the prompt. Additional calls can then be made by directly calling the Beam API.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/bedrock":{"id":"modules/model_io/models/llms/integrations/bedrock","title":"Bedrock","description":"Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/cerebriumai_example":{"id":"modules/model_io/models/llms/integrations/cerebriumai_example","title":"CerebriumAI","description":"Cerebrium is an AWS Sagemaker alternative. It also provides API access to several LLM models.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/cohere":{"id":"modules/model_io/models/llms/integrations/cohere","title":"Cohere","description":"Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/ctransformers":{"id":"modules/model_io/models/llms/integrations/ctransformers","title":"C Transformers","description":"The C Transformers library provides Python bindings for GGML models.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/databricks":{"id":"modules/model_io/models/llms/integrations/databricks","title":"Databricks","description":"The Databricks Lakehouse Platform unifies data, analytics, and AI on one platform.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/deepinfra_example":{"id":"modules/model_io/models/llms/integrations/deepinfra_example","title":"DeepInfra","description":"DeepInfra provides several LLMs.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/forefrontai_example":{"id":"modules/model_io/models/llms/integrations/forefrontai_example","title":"ForefrontAI","description":"The Forefront platform gives you the ability to fine-tune and use open source large language models.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/google_vertex_ai_palm":{"id":"modules/model_io/models/llms/integrations/google_vertex_ai_palm","title":"Google Cloud Platform Vertex AI PaLM","description":"Note: This is seperate from the Google PaLM integration. Google has chosen to offer an enterprise version of PaLM through GCP, and this supports the models made available through there.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/gooseai_example":{"id":"modules/model_io/models/llms/integrations/gooseai_example","title":"GooseAI","description":"GooseAI is a fully managed NLP-as-a-Service, delivered via API. GooseAI provides access to these models.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/gpt4all":{"id":"modules/model_io/models/llms/integrations/gpt4all","title":"GPT4All","description":"GitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/huggingface_hub":{"id":"modules/model_io/models/llms/integrations/huggingface_hub","title":"Hugging Face Hub","description":"The Hugging Face Hub is a platform with over 120k models, 20k datasets, and 50k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/huggingface_pipelines":{"id":"modules/model_io/models/llms/integrations/huggingface_pipelines","title":"Hugging Face Local Pipelines","description":"Hugging Face models can be run locally through the HuggingFacePipeline class.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/huggingface_textgen_inference":{"id":"modules/model_io/models/llms/integrations/huggingface_textgen_inference","title":"Huggingface TextGen Inference","description":"Text Generation Inference is a Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/jsonformer_experimental":{"id":"modules/model_io/models/llms/integrations/jsonformer_experimental","title":"JSONFormer","description":"JSONFormer is a library that wraps local HuggingFace pipeline models for structured decoding of a subset of the JSON Schema.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/llamacpp":{"id":"modules/model_io/models/llms/integrations/llamacpp","title":"Llama-cpp","description":"llama-cpp is a Python binding for llama.cpp.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/llm_caching":{"id":"modules/model_io/models/llms/integrations/llm_caching","title":"Caching integrations","description":"This notebook covers how to cache results of individual LLM calls.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/manifest":{"id":"modules/model_io/models/llms/integrations/manifest","title":"Manifest","description":"This notebook goes over how to use Manifest and LangChain.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/modal":{"id":"modules/model_io/models/llms/integrations/modal","title":"Modal","description":"The Modal Python Library provides convenient, on-demand access to serverless cloud compute from Python scripts on your local computer.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/mosaicml":{"id":"modules/model_io/models/llms/integrations/mosaicml","title":"MosaicML","description":"MosaicML offers a managed inference service. You can either use a variety of open source models, or deploy your own.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/nlpcloud":{"id":"modules/model_io/models/llms/integrations/nlpcloud","title":"NLP Cloud","description":"The NLP Cloud serves high performance pre-trained or custom models for NER, sentiment-analysis, classification, summarization, paraphrasing, grammar and spelling correction, keywords and keyphrases extraction, chatbot, product description and ad generation, intent classification, text generation, image generation, blog post generation, code generation, question answering, automatic speech recognition, machine translation, language detection, semantic search, semantic similarity, tokenization, POS tagging, embeddings, and dependency parsing. It is ready for production, served through a REST API.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/openai":{"id":"modules/model_io/models/llms/integrations/openai","title":"OpenAI","description":"OpenAI offers a spectrum of models with different levels of power suitable for different tasks.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/openlm":{"id":"modules/model_io/models/llms/integrations/openlm","title":"OpenLM","description":"OpenLM is a zero-dependency OpenAI-compatible LLM provider that can call different inference endpoints directly via HTTP.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/petals_example":{"id":"modules/model_io/models/llms/integrations/petals_example","title":"Petals","description":"Petals runs 100B+ language models at home, BitTorrent-style.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/pipelineai_example":{"id":"modules/model_io/models/llms/integrations/pipelineai_example","title":"PipelineAI","description":"PipelineAI allows you to run your ML models at scale in the cloud. It also provides API access to several LLM models.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/predictionguard":{"id":"modules/model_io/models/llms/integrations/predictionguard","title":"Prediction Guard","description":"Basic LLM usage","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/promptlayer_openai":{"id":"modules/model_io/models/llms/integrations/promptlayer_openai","title":"PromptLayer OpenAI","description":"PromptLayer is the first platform that allows you to track, manage, and share your GPT prompt engineering. PromptLayer acts a middleware between your code and OpenAI\u2019s python library.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/rellm_experimental":{"id":"modules/model_io/models/llms/integrations/rellm_experimental","title":"RELLM","description":"RELLM is a library that wraps local Hugging Face pipeline models for structured decoding.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/replicate":{"id":"modules/model_io/models/llms/integrations/replicate","title":"Replicate","description":"Replicate runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you\'re building your own machine learning models, Replicate makes it easy to deploy them at scale.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/runhouse":{"id":"modules/model_io/models/llms/integrations/runhouse","title":"Runhouse","description":"The Runhouse allows remote compute and data across environments and users. See the Runhouse docs.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/sagemaker":{"id":"modules/model_io/models/llms/integrations/sagemaker","title":"SageMakerEndpoint","description":"Amazon SageMaker is a system that can build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/stochasticai":{"id":"modules/model_io/models/llms/integrations/stochasticai","title":"StochasticAI","description":"Stochastic Acceleration Platform aims to simplify the life cycle of a Deep Learning model. From uploading and versioning the model, through training, compression and acceleration to putting it into production.","sidebar":"sidebar"},"modules/model_io/models/llms/integrations/writer":{"id":"modules/model_io/models/llms/integrations/writer","title":"Writer","description":"Writer is a platform to generate different language content.","sidebar":"sidebar"},"modules/model_io/output_parsers/comma_separated":{"id":"modules/model_io/output_parsers/comma_separated","title":"List parser","description":"This output parser can be used when you want to return a list of comma-separated items.","sidebar":"sidebar"},"modules/model_io/output_parsers/datetime":{"id":"modules/model_io/output_parsers/datetime","title":"Datetime parser","description":"This OutputParser shows out to parse LLM output into datetime format.","sidebar":"sidebar"},"modules/model_io/output_parsers/enum":{"id":"modules/model_io/output_parsers/enum","title":"Enum parser","description":"This notebook shows how to use an Enum output parser","sidebar":"sidebar"},"modules/model_io/output_parsers/index":{"id":"modules/model_io/output_parsers/index","title":"Output parsers","description":"Language models output text. But many times you may want to get more structured information than just text back. This is where output parsers come in.","sidebar":"sidebar"},"modules/model_io/output_parsers/output_fixing_parser":{"id":"modules/model_io/output_parsers/output_fixing_parser","title":"Auto-fixing parser","description":"This output parser wraps another output parser, and in the event that the first one fails it calls out to another LLM to fix any errors.","sidebar":"sidebar"},"modules/model_io/output_parsers/pydantic":{"id":"modules/model_io/output_parsers/pydantic","title":"Pydantic (JSON) parser","description":"This output parser allows users to specify an arbitrary JSON schema and query LLMs for JSON outputs that conform to that schema.","sidebar":"sidebar"},"modules/model_io/output_parsers/retry":{"id":"modules/model_io/output_parsers/retry","title":"Retry parser","description":"While in some cases it is possible to fix any parsing mistakes by only looking at the output, in other cases it can\'t. An example of this is when the output is not just in the incorrect format, but is partially complete. Consider the below example.","sidebar":"sidebar"},"modules/model_io/output_parsers/structured":{"id":"modules/model_io/output_parsers/structured","title":"Structured output parser","description":"This output parser can be used when you want to return multiple fields. While the Pydantic/JSON parser is more powerful, we initially experimented with data structures having text fields only.","sidebar":"sidebar"},"modules/model_io/prompts/example_selectors/custom_example_selector":{"id":"modules/model_io/prompts/example_selectors/custom_example_selector","title":"Custom example selector","description":"In this tutorial, we\'ll create a custom example selector that selects every alternate example from a given list of examples.","sidebar":"sidebar"},"modules/model_io/prompts/example_selectors/index":{"id":"modules/model_io/prompts/example_selectors/index","title":"Example selectors","description":"If you have a large number of examples, you may need to select which ones to include in the prompt. The Example Selector is the class responsible for doing so.","sidebar":"sidebar"},"modules/model_io/prompts/example_selectors/length_based":{"id":"modules/model_io/prompts/example_selectors/length_based","title":"Select by length","description":"This example selector selects which examples to use based on length. This is useful when you are worried about constructing a prompt that will go over the length of the context window. For longer inputs, it will select fewer examples to include, while for shorter inputs it will select more.","sidebar":"sidebar"},"modules/model_io/prompts/example_selectors/mmr":{"id":"modules/model_io/prompts/example_selectors/mmr","title":"Select by maximal marginal relevance (MMR)","description":"The MaxMarginalRelevanceExampleSelector selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.","sidebar":"sidebar"},"modules/model_io/prompts/example_selectors/ngram_overlap":{"id":"modules/model_io/prompts/example_selectors/ngram_overlap","title":"Select by n-gram overlap","description":"The NGramOverlapExampleSelector selects and orders examples based on which examples are most similar to the input, according to an ngram overlap score. The ngram overlap score is a float between 0.0 and 1.0, inclusive.","sidebar":"sidebar"},"modules/model_io/prompts/example_selectors/similarity":{"id":"modules/model_io/prompts/example_selectors/similarity","title":"Select by similarity","description":"This object selects examples based on similarity to the inputs. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs.","sidebar":"sidebar"},"modules/model_io/prompts/index":{"id":"modules/model_io/prompts/index","title":"Prompts","description":"The new way of programming models is through prompts.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store":{"id":"modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store","title":"Connecting to a Feature Store","description":"Feature stores are a concept from traditional machine learning that make sure data fed into models is up-to-date and relevant. For more on this, see here.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/custom_prompt_template":{"id":"modules/model_io/prompts/prompt_templates/custom_prompt_template","title":"Custom prompt template","description":"Let\'s suppose we want the LLM to generate English language explanations of a function given its name. To achieve this task, we will create a custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/few_shot_examples":{"id":"modules/model_io/prompts/prompt_templates/few_shot_examples","title":"Few-shot prompt templates","description":"In this tutorial, we\'ll learn how to create a prompt template that uses few shot examples. A few shot prompt template can be constructed from either a set of examples, or from an Example Selector object.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/few_shot_examples_chat":{"id":"modules/model_io/prompts/prompt_templates/few_shot_examples_chat","title":"Few shot examples for chat models","description":"This notebook covers how to use few shot examples in chat models.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/format_output":{"id":"modules/model_io/prompts/prompt_templates/format_output","title":"Format template output","description":"The output of the format method is available as string, list of messages and ChatPromptValue","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/formats":{"id":"modules/model_io/prompts/prompt_templates/formats","title":"Template formats","description":"By default, PromptTemplate will treat the provided template as a Python f-string. You can specify other template format through template_format argument:","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/index":{"id":"modules/model_io/prompts/prompt_templates/index","title":"Prompt templates","description":"Language models take text as input - that text is commonly referred to as a prompt.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/msg_prompt_templates":{"id":"modules/model_io/prompts/prompt_templates/msg_prompt_templates","title":"Types of MessagePromptTemplate","description":"LangChain provides different types of MessagePromptTemplate. The most commonly used are AIMessagePromptTemplate, SystemMessagePromptTemplate and HumanMessagePromptTemplate, which create an AI message, system message and human message respectively.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/partial":{"id":"modules/model_io/prompts/prompt_templates/partial","title":"Partial prompt templates","description":"Like other methods, it can make sense to \\"partial\\" a prompt template - eg pass in a subset of the required values, as to create a new prompt template which expects only the remaining subset of values.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/prompt_composition":{"id":"modules/model_io/prompts/prompt_templates/prompt_composition","title":"Composition","description":"This notebook goes over how to compose multiple prompts together. This can be useful when you want to reuse parts of prompts. This can be done with a PipelinePrompt. A PipelinePrompt consists of two main parts:","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/prompt_serialization":{"id":"modules/model_io/prompts/prompt_templates/prompt_serialization","title":"Serialization","description":"It is often preferrable to store prompts not as python code but as files. This can make it easy to share, store, and version prompts. This notebook covers how to do that in LangChain, walking through all the different types of prompts and the different serialization options.","sidebar":"sidebar"},"modules/model_io/prompts/prompt_templates/validate":{"id":"modules/model_io/prompts/prompt_templates/validate","title":"Validate template","description":"By default, PromptTemplate will validate the template string by checking whether the inputvariables match the variables defined in template. You can disable this behavior by setting validatetemplate to False","sidebar":"sidebar"},"use_cases/agent_simulations/camel_role_playing":{"id":"use_cases/agent_simulations/camel_role_playing","title":"CAMEL Role-Playing Autonomous Cooperative Agents","description":"This is a langchain implementation of paper Communicative Agents for \u201cMind\u201d Exploration of Large Scale Language Model Society\\".","sidebar":"sidebar"},"use_cases/agent_simulations/characters":{"id":"use_cases/agent_simulations/characters","title":"Generative Agents in LangChain","description":"This notebook implements a generative agent based on the paper Generative Agents: Interactive Simulacra of Human Behavior by Park, et. al.","sidebar":"sidebar"},"use_cases/agent_simulations/gymnasium":{"id":"use_cases/agent_simulations/gymnasium","title":"Simulated Environment: Gymnasium","description":"For many applications of LLM agents, the environment is real (internet, database, REPL, etc). However, we can also define agents to interact in simulated environments like text-based games. This is an example of how to create a simple agent-environment interaction loop with Gymnasium (formerly OpenAI Gym).","sidebar":"sidebar"},"use_cases/agent_simulations/index":{"id":"use_cases/agent_simulations/index","title":"Agent simulations","description":"Agent simulations involve interacting one of more agents with each other.","sidebar":"sidebar"},"use_cases/agent_simulations/multi_player_dnd":{"id":"use_cases/agent_simulations/multi_player_dnd","title":"Multi-Player Dungeons & Dragons","description":"This notebook shows how the DialogueAgent and DialogueSimulator class make it easy to extend the Two-Player Dungeons & Dragons example to multiple players.","sidebar":"sidebar"},"use_cases/agent_simulations/multiagent_authoritarian":{"id":"use_cases/agent_simulations/multiagent_authoritarian","title":"Multi-agent authoritarian speaker selection","description":"This notebook showcases how to implement a multi-agent simulation where a privileged agent decides who to speak.","sidebar":"sidebar"},"use_cases/agent_simulations/multiagent_bidding":{"id":"use_cases/agent_simulations/multiagent_bidding","title":"Multi-agent decentralized speaker selection","description":"This notebook showcases how to implement a multi-agent simulation without a fixed schedule for who speaks when. Instead the agents decide for themselves who speaks. We can implement this by having each agent bid to speak. Whichever agent\'s bid is the highest gets to speak.","sidebar":"sidebar"},"use_cases/agent_simulations/petting_zoo":{"id":"use_cases/agent_simulations/petting_zoo","title":"Multi-Agent Simulated Environment: Petting Zoo","description":"In this example, we show how to define multi-agent simulations with simulated environments. Like ours single-agent example with Gymnasium, we create an agent-environment loop with an externally defined environment. The main difference is that we now implement this kind of interaction loop with multiple agents instead. We will use the Petting Zoo library, which is the multi-agent counterpart to Gymnasium.","sidebar":"sidebar"},"use_cases/agent_simulations/two_agent_debate_tools":{"id":"use_cases/agent_simulations/two_agent_debate_tools","title":"Agent Debates with Tools","description":"This example shows how to simulate multi-agent dialogues where agents have access to tools.","sidebar":"sidebar"},"use_cases/agent_simulations/two_player_dnd":{"id":"use_cases/agent_simulations/two_player_dnd","title":"Two-Player Dungeons & Dragons","description":"In this notebook, we show how we can use concepts from CAMEL to simulate a role-playing game with a protagonist and a dungeon master. To simulate this game, we create an DialogueSimulator class that coordinates the dialogue between the two agents.","sidebar":"sidebar"},"use_cases/agents/baby_agi":{"id":"use_cases/agents/baby_agi","title":"BabyAGI User Guide","description":"This notebook demonstrates how to implement BabyAGI by Yohei Nakajima. BabyAGI is an AI agent that can generate and pretend to execute tasks based on a given objective.","sidebar":"sidebar"},"use_cases/agents/baby_agi_with_agent":{"id":"use_cases/agents/baby_agi_with_agent","title":"BabyAGI with Tools","description":"This notebook builds on top of baby agi, but shows how you can swap out the execution chain. The previous execution chain was just an LLM which made stuff up. By swapping it out with an agent that has access to tools, we can hopefully get real reliable information","sidebar":"sidebar"},"use_cases/agents/camel_role_playing":{"id":"use_cases/agents/camel_role_playing","title":"CAMEL Role-Playing Autonomous Cooperative Agents","description":"This is a langchain implementation of paper Communicative Agents for \u201cMind\u201d Exploration of Large Scale Language Model Society\\".","sidebar":"sidebar"},"use_cases/agents/custom_agent_with_plugin_retrieval":{"id":"use_cases/agents/custom_agent_with_plugin_retrieval","title":"Custom Agent with PlugIn Retrieval","description":"This notebook combines two concepts in order to build a custom agent that can interact with AI Plugins:","sidebar":"sidebar"},"use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai":{"id":"use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai","title":"Plug-and-Plai","description":"This notebook builds upon the idea of tool retrieval, but pulls all tools from plugnplai - a directory of AI Plugins.","sidebar":"sidebar"},"use_cases/agents/index":{"id":"use_cases/agents/index","title":"Agents","description":"Agents can be used for a variety of tasks.","sidebar":"sidebar"},"use_cases/agents/multi_modal_output_agent":{"id":"use_cases/agents/multi_modal_output_agent","title":"multi_modal_output_agent","description":"Multi-modal outputs: Image & Text","sidebar":"sidebar"},"use_cases/agents/sales_agent_with_context":{"id":"use_cases/agents/sales_agent_with_context","title":"SalesGPT - Your Context-Aware AI Sales Assistant","description":"This notebook demonstrates an implementation of a Context-Aware AI Sales agent.","sidebar":"sidebar"},"use_cases/agents/wikibase_agent":{"id":"use_cases/agents/wikibase_agent","title":"Wikibase Agent","description":"This notebook demonstrates a very simple wikibase agent that uses sparql generation. Although this code is intended to work against any","sidebar":"sidebar"},"use_cases/apis":{"id":"use_cases/apis","title":"Interacting with APIs","description":"Lots of data and information is stored behind APIs.","sidebar":"sidebar"},"use_cases/autonomous_agents/autogpt":{"id":"use_cases/autonomous_agents/autogpt","title":"AutoGPT","description":"Implementation of https://github.com/Significant-Gravitas/Auto-GPT but with LangChain primitives (LLMs, PromptTemplates, VectorStores, Embeddings, Tools)","sidebar":"sidebar"},"use_cases/autonomous_agents/baby_agi":{"id":"use_cases/autonomous_agents/baby_agi","title":"BabyAGI User Guide","description":"This notebook demonstrates how to implement BabyAGI by Yohei Nakajima. BabyAGI is an AI agent that can generate and pretend to execute tasks based on a given objective.","sidebar":"sidebar"},"use_cases/autonomous_agents/baby_agi_with_agent":{"id":"use_cases/autonomous_agents/baby_agi_with_agent","title":"BabyAGI with Tools","description":"This notebook builds on top of baby agi, but shows how you can swap out the execution chain. The previous execution chain was just an LLM which made stuff up. By swapping it out with an agent that has access to tools, we can hopefully get real reliable information","sidebar":"sidebar"},"use_cases/autonomous_agents/index":{"id":"use_cases/autonomous_agents/index","title":"Autonomous (long-running) agents","description":"Autonomous Agents are agents that designed to be more long running.","sidebar":"sidebar"},"use_cases/autonomous_agents/marathon_times":{"id":"use_cases/autonomous_agents/marathon_times","title":"marathon_times","description":"AutoGPT example finding Winning Marathon Times","sidebar":"sidebar"},"use_cases/autonomous_agents/meta_prompt":{"id":"use_cases/autonomous_agents/meta_prompt","title":"Meta-Prompt","description":"This is a LangChain implementation of Meta-Prompt, by Noah Goodman, for building self-improving agents.","sidebar":"sidebar"},"use_cases/chatbots/index":{"id":"use_cases/chatbots/index","title":"Chatbots","description":"Since language models are good at producing text, that makes them ideal for creating chatbots.","sidebar":"sidebar"},"use_cases/chatbots/voice_assistant":{"id":"use_cases/chatbots/voice_assistant","title":"Voice Assistant","description":"This chain creates a clone of ChatGPT with a few modifications to make it a voice assistant.","sidebar":"sidebar"},"use_cases/code/code-analysis-deeplake":{"id":"use_cases/code/code-analysis-deeplake","title":"Use LangChain, GPT and Deep Lake to work with code base","description":"In this tutorial, we are going to use Langchain + Deep Lake with GPT to analyze the code base of the LangChain itself.","sidebar":"sidebar"},"use_cases/code/index":{"id":"use_cases/code/index","title":"Code Understanding","description":"Overview","sidebar":"sidebar"},"use_cases/code/twitter-the-algorithm-analysis-deeplake":{"id":"use_cases/code/twitter-the-algorithm-analysis-deeplake","title":"Analysis of Twitter the-algorithm source code with LangChain, GPT4 and Deep Lake","description":"In this tutorial, we are going to use Langchain + Deep Lake with GPT4 to analyze the code base of the twitter algorithm.","sidebar":"sidebar"},"use_cases/extraction":{"id":"use_cases/extraction","title":"Extraction","description":"Most APIs and databases still deal with structured information.","sidebar":"sidebar"},"use_cases/multi_modal/image_agent":{"id":"use_cases/multi_modal/image_agent","title":"image_agent","description":"Multi-modal outputs: Image & Text","sidebar":"sidebar"},"use_cases/question_answering/index":{"id":"use_cases/question_answering/index","title":"Question answering over documents","description":"Question answering in this context refers to question answering over your document data.","sidebar":"sidebar"},"use_cases/question_answering/semantic-search-over-chat":{"id":"use_cases/question_answering/semantic-search-over-chat","title":"Question answering over a group chat messages","description":"In this tutorial, we are going to use Langchain + Deep Lake with GPT4 to semantically search and ask questions over a group chat.","sidebar":"sidebar"},"use_cases/summarization":{"id":"use_cases/summarization","title":"Summarization","description":"Summarization involves creating a smaller summary of multiple longer documents.","sidebar":"sidebar"},"use_cases/tabular":{"id":"use_cases/tabular","title":"Analyzing structured data","description":"Lots of data and information is stored in tabular data, whether it be csvs, excel sheets, or SQL tables.","sidebar":"sidebar"}}}')}}]);