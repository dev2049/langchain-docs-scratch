"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[40802],{3905:(e,n,t)=>{t.d(n,{Zo:()=>u,kt:()=>h});var o=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=o.createContext({}),m=function(e){var n=o.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},u=function(e){var n=m(e.components);return o.createElement(l.Provider,{value:n},e.children)},c="mdxType",p={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},d=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=m(t),d=a,h=c["".concat(l,".").concat(d)]||c[d]||p[d]||r;return t?o.createElement(h,i(i({ref:n},u),{},{components:t})):o.createElement(h,i({ref:n},u))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,i=new Array(r);i[0]=d;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[c]="string"==typeof e?e:a,i[1]=s;for(var m=2;m<r;m++)i[m]=t[m];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}d.displayName="MDXCreateElement"},87267:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>g,frontMatter:()=>u,metadata:()=>p,toc:()=>h});var o=t(87462),a=(t(67294),t(3905));const r=(i="CodeOutputBlock",function(e){return console.warn("Component "+i+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var i;const s={toc:[{value:"Using in a chain",id:"using-in-a-chain",level:2}]},l="wrapper";function m(e){let{components:n,...t}=e;return(0,a.kt)(l,(0,o.Z)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.memory import ConversationBufferMemory\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'memory = ConversationBufferMemory()\nmemory.save_context({"input": "hi"}, {"output": "whats up"})\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"memory.load_memory_variables({})\n")),(0,a.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    {'history': 'Human: hi\\nAI: whats up'}\n"))),(0,a.kt)("p",null,"We can also get the history as a list of messages (this is useful if you are using this with a chat model)."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'memory = ConversationBufferMemory(return_messages=True)\nmemory.save_context({"input": "hi"}, {"output": "whats up"})\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"memory.load_memory_variables({})\n")),(0,a.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    {'history': [HumanMessage(content='hi', additional_kwargs={}),\n      AIMessage(content='whats up', additional_kwargs={})]}\n"))),(0,a.kt)("h2",{id:"using-in-a-chain"},"Using in a chain"),(0,a.kt)("p",null,"Finally, let's take a look at using this in a chain (setting ",(0,a.kt)("inlineCode",{parentName:"p"},"verbose=True")," so we can see the prompt)."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.llms import OpenAI\nfrom langchain.chains import ConversationChain\n\n\nllm = OpenAI(temperature=0)\nconversation = ConversationChain(\n    llm=llm, \n    verbose=True, \n    memory=ConversationBufferMemory()\n)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="Hi there!")\n')),(0,a.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    \n    Human: Hi there!\n    AI:\n    \n    > Finished chain.\n\n\n\n\n\n    " Hi there! It\'s nice to meet you. How can I help you today?"\n'))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="I\'m doing well! Just having a conversation with an AI.")\n')),(0,a.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    Human: Hi there!\n    AI:  Hi there! It's nice to meet you. How can I help you today?\n    Human: I'm doing well! Just having a conversation with an AI.\n    AI:\n    \n    > Finished chain.\n\n\n\n\n\n    \" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\"\n"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'conversation.predict(input="Tell me about yourself.")\n')),(0,a.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new ConversationChain chain...\n    Prompt after formatting:\n    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n    \n    Current conversation:\n    Human: Hi there!\n    AI:  Hi there! It's nice to meet you. How can I help you today?\n    Human: I'm doing well! Just having a conversation with an AI.\n    AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n    Human: Tell me about yourself.\n    AI:\n    \n    > Finished chain.\n\n\n\n\n\n    \" Sure! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also constantly learning and updating my knowledge base so I can provide more accurate and helpful answers.\"\n"))),(0,a.kt)("p",null,"And that's it for the getting started! There are plenty of different types of memory, check out our examples to see them all"))}m.isMDXComponent=!0;const u={},c="Conversation buffer memory",p={unversionedId:"modules/memory/how_to/buffer",id:"modules/memory/how_to/buffer",title:"Conversation buffer memory",description:"This notebook shows how to use ConversationBufferMemory. This memory allows for storing of messages and then extracts the messages in a variable.",source:"@site/docs/modules/memory/how_to/buffer.mdx",sourceDirName:"modules/memory/how_to",slug:"/modules/memory/how_to/buffer",permalink:"/langchain-docs-scratch/docs/modules/memory/how_to/buffer",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/memory/how_to/buffer.mdx",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Adding Message Memory backed by a database to an Agent",permalink:"/langchain-docs-scratch/docs/modules/memory/how_to/agent_with_memory_in_db"},next:{title:"Conversation buffer window memory",permalink:"/langchain-docs-scratch/docs/modules/memory/how_to/buffer_window"}},d={},h=[],f={toc:h},y="wrapper";function g(e){let{components:n,...t}=e;return(0,a.kt)(y,(0,o.Z)({},f,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"conversation-buffer-memory"},"Conversation buffer memory"),(0,a.kt)("p",null,"This notebook shows how to use ",(0,a.kt)("inlineCode",{parentName:"p"},"ConversationBufferMemory"),". This memory allows for storing of messages and then extracts the messages in a variable."),(0,a.kt)("p",null,"We can first extract it as a string."),(0,a.kt)(m,{mdxType:"Example"}))}g.isMDXComponent=!0}}]);