"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[91490],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>u});var o=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,r=function(e,n){if(null==e)return{};var t,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=o.createContext({}),c=function(e){var n=o.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=c(e.components);return o.createElement(l.Provider,{value:n},e.children)},p="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},m=o.forwardRef((function(e,n){var t=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=c(t),m=r,u=p["".concat(l,".").concat(m)]||p[m]||g[m]||a;return t?o.createElement(u,i(i({ref:n},d),{},{components:t})):o.createElement(u,i({ref:n},d))}));function u(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=t.length,i=new Array(a);i[0]=m;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[p]="string"==typeof e?e:r,i[1]=s;for(var c=2;c<a;c++)i[c]=t[c];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}m.displayName="MDXCreateElement"},13683:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>g,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var o=t(87462),r=(t(67294),t(3905));const a={},i="MatchingEngine",s={unversionedId:"modules/data_io/vectorstores/integrations/matchingengine",id:"modules/data_io/vectorstores/integrations/matchingengine",title:"MatchingEngine",description:"This notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.",source:"@site/docs/modules/data_io/vectorstores/integrations/matchingengine.md",sourceDirName:"modules/data_io/vectorstores/integrations",slug:"/modules/data_io/vectorstores/integrations/matchingengine",permalink:"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/matchingengine",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/data_io/vectorstores/integrations/matchingengine.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"LanceDB",permalink:"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/lancedb"},next:{title:"Milvus",permalink:"/langchain-docs-scratch/docs/modules/data_io/vectorstores/integrations/milvus"}},l={},c=[{value:"Create VectorStore from texts",id:"create-vectorstore-from-texts",level:2},{value:"Create Index and deploy it to an Endpoint",id:"create-index-and-deploy-it-to-an-endpoint",level:2},{value:"Imports, Constants and Configs",id:"imports-constants-and-configs",level:3},{value:"Using Tensorflow Universal Sentence Encoder as an Embedder",id:"using-tensorflow-universal-sentence-encoder-as-an-embedder",level:3},{value:"Inserting a test embedding",id:"inserting-a-test-embedding",level:3},{value:"Creating Index",id:"creating-index",level:3},{value:"Creating Endpoint",id:"creating-endpoint",level:3},{value:"Deploy Index",id:"deploy-index",level:3}],d={toc:c},p="wrapper";function g(e){let{components:n,...t}=e;return(0,r.kt)(p,(0,o.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"matchingengine"},"MatchingEngine"),(0,r.kt)("p",null,"This notebook shows how to use functionality related to the GCP Vertex AI ",(0,r.kt)("inlineCode",{parentName:"p"},"MatchingEngine")," vector database."),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Vertex AI ",(0,r.kt)("a",{parentName:"p",href:"https://cloud.google.com/vertex-ai/docs/matching-engine/overview"},"Matching Engine")," provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note"),": This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section ",(0,r.kt)("a",{parentName:"p",href:"#create-index-and-deploy-it-to-an-endpoint"},"Create Index and deploy it to an Endpoint")),(0,r.kt)("h2",{id:"create-vectorstore-from-texts"},"Create VectorStore from texts"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.vectorstores import MatchingEngine\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"texts = ['The cat sat on', 'the mat.', 'I like to', 'eat pizza for', 'dinner.', 'The sun sets', 'in the west.']\n\n\nvector_store = MatchingEngine.from_components(\n    texts=texts,\n    project_id=\"<my_project_id>\",\n    region=\"<my_region>\",\n    gcs_bucket_uri=\"<my_gcs_bucket>\",\n    index_id=\"<my_matching_engine_index_id>\",\n    endpoint_id=\"<my_matching_engine_endpoint_id>\"\n)\n\nvector_store.add_texts(texts=texts)\n\nvector_store.similarity_search(\"lunch\", k=2)\n")),(0,r.kt)("h2",{id:"create-index-and-deploy-it-to-an-endpoint"},"Create Index and deploy it to an Endpoint"),(0,r.kt)("h3",{id:"imports-constants-and-configs"},"Imports, Constants and Configs"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# Installing dependencies.\npip install tensorflow \\\n            google-cloud-aiplatform \\\n            tensorflow-hub \\\n            tensorflow-text\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import os\nimport json\n\nfrom google.cloud import aiplatform\nimport tensorflow_hub as hub\nimport tensorflow_text\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'PROJECT_ID = "<my_project_id>"\nREGION = "<my_region>"\nVPC_NETWORK = "<my_vpc_network_name>"\nPEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.\nBUCKET_URI = "gs://<bucket_uri>"\n# The number of dimensions for the tensorflow universal sentence encoder. \n# If other embedder is used, the dimensions would probably need to change.\nDIMENSIONS = 512\nDISPLAY_NAME = "index-test-name"\nEMBEDDING_DIR = f"{BUCKET_URI}/banana"\nDEPLOYED_INDEX_ID = "endpoint-test-name"\n\nPROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:\'{PROJECT_ID}\'" --format=\'value(PROJECT_NUMBER)\'\nPROJECT_NUMBER = PROJECT_NUMBER[0]\nVPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"\n\n# Change this if you need the VPC to be created.\nCREATE_VPC = False\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# Set the project id\n gcloud config set project {PROJECT_ID}\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'# Remove the if condition to run the encapsulated code\nif CREATE_VPC:\n    # Create a VPC network\n gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}\n\n    # Add necessary firewall rules\n gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp\n gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9\n gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389\n gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22\n\n    # Reserve IP range\n gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"\n\n    # Set up peering with service networking\n    # Your account must have the "Compute Network Admin" role to run the following.\n gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# Creating bucket.\n gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI\n")),(0,r.kt)("h3",{id:"using-tensorflow-universal-sentence-encoder-as-an-embedder"},"Using Tensorflow Universal Sentence Encoder as an Embedder"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Load the Universal Sentence Encoder module\nmodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"\nmodel = hub.load(module_url)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# Generate embeddings for each word\nembeddings = model(['banana'])\n")),(0,r.kt)("h3",{id:"inserting-a-test-embedding"},"Inserting a test embedding"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'initial_config = {"id": "banana_id", "embedding": [float(x) for x in list(embeddings.numpy()[0])]}\n\nwith open("data.json", "w") as f:\n    json.dump(initial_config, f)\ngsutil cp data.json {EMBEDDING_DIR}/file.json\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\n")),(0,r.kt)("h3",{id:"creating-index"},"Creating Index"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n    display_name=DISPLAY_NAME,\n    contents_delta_uri=EMBEDDING_DIR,\n    dimensions=DIMENSIONS,\n    approximate_neighbors_count=150,\n    distance_measure_type="DOT_PRODUCT_DISTANCE"\n)\n')),(0,r.kt)("h3",{id:"creating-endpoint"},"Creating Endpoint"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n    display_name=f"{DISPLAY_NAME}-endpoint",\n    network=VPC_NETWORK_FULL,\n)\n')),(0,r.kt)("h3",{id:"deploy-index"},"Deploy Index"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"my_index_endpoint = my_index_endpoint.deploy_index(\n    index=my_index, \n    deployed_index_id=DEPLOYED_INDEX_ID\n)\n\nmy_index_endpoint.deployed_indexes\n")))}g.isMDXComponent=!0}}]);