"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[34270],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>h});var i=n(67294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,i,l=function(e,t){if(null==e)return{};var n,i,l={},a=Object.keys(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var p=i.createContext({}),s=function(e){var t=i.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},m=function(e){var t=s(e.components);return i.createElement(p.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},d=i.forwardRef((function(e,t){var n=e.components,l=e.mdxType,a=e.originalType,p=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),c=s(n),d=l,h=c["".concat(p,".").concat(d)]||c[d]||u[d]||a;return n?i.createElement(h,r(r({ref:t},m),{},{components:n})):i.createElement(h,r({ref:t},m))}));function h(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var a=n.length,r=new Array(a);r[0]=d;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o[c]="string"==typeof e?e:l,r[1]=o;for(var s=2;s<a;s++)r[s]=n[s];return i.createElement.apply(null,r)}return i.createElement.apply(null,n)}d.displayName="MDXCreateElement"},67533:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>s});var i=n(87462),l=(n(67294),n(3905));const a={},r="PipelineAI",o={unversionedId:"modules/model_io/models/llms/integrations/pipelineai_example",id:"modules/model_io/models/llms/integrations/pipelineai_example",title:"PipelineAI",description:"PipelineAI allows you to run your ML models at scale in the cloud. It also provides API access to several LLM models.",source:"@site/docs/modules/model_io/models/llms/integrations/pipelineai_example.md",sourceDirName:"modules/model_io/models/llms/integrations",slug:"/modules/model_io/models/llms/integrations/pipelineai_example",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/pipelineai_example",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/models/llms/integrations/pipelineai_example.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Petals",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/petals_example"},next:{title:"Prediction Guard",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/predictionguard"}},p={},s=[{value:"Install pipeline-ai",id:"install-pipeline-ai",level:2},{value:"Imports",id:"imports",level:2},{value:"Set the Environment API Key",id:"set-the-environment-api-key",level:2},{value:"Create the PipelineAI instance",id:"create-the-pipelineai-instance",level:2},{value:"Create a Prompt Template",id:"create-a-prompt-template",level:2},{value:"Initiate the LLMChain",id:"initiate-the-llmchain",level:2},{value:"Run the LLMChain",id:"run-the-llmchain",level:2}],m={toc:s},c="wrapper";function u(e){let{components:t,...n}=e;return(0,l.kt)(c,(0,i.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"pipelineai"},"PipelineAI"),(0,l.kt)("p",null,"PipelineAI allows you to run your ML models at scale in the cloud. It also provides API access to ",(0,l.kt)("a",{parentName:"p",href:"https://pipeline.ai"},"several LLM models"),"."),(0,l.kt)("p",null,"This notebook goes over how to use Langchain with ",(0,l.kt)("a",{parentName:"p",href:"https://docs.pipeline.ai/docs"},"PipelineAI"),"."),(0,l.kt)("h2",{id:"install-pipeline-ai"},"Install pipeline-ai"),(0,l.kt)("p",null,"The ",(0,l.kt)("inlineCode",{parentName:"p"},"pipeline-ai")," library is required to use the ",(0,l.kt)("inlineCode",{parentName:"p"},"PipelineAI")," API, AKA ",(0,l.kt)("inlineCode",{parentName:"p"},"Pipeline Cloud"),". Install ",(0,l.kt)("inlineCode",{parentName:"p"},"pipeline-ai")," using ",(0,l.kt)("inlineCode",{parentName:"p"},"pip install pipeline-ai"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"# Install the package\npip install pipeline-ai\n")),(0,l.kt)("h2",{id:"imports"},"Imports"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"import os\nfrom langchain.llms import PipelineAI\nfrom langchain import PromptTemplate, LLMChain\n")),(0,l.kt)("h2",{id:"set-the-environment-api-key"},"Set the Environment API Key"),(0,l.kt)("p",null,"Make sure to get your API key from PipelineAI. Check out the ",(0,l.kt)("a",{parentName:"p",href:"https://docs.pipeline.ai/docs/cloud-quickstart"},"cloud quickstart guide"),". You'll be given a 30 day free trial with 10 hours of serverless GPU compute to test different models."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'os.environ["PIPELINE_API_KEY"] = "YOUR_API_KEY_HERE"\n')),(0,l.kt)("h2",{id:"create-the-pipelineai-instance"},"Create the PipelineAI instance"),(0,l.kt)("p",null,"When instantiating PipelineAI, you need to specify the id or tag of the pipeline you want to use, e.g. ",(0,l.kt)("inlineCode",{parentName:"p"},'pipeline_key = "public/gpt-j:base"'),". You then have the option of passing additional pipeline-specific keyword arguments:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'llm = PipelineAI(pipeline_key="YOUR_PIPELINE_KEY", pipeline_kwargs={...})\n')),(0,l.kt)("h2",{id:"create-a-prompt-template"},"Create a Prompt Template"),(0,l.kt)("p",null,"We will create a prompt template for Question and Answer."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'template = """Question: {question}\n\nAnswer: Let\'s think step by step."""\n\nprompt = PromptTemplate(template=template, input_variables=["question"])\n')),(0,l.kt)("h2",{id:"initiate-the-llmchain"},"Initiate the LLMChain"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"llm_chain = LLMChain(prompt=prompt, llm=llm)\n")),(0,l.kt)("h2",{id:"run-the-llmchain"},"Run the LLMChain"),(0,l.kt)("p",null,"Provide a question and run the LLMChain."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"\n\nllm_chain.run(question)\n')))}u.isMDXComponent=!0}}]);