"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[65905],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>d});var r=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=r.createContext({}),p=function(e){var n=r.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=p(e.components);return r.createElement(l.Provider,{value:n},e.children)},h="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},u=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),h=p(t),u=a,d=h["".concat(l,".").concat(u)]||h[u]||m[u]||o;return t?r.createElement(d,i(i({ref:n},c),{},{components:t})):r.createElement(d,i({ref:n},c))}));function d(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=u;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[h]="string"==typeof e?e:a,i[1]=s;for(var p=2;p<o;p++)i[p]=t[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}u.displayName="MDXCreateElement"},26646:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var r=t(87462),a=(t(67294),t(3905));const o={},i="Bash chain",s={unversionedId:"modules/chains/integrations/llm_bash",id:"modules/chains/integrations/llm_bash",title:"Bash chain",description:"This notebook showcases using LLMs and a bash process to perform simple filesystem commands.",source:"@site/docs/modules/chains/integrations/llm_bash.md",sourceDirName:"modules/chains/integrations",slug:"/modules/chains/integrations/llm_bash",permalink:"/langchain-docs-scratch/docs/modules/chains/integrations/llm_bash",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/chains/integrations/llm_bash.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Graph DB QA chain",permalink:"/langchain-docs-scratch/docs/modules/chains/integrations/graph_cypher_qa"},next:{title:"Self-checking chain",permalink:"/langchain-docs-scratch/docs/modules/chains/integrations/llm_checker"}},l={},p=[{value:"Customize Prompt",id:"customize-prompt",level:2},{value:"Persistent Terminal",id:"persistent-terminal",level:2}],c=(h="CodeOutputBlock",function(e){return console.warn("Component "+h+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var h;const m={toc:p},u="wrapper";function d(e){let{components:n,...t}=e;return(0,a.kt)(u,(0,r.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"bash-chain"},"Bash chain"),(0,a.kt)("p",null,"This notebook showcases using LLMs and a bash process to perform simple filesystem commands."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.chains import LLMBashChain\nfrom langchain.llms import OpenAI\n\nllm = OpenAI(temperature=0)\n\ntext = \"Please write a bash script that prints 'Hello World' to the console.\"\n\nbash_chain = LLMBashChain.from_llm(llm, verbose=True)\n\nbash_chain.run(text)\n")),(0,a.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new LLMBashChain chain...\n    Please write a bash script that prints 'Hello World' to the console.\n    \n    ```bash\n    echo \"Hello World\"\n    ```\n    Code: ['echo \"Hello World\"']\n    Answer: Hello World\n    \n    > Finished chain.\n\n\n\n\n\n    'Hello World\\n'\n"))),(0,a.kt)("h2",{id:"customize-prompt"},"Customize Prompt"),(0,a.kt)("p",null,"You can also customize the prompt that is used. Here is an example prompting to avoid using the 'echo' utility"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.prompts.prompt import PromptTemplate\nfrom langchain.chains.llm_bash.prompt import BashOutputParser\n\n_PROMPT_TEMPLATE = """If someone asks you to perform a task, your job is to come up with a series of bash commands that will perform the task. There is no need to put "#!/bin/bash" in your answer. Make sure to reason step by step, using this format:\nQuestion: "copy the files in the directory named \'target\' into a new directory at the same level as target called \'myNewDirectory\'"\nI need to take the following actions:\n- List all files in the directory\n- Create a new directory\n- Copy the files from the first directory into the second directory\n```bash\nls\nmkdir myNewDirectory\ncp -r target/* myNewDirectory\n')),(0,a.kt)("p",null,"Do not use 'echo' when writing the script."),(0,a.kt)("p",null,'That is the format. Begin!\nQuestion: {question}"""'),(0,a.kt)("p",null,"PROMPT = PromptTemplate(input_variables=",'["question"]',", template=_PROMPT_TEMPLATE, output_parser=BashOutputParser())"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"\n\n```python\nbash_chain = LLMBashChain.from_llm(llm, prompt=PROMPT, verbose=True)\n\ntext = \"Please write a bash script that prints 'Hello World' to the console.\"\n\nbash_chain.run(text)\n")),(0,a.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new LLMBashChain chain...\n    Please write a bash script that prints 'Hello World' to the console.\n    \n    ```bash\n    printf \"Hello World\\n\"\n    ```\n    Code: ['printf \"Hello World\\\\n\"']\n    Answer: Hello World\n    \n    > Finished chain.\n\n\n\n\n\n    'Hello World\\n'\n"))),(0,a.kt)("h2",{id:"persistent-terminal"},"Persistent Terminal"),(0,a.kt)("p",null,"By default, the chain will run in a separate subprocess each time it is called. This behavior can be changed by instantiating with a persistent bash process."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.utilities.bash import BashProcess\n\n\npersistent_process = BashProcess(persistent=True)\nbash_chain = LLMBashChain.from_llm(llm, bash_process=persistent_process, verbose=True)\n\ntext = "List the current directory then move up a level."\n\nbash_chain.run(text)\n')),(0,a.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new LLMBashChain chain...\n    List the current directory then move up a level.\n    \n    ```bash\n    ls\n    cd ..\n    ```\n    Code: ['ls', 'cd ..']\n    Answer: api.ipynb           llm_summarization_checker.ipynb\n    constitutional_chain.ipynb  moderation.ipynb\n    llm_bash.ipynb          openai_openapi.yaml\n    llm_checker.ipynb       openapi.ipynb\n    llm_math.ipynb          pal.ipynb\n    llm_requests.ipynb      sqlite.ipynb\n    > Finished chain.\n\n\n\n\n\n    'api.ipynb\\t\\t\\tllm_summarization_checker.ipynb\\r\\nconstitutional_chain.ipynb\\tmoderation.ipynb\\r\\nllm_bash.ipynb\\t\\t\\topenai_openapi.yaml\\r\\nllm_checker.ipynb\\t\\topenapi.ipynb\\r\\nllm_math.ipynb\\t\\t\\tpal.ipynb\\r\\nllm_requests.ipynb\\t\\tsqlite.ipynb'\n"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Run the same command again and see that the state is maintained between calls\nbash_chain.run(text)\n")),(0,a.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new LLMBashChain chain...\n    List the current directory then move up a level.\n    \n    ```bash\n    ls\n    cd ..\n    ```\n    Code: ['ls', 'cd ..']\n    Answer: examples        getting_started.ipynb   index_examples\n    generic         how_to_guides.rst\n    > Finished chain.\n\n\n\n\n\n    'examples\\t\\tgetting_started.ipynb\\tindex_examples\\r\\ngeneric\\t\\t\\thow_to_guides.rst'\n"))))}d.isMDXComponent=!0}}]);