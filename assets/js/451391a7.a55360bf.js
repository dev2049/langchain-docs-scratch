"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[81970],{3905:(e,t,r)=>{r.d(t,{Zo:()=>u,kt:()=>y});var n=r(67294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function p(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var i=n.createContext({}),l=function(e){var t=n.useContext(i),r=t;return e&&(r="function"==typeof e?e(t):p(p({},t),e)),r},u=function(e){var t=l(e.components);return n.createElement(i.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,i=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=l(r),d=o,y=c["".concat(i,".").concat(d)]||c[d]||m[d]||a;return r?n.createElement(y,p(p({ref:t},u),{},{components:r})):n.createElement(y,p({ref:t},u))}));function y(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,p=new Array(a);p[0]=d;var s={};for(var i in t)hasOwnProperty.call(t,i)&&(s[i]=t[i]);s.originalType=e,s[c]="string"==typeof e?e:o,p[1]=s;for(var l=2;l<a;l++)p[l]=r[l];return n.createElement.apply(null,p)}return n.createElement.apply(null,r)}d.displayName="MDXCreateElement"},66027:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>i,contentTitle:()=>p,default:()=>y,frontMatter:()=>a,metadata:()=>s,toc:()=>l});var n=r(87462),o=(r(67294),r(3905));const a={},p="Pydantic (JSON) parser",s={unversionedId:"modules/model_io/output_parsers/how_to/pydantic",id:"modules/model_io/output_parsers/how_to/pydantic",title:"Pydantic (JSON) parser",description:"This output parser allows users to specify an arbitrary JSON schema and query LLMs for JSON outputs that conform to that schema.",source:"@site/docs/modules/model_io/output_parsers/how_to/pydantic.md",sourceDirName:"modules/model_io/output_parsers/how_to",slug:"/modules/model_io/output_parsers/how_to/pydantic",permalink:"/langchain-docs-scratch/docs/modules/model_io/output_parsers/how_to/pydantic",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/output_parsers/how_to/pydantic.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Auto-fixing parser",permalink:"/langchain-docs-scratch/docs/modules/model_io/output_parsers/how_to/output_fixing_parser"},next:{title:"Retry parser",permalink:"/langchain-docs-scratch/docs/modules/model_io/output_parsers/how_to/retry"}},i={},l=[],u=(c="CodeOutputBlock",function(e){return console.warn("Component "+c+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var c;const m={toc:l},d="wrapper";function y(e){let{components:t,...r}=e;return(0,o.kt)(d,(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"pydantic-json-parser"},"Pydantic (JSON) parser"),(0,o.kt)("p",null,"This output parser allows users to specify an arbitrary JSON schema and query LLMs for JSON outputs that conform to that schema."),(0,o.kt)("p",null,"Keep in mind that large language models are leaky abstractions! You'll have to use an LLM with sufficient capacity to generate well-formed JSON. In the OpenAI family, DaVinci can do reliably but Curie's ability already drops off dramatically. "),(0,o.kt)("p",null,"Use Pydantic to declare your data model. Pydantic's BaseModel like a Python dataclass, but with actual type checking + coercion."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\nfrom langchain.llms import OpenAI\nfrom langchain.chat_models import ChatOpenAI\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.output_parsers import PydanticOutputParser\nfrom pydantic import BaseModel, Field, validator\nfrom typing import List\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"model_name = 'text-davinci-003'\ntemperature = 0.0\nmodel = OpenAI(model_name=model_name, temperature=temperature)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Define your desired data structure.\nclass Joke(BaseModel):\n    setup: str = Field(description="question to set up a joke")\n    punchline: str = Field(description="answer to resolve the joke")\n    \n    # You can add custom validation logic easily with Pydantic.\n    @validator(\'setup\')\n    def question_ends_with_question_mark(cls, field):\n        if field[-1] != \'?\':\n            raise ValueError("Badly formed question!")\n        return field\n\n# And a query intented to prompt a language model to populate the data structure.\njoke_query = "Tell me a joke."\n\n# Set up a parser + inject instructions into the prompt template.\nparser = PydanticOutputParser(pydantic_object=Joke)\n\nprompt = PromptTemplate(\n    template="Answer the user query.\\n{format_instructions}\\n{query}\\n",\n    input_variables=["query"],\n    partial_variables={"format_instructions": parser.get_format_instructions()}\n)\n\n_input = prompt.format_prompt(query=joke_query)\n\noutput = model(_input.to_string())\n\nparser.parse(output)\n')),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Here\'s another example, but with a compound typed field.\nclass Actor(BaseModel):\n    name: str = Field(description="name of an actor")\n    film_names: List[str] = Field(description="list of names of films they starred in")\n        \nactor_query = "Generate the filmography for a random actor."\n\nparser = PydanticOutputParser(pydantic_object=Actor)\n\nprompt = PromptTemplate(\n    template="Answer the user query.\\n{format_instructions}\\n{query}\\n",\n    input_variables=["query"],\n    partial_variables={"format_instructions": parser.get_format_instructions()}\n)\n\n_input = prompt.format_prompt(query=actor_query)\n\noutput = model(_input.to_string())\n\nparser.parse(output)\n')),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Cast Away', 'Toy Story'])\n"))))}y.isMDXComponent=!0}}]);