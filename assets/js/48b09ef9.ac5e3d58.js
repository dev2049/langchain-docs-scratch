"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[55244],{3905:(e,t,o)=>{o.d(t,{Zo:()=>c,kt:()=>f});var n=o(67294);function r(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function a(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,n)}return o}function p(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?a(Object(o),!0).forEach((function(t){r(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):a(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function m(e,t){if(null==e)return{};var o,n,r=function(e,t){if(null==e)return{};var o,n,r={},a=Object.keys(e);for(n=0;n<a.length;n++)o=a[n],t.indexOf(o)>=0||(r[o]=e[o]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)o=a[n],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(r[o]=e[o])}return r}var s=n.createContext({}),l=function(e){var t=n.useContext(s),o=t;return e&&(o="function"==typeof e?e(t):p(p({},t),e)),o},c=function(e){var t=l(e.components);return n.createElement(s.Provider,{value:t},e.children)},i="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var o=e.components,r=e.mdxType,a=e.originalType,s=e.parentName,c=m(e,["components","mdxType","originalType","parentName"]),i=l(o),d=r,f=i["".concat(s,".").concat(d)]||i[d]||u[d]||a;return o?n.createElement(f,p(p({ref:t},c),{},{components:o})):n.createElement(f,p({ref:t},c))}));function f(e,t){var o=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=o.length,p=new Array(a);p[0]=d;var m={};for(var s in t)hasOwnProperty.call(t,s)&&(m[s]=t[s]);m.originalType=e,m[i]="string"==typeof e?e:r,p[1]=m;for(var l=2;l<a;l++)p[l]=o[l];return n.createElement.apply(null,p)}return n.createElement.apply(null,o)}d.displayName="MDXCreateElement"},65301:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>s,contentTitle:()=>p,default:()=>f,frontMatter:()=>a,metadata:()=>m,toc:()=>l});var n=o(87462),r=(o(67294),o(3905));const a={},p="Custom prompt template",m={unversionedId:"modules/model_io/prompts/prompt_templates/custom_prompt_template",id:"modules/model_io/prompts/prompt_templates/custom_prompt_template",title:"Custom prompt template",description:"Let's suppose we want the LLM to generate English language explanations of a function given its name. To achieve this task, we will create a custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function.",source:"@site/docs/modules/model_io/prompts/prompt_templates/custom_prompt_template.md",sourceDirName:"modules/model_io/prompts/prompt_templates",slug:"/modules/model_io/prompts/prompt_templates/custom_prompt_template",permalink:"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/custom_prompt_template",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/prompts/prompt_templates/custom_prompt_template.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Connecting to a Feature Store",permalink:"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store"},next:{title:"Few-shot prompt templates",permalink:"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/few_shot_examples"}},s={},l=[{value:"Why are custom prompt templates needed?",id:"why-are-custom-prompt-templates-needed",level:2},{value:"Creating a Custom Prompt Template",id:"creating-a-custom-prompt-template",level:2},{value:"Use the custom prompt template",id:"use-the-custom-prompt-template",level:2}],c=(i="CodeOutputBlock",function(e){return console.warn("Component "+i+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var i;const u={toc:l},d="wrapper";function f(e){let{components:t,...o}=e;return(0,r.kt)(d,(0,n.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"custom-prompt-template"},"Custom prompt template"),(0,r.kt)("p",null,"Let's suppose we want the LLM to generate English language explanations of a function given its name. To achieve this task, we will create a custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function."),(0,r.kt)("h2",{id:"why-are-custom-prompt-templates-needed"},"Why are custom prompt templates needed?"),(0,r.kt)("p",null,"LangChain provides a set of default prompt templates that can be used to generate prompts for a variety of tasks. However, there may be cases where the default prompt templates do not meet your needs. For example, you may want to create a prompt template with specific dynamic instructions for your language model. In such cases, you can create a custom prompt template."),(0,r.kt)("p",null,"Take a look at the current set of default prompt templates ",(0,r.kt)("a",{parentName:"p",href:"../getting_started.md"},"here"),"."),(0,r.kt)("h2",{id:"creating-a-custom-prompt-template"},"Creating a Custom Prompt Template"),(0,r.kt)("p",null,"There are essentially two distinct prompt templates available - string prompt templates and chat prompt templates. String prompt templates provides a simple prompt in string format, while chat prompt templates produces a more structured prompt to be used with a chat API."),(0,r.kt)("p",null,"In this guide, we will create a custom prompt using a string prompt template. "),(0,r.kt)("p",null,"To create a custom string prompt template, there are two requirements:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"It has an input_variables attribute that exposes what input variables the prompt template expects."),(0,r.kt)("li",{parentName:"ol"},"It exposes a format method that takes in keyword arguments corresponding to the expected input_variables and returns the formatted prompt.")),(0,r.kt)("p",null,"We will create a custom prompt template that takes in the function name as input and formats the prompt to provide the source code of the function. To achieve this, let's first create a function that will return the source code of a function given its name."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import inspect\n\ndef get_source_code(function_name):\n    # Get the source code of the function\n    return inspect.getsource(function_name)\n")),(0,r.kt)("p",null,"Next, we'll create a custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.prompts import StringPromptTemplate\nfrom pydantic import BaseModel, validator\n\n\nclass FunctionExplainerPromptTemplate(StringPromptTemplate, BaseModel):\n    """ A custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function. """\n\n    @validator("input_variables")\n    def validate_input_variables(cls, v):\n        """ Validate that the input variables are correct. """\n        if len(v) != 1 or "function_name" not in v:\n            raise ValueError("function_name must be the only input_variable.")\n        return v\n\n    def format(self, **kwargs) -> str:\n        # Get the source code of the function\n        source_code = get_source_code(kwargs["function_name"])\n\n        # Generate the prompt to be sent to the language model\n        prompt = f"""\n        Given the function name and source code, generate an English language explanation of the function.\n        Function Name: {kwargs["function_name"].__name__}\n        Source Code:\n        {source_code}\n        Explanation:\n        """\n        return prompt\n    \n    def _prompt_type(self):\n        return "function-explainer"\n')),(0,r.kt)("h2",{id:"use-the-custom-prompt-template"},"Use the custom prompt template"),(0,r.kt)("p",null,"Now that we have created a custom prompt template, we can use it to generate prompts for our task."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'fn_explainer = FunctionExplainerPromptTemplate(input_variables=["function_name"])\n\n# Generate a prompt for the function "get_source_code"\nprompt = fn_explainer.format(function_name=get_source_code)\nprint(prompt)\n')),(0,r.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n            Given the function name and source code, generate an English language explanation of the function.\n            Function Name: get_source_code\n            Source Code:\n            def get_source_code(function_name):\n        # Get the source code of the function\n        return inspect.getsource(function_name)\n    \n            Explanation:\n            \n"))))}f.isMDXComponent=!0}}]);