"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[52976],{3905:(e,t,o)=>{o.d(t,{Zo:()=>s,kt:()=>f});var p=o(67294);function n(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function r(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var p=Object.getOwnPropertySymbols(e);t&&(p=p.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,p)}return o}function a(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?r(Object(o),!0).forEach((function(t){n(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):r(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function l(e,t){if(null==e)return{};var o,p,n=function(e,t){if(null==e)return{};var o,p,n={},r=Object.keys(e);for(p=0;p<r.length;p++)o=r[p],t.indexOf(o)>=0||(n[o]=e[o]);return n}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(p=0;p<r.length;p++)o=r[p],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var m=p.createContext({}),i=function(e){var t=p.useContext(m),o=t;return e&&(o="function"==typeof e?e(t):a(a({},t),e)),o},s=function(e){var t=i(e.components);return p.createElement(m.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return p.createElement(p.Fragment,{},t)}},d=p.forwardRef((function(e,t){var o=e.components,n=e.mdxType,r=e.originalType,m=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),c=i(o),d=n,f=c["".concat(m,".").concat(d)]||c[d]||u[d]||r;return o?p.createElement(f,a(a({ref:t},s),{},{components:o})):p.createElement(f,a({ref:t},s))}));function f(e,t){var o=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var r=o.length,a=new Array(r);a[0]=d;var l={};for(var m in t)hasOwnProperty.call(t,m)&&(l[m]=t[m]);l.originalType=e,l[c]="string"==typeof e?e:n,a[1]=l;for(var i=2;i<r;i++)a[i]=o[i];return p.createElement.apply(null,a)}return p.createElement.apply(null,o)}d.displayName="MDXCreateElement"},87327:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>y,frontMatter:()=>s,metadata:()=>u,toc:()=>f});var p=o(87462),n=(o(67294),o(3905));const r=(a="CodeOutputBlock",function(e){return console.warn("Component "+a+" was not imported, exported, or provided by MDXProvider as global scope"),(0,n.kt)("div",e)});var a;const l={toc:[]},m="wrapper";function i(e){let{components:t,...o}=e;return(0,n.kt)(m,(0,p.Z)({},l,o,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.prompts.pipeline import PipelinePromptTemplate\nfrom langchain.prompts.prompt import PromptTemplate\n")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'full_template = """{introduction}\n\n{example}\n\n{start}"""\nfull_prompt = PromptTemplate.from_template(full_template)\n')),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'introduction_template = """You are impersonating {person}."""\nintroduction_prompt = PromptTemplate.from_template(introduction_template)\n')),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'example_template = """Here\'s an example of an interaction: \n\nQ: {example_q}\nA: {example_a}"""\nexample_prompt = PromptTemplate.from_template(example_template)\n')),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'start_template = """Now, do this for real!\n\nQ: {input}\nA:"""\nstart_prompt = PromptTemplate.from_template(start_template)\n')),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'input_prompts = [\n    ("introduction", introduction_prompt),\n    ("example", example_prompt),\n    ("start", start_prompt)\n]\npipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)\n')),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"pipeline_prompt.input_variables\n")),(0,n.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"    ['example_a', 'person', 'example_q', 'input']\n"))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'print(pipeline_prompt.format(\n    person="Elon Musk",\n    example_q="What\'s your favorite car?",\n    example_a="Telsa",\n    input="What\'s your favorite social media site?"\n))\n')),(0,n.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"    You are impersonating Elon Musk.\n    Here's an example of an interaction: \n    \n    Q: What's your favorite car?\n    A: Telsa\n    Now, do this for real!\n    \n    Q: What's your favorite social media site?\n    A:\n    \n"))))}i.isMDXComponent=!0;const s={},c="Composition",u={unversionedId:"modules/model_io/prompts/prompt_templates/prompt_composition",id:"modules/model_io/prompts/prompt_templates/prompt_composition",title:"Composition",description:"This notebook goes over how to compose multiple prompts together. This can be useful when you want to reuse parts of prompts. This can be done with a PipelinePrompt. A PipelinePrompt consists of two main parts:",source:"@site/docs/modules/model_io/prompts/prompt_templates/prompt_composition.mdx",sourceDirName:"modules/model_io/prompts/prompt_templates",slug:"/modules/model_io/prompts/prompt_templates/prompt_composition",permalink:"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/prompt_composition",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/prompts/prompt_templates/prompt_composition.mdx",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Partial prompt templates",permalink:"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/partial"},next:{title:"Serialization",permalink:"/langchain-docs-scratch/docs/modules/model_io/prompts/prompt_templates/prompt_serialization"}},d={},f=[],h={toc:f},_="wrapper";function y(e){let{components:t,...o}=e;return(0,n.kt)(_,(0,p.Z)({},h,o,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"composition"},"Composition"),(0,n.kt)("p",null,"This notebook goes over how to compose multiple prompts together. This can be useful when you want to reuse parts of prompts. This can be done with a PipelinePrompt. A PipelinePrompt consists of two main parts:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Final prompt: This is the final prompt that is returned"),(0,n.kt)("li",{parentName:"ul"},"Pipeline prompts: This is a list of tuples, consisting of a string name and a prompt template. Each prompt template will be formatted and then passed to future prompt templates as a variable with the same name.")),(0,n.kt)(i,{mdxType:"Example"}))}y.isMDXComponent=!0}}]);