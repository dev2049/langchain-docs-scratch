"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[83963],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>f});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},m="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),m=d(n),u=r,f=m["".concat(l,".").concat(u)]||m[u]||p[u]||o;return n?a.createElement(f,s(s({ref:t},c),{},{components:n})):a.createElement(f,s({ref:t},c))}));function f(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,s=new Array(o);s[0]=u;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[m]="string"==typeof e?e:r,s[1]=i;for(var d=2;d<o;d++)s[d]=n[d];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},39058:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>d});var a=n(87462),r=(n(67294),n(3905));const o={sidebar_position:1},s="Language models",i={unversionedId:"modules/model_io/models/index",id:"modules/model_io/models/index",title:"Language models",description:"LangChain provides interfaces and integrations for two types of models:",source:"@site/docs/modules/model_io/models/index.mdx",sourceDirName:"modules/model_io/models",slug:"/modules/model_io/models/",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/models/index.mdx",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"sidebar",previous:{title:"Select by similarity",permalink:"/langchain-docs-scratch/docs/modules/model_io/prompts/example_selectors/similarity"},next:{title:"LLMs",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/"}},l={},d=[{value:"LLMs vs Chat Models",id:"llms-vs-chat-models",level:2}],c={toc:d},m="wrapper";function p(e){let{components:t,...n}=e;return(0,r.kt)(m,(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"language-models"},"Language models"),(0,r.kt)("p",null,"LangChain provides interfaces and integrations for two types of models:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"./llms.html"},"LLMs"),": Models that take a text string as input and return a text string"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"./chat_models.html"},"Chat models"),": Models that are backed by a language model but take a list of Chat Messages as input and return a Chat Message")),(0,r.kt)("h2",{id:"llms-vs-chat-models"},"LLMs vs Chat Models"),(0,r.kt)("p",null,'LLMs and Chat Models are subtly but importantly different. LLMs in LangChain refer to pure text completion models.\nThe APIs they wrap take a string prompt as input and output a string completion. OpenAI\'s GPT-3 is implemented as an LLM.\nChat models are often backed by LLMs but tuned specifically for having conversations.\nAnd, crucially, their provider APIs expose a different interface than pure text completion models. Instead of a single string,\nthey take a list of chat messages as input. Usually these messages are labeled with the speaker (usually one of "System",\n"AI", and "Human"). And they return a ("AI") chat message as output. GPT-4 and Anthropic\'s Claude are both implemented as Chat Models.'),(0,r.kt)("p",null,'To make it possible to swap LLMs and Chat Models, both implement the Base Language Model interface. This exposes common\nmethods "predict", which takes a string and returns a string, and "predict messages", which takes messages and returns a message.\nIf you are using a specific model it\'s recommended you use the methods specific to that model class (i.e., "predict" for LLMs and "predict messages" for Chat Models),\nbut if you\'re creating an application that should work with different types of models the shared interface can be helpful.'))}p.isMDXComponent=!0}}]);