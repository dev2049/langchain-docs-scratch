"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[58819],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>d});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var p=a.createContext({}),c=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},s=function(e){var t=c(e.components);return a.createElement(p.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,p=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),m=c(n),h=o,d=m["".concat(p,".").concat(h)]||m[h]||u[h]||r;return n?a.createElement(d,i(i({ref:t},s),{},{components:n})):a.createElement(d,i({ref:t},s))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=h;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l[m]="string"==typeof e?e:o,i[1]=l;for(var c=2;c<r;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},22414:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var a=n(87462),o=(n(67294),n(3905));const r={sidebar_position:2},i="Chains",l={unversionedId:"modules/chains/index",id:"modules/chains/index",title:"Chains",description:"Using an LLM in isolation is fine for simple applications,",source:"@site/docs/modules/chains/index.mdx",sourceDirName:"modules/chains",slug:"/modules/chains/",permalink:"/langchain-docs-scratch/docs/modules/chains/",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/chains/index.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"sidebar",previous:{title:"Zep",permalink:"/langchain-docs-scratch/docs/modules/data_io/retrievers/integrations/zep_memorystore"},next:{title:"How to",permalink:"/langchain-docs-scratch/docs/modules/chains/how_to/"}},p={},c=[{value:"Why do we need chains?",id:"why-do-we-need-chains",level:2},{value:"Get started",id:"get-started",level:2},{value:"Using <code>LLMChain</code>",id:"using-llmchain",level:4}],s=(m="CodeOutputBlock",function(e){return console.warn("Component "+m+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var m;const u={toc:c},h="wrapper";function d(e){let{components:t,...n}=e;return(0,o.kt)(h,(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"chains"},"Chains"),(0,o.kt)("p",null,"Using an LLM in isolation is fine for simple applications,\nbut more complex applications require chaining LLMs - either with each other or with other components.\nLangChain provides a standard interface for ",(0,o.kt)("strong",{parentName:"p"},"Chains"),", as well as several common implementations of chains."),(0,o.kt)("p",null,"For more specifics check out:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"./how_to.html"},"How-to")," for walkthroughs of different chain features"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"./foundational.html"},"Foundational")," to get acquainted with core building block chains"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"./document.html"},"Document")," to learn how to incorporate documents into chains"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"./popular.html"},"Popular")," chains for the most common use cases"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"./additional.html"},"Additional")," to see some of the more advanced chains and integrations that you can use out of the box")),(0,o.kt)("h2",{id:"why-do-we-need-chains"},"Why do we need chains?"),(0,o.kt)("p",null,"Chains allow us to combine multiple components together to create a single, coherent application. For example, we can create a chain that takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM. We can build more complex chains by combining multiple chains together, or by combining chains with other components."),(0,o.kt)("h2",{id:"get-started"},"Get started"),(0,o.kt)("h4",{id:"using-llmchain"},"Using ",(0,o.kt)("inlineCode",{parentName:"h4"},"LLMChain")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"LLMChain")," is most basic building block chain. It takes in a prompt template, formats it with the user input and returns the response from an LLM."),(0,o.kt)("p",null,"To use the ",(0,o.kt)("inlineCode",{parentName:"p"},"LLMChain"),", first create a prompt template."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\n\nllm = OpenAI(temperature=0.9)\nprompt = PromptTemplate(\n    input_variables=["product"],\n    template="What is a good name for a company that makes {product}?",\n)\n')),(0,o.kt)("p",null,"We can now create a very simple chain that will take user input, format the prompt with it, and then send it to the LLM."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.chains import LLMChain\nchain = LLMChain(llm=llm, prompt=prompt)\n\n# Run the chain only specifying the input variable.\nprint(chain.run("colorful socks"))\n')),(0,o.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Colorful Toes Co.\n"))),(0,o.kt)("p",null,"If there are multiple variables, you can input them all at once using a dictionary."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'prompt = PromptTemplate(\n    input_variables=["company", "product"],\n    template="What is a good name for {company} that makes {product}?",\n)\nchain = LLMChain(llm=llm, prompt=prompt)\nprint(chain.run({\n    \'company\': "ABC Startup",\n    \'product\': "colorful socks"\n    }))\n')),(0,o.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Socktopia Colourful Creations.\n"))),(0,o.kt)("p",null,"You can use a chat model in an ",(0,o.kt)("inlineCode",{parentName:"p"},"LLMChain")," as well:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.chat_models import ChatOpenAI\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    HumanMessagePromptTemplate,\n)\nhuman_message_prompt = HumanMessagePromptTemplate(\n        prompt=PromptTemplate(\n            template="What is a good name for a company that makes {product}?",\n            input_variables=["product"],\n        )\n    )\nchat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\nchat = ChatOpenAI(temperature=0.9)\nchain = LLMChain(llm=chat, prompt=chat_prompt_template)\nprint(chain.run("colorful socks"))\n')),(0,o.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Rainbow Socks Co.\n"))))}d.isMDXComponent=!0}}]);