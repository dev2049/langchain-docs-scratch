"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[55701],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>h});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},m=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},g=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),p=c(n),g=r,h=p["".concat(s,".").concat(g)]||p[g]||u[g]||l;return n?a.createElement(h,o(o({ref:t},m),{},{components:n})):a.createElement(h,o({ref:t},m))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,o=new Array(l);o[0]=g;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[p]="string"==typeof e?e:r,o[1]=i;for(var c=2;c<l;c++)o[c]=n[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}g.displayName="MDXCreateElement"},57080:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>i,toc:()=>c});var a=n(87462),r=(n(67294),n(3905));const l={},o="Comet",i={unversionedId:"ecosystem/integrations/comet_tracking",id:"ecosystem/integrations/comet_tracking",title:"Comet",description:"In this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.",source:"@site/docs/ecosystem/integrations/comet_tracking.md",sourceDirName:"ecosystem/integrations",slug:"/ecosystem/integrations/comet_tracking",permalink:"/langchain-docs-scratch/docs/ecosystem/integrations/comet_tracking",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/ecosystem/integrations/comet_tracking.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"College Confidential",permalink:"/langchain-docs-scratch/docs/ecosystem/integrations/college_confidential"},next:{title:"Confluence",permalink:"/langchain-docs-scratch/docs/ecosystem/integrations/confluence"}},s={},c=[{value:"Install Comet and Dependencies",id:"install-comet-and-dependencies",level:3},{value:"Initialize Comet and Set your Credentials",id:"initialize-comet-and-set-your-credentials",level:3},{value:"Set OpenAI and SerpAPI credentials",id:"set-openai-and-serpapi-credentials",level:3},{value:"Scenario 1: Using just an LLM",id:"scenario-1-using-just-an-llm",level:3},{value:"Scenario 2: Using an LLM in a Chain",id:"scenario-2-using-an-llm-in-a-chain",level:3},{value:"Scenario 3: Using An Agent with Tools",id:"scenario-3-using-an-agent-with-tools",level:3},{value:"Scenario 4: Using Custom Evaluation Metrics",id:"scenario-4-using-custom-evaluation-metrics",level:3}],m={toc:c},p="wrapper";function u(e){let{components:t,...n}=e;return(0,r.kt)(p,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"comet"},"Comet"),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/7529846/230328046-a8b18c51-12e3-4617-9b39-97614a571a2d.png",alt:null})),(0,r.kt)("p",null,"In this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with ",(0,r.kt)("a",{parentName:"p",href:"https://www.comet.com/site/?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook"},"Comet"),".  "),(0,r.kt)("a",{target:"_blank",href:"https://colab.research.google.com/github/hwchase17/langchain/blob/master/docs/ecosystem/comet_tracking.ipynb"},(0,r.kt)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Example Project:")," ",(0,r.kt)("a",{parentName:"p",href:"https://www.comet.com/examples/comet-example-langchain/view/b5ZThK6OFdhKWVSP3fDfRtrNF/panels?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook"},"Comet with LangChain")),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/7529846/230326720-a9711435-9c6f-4edb-a707-94b67271ab25.png",alt:null})),(0,r.kt)("h3",{id:"install-comet-and-dependencies"},"Install Comet and Dependencies"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"import sys\n{sys.executable} -m spacy download en_core_web_sm\n")),(0,r.kt)("h3",{id:"initialize-comet-and-set-your-credentials"},"Initialize Comet and Set your Credentials"),(0,r.kt)("p",null,"You can grab your ",(0,r.kt)("a",{parentName:"p",href:"https://www.comet.com/signup?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook"},"Comet API Key here")," or click the link after initializing Comet"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import comet_ml\n\ncomet_ml.init(project_name="comet-example-langchain")\n')),(0,r.kt)("h3",{id:"set-openai-and-serpapi-credentials"},"Set OpenAI and SerpAPI credentials"),(0,r.kt)("p",null,"You will need an ",(0,r.kt)("a",{parentName:"p",href:"https://platform.openai.com/account/api-keys"},"OpenAI API Key")," and a ",(0,r.kt)("a",{parentName:"p",href:"https://serpapi.com/dashboard"},"SerpAPI API Key")," to run the following examples"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import os\n\nos.environ["OPENAI_API_KEY"] = "..."\n#os.environ["OPENAI_ORGANIZATION"] = "..."\nos.environ["SERPAPI_API_KEY"] = "..."\n')),(0,r.kt)("h3",{id:"scenario-1-using-just-an-llm"},"Scenario 1: Using just an LLM"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from datetime import datetime\n\nfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandler\nfrom langchain.llms import OpenAI\n\ncomet_callback = CometCallbackHandler(\n    project_name="comet-example-langchain",\n    complexity_metrics=True,\n    stream_logs=True,\n    tags=["llm"],\n    visualizations=["dep"],\n)\ncallbacks = [StdOutCallbackHandler(), comet_callback]\nllm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)\n\nllm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)\nprint("LLM result", llm_result)\ncomet_callback.flush_tracker(llm, finish=True)\n')),(0,r.kt)("h3",{id:"scenario-2-using-an-llm-in-a-chain"},"Scenario 2: Using an LLM in a Chain"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.callbacks import CometCallbackHandler, StdOutCallbackHandler\nfrom langchain.chains import LLMChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\n\ncomet_callback = CometCallbackHandler(\n    complexity_metrics=True,\n    project_name="comet-example-langchain",\n    stream_logs=True,\n    tags=["synopsis-chain"],\n)\ncallbacks = [StdOutCallbackHandler(), comet_callback]\nllm = OpenAI(temperature=0.9, callbacks=callbacks)\n\ntemplate = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\nTitle: {title}\nPlaywright: This is a synopsis for the above play:"""\nprompt_template = PromptTemplate(input_variables=["title"], template=template)\nsynopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)\n\ntest_prompts = [{"title": "Documentary about Bigfoot in Paris"}]\nprint(synopsis_chain.apply(test_prompts))\ncomet_callback.flush_tracker(synopsis_chain, finish=True)\n')),(0,r.kt)("h3",{id:"scenario-3-using-an-agent-with-tools"},"Scenario 3: Using An Agent with Tools"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.agents import initialize_agent, load_tools\nfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandler\nfrom langchain.llms import OpenAI\n\ncomet_callback = CometCallbackHandler(\n    project_name="comet-example-langchain",\n    complexity_metrics=True,\n    stream_logs=True,\n    tags=["agent"],\n)\ncallbacks = [StdOutCallbackHandler(), comet_callback]\nllm = OpenAI(temperature=0.9, callbacks=callbacks)\n\ntools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)\nagent = initialize_agent(\n    tools,\n    llm,\n    agent="zero-shot-react-description",\n    callbacks=callbacks,\n    verbose=True,\n)\nagent.run(\n    "Who is Leo DiCaprio\'s girlfriend? What is her current age raised to the 0.43 power?"\n)\ncomet_callback.flush_tracker(agent, finish=True)\n')),(0,r.kt)("h3",{id:"scenario-4-using-custom-evaluation-metrics"},"Scenario 4: Using Custom Evaluation Metrics"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"CometCallbackManager")," also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. "),(0,r.kt)("p",null,"In the snippet below, we will use the ",(0,r.kt)("a",{parentName:"p",href:"https://huggingface.co/spaces/evaluate-metric/rouge"},"ROUGE")," metric to evaluate the quality of a generated summary of an input prompt. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"%pip install rouge-score\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from rouge_score import rouge_scorer\n\nfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandler\nfrom langchain.chains import LLMChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\n\n\nclass Rouge:\n    def __init__(self, reference):\n        self.reference = reference\n        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)\n\n    def compute_metric(self, generation, prompt_idx, gen_idx):\n        prediction = generation.text\n        results = self.scorer.score(target=self.reference, prediction=prediction)\n\n        return {\n            "rougeLsum_score": results["rougeLsum"].fmeasure,\n            "reference": self.reference,\n        }\n\n\nreference = """\nThe tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.\nIt was the first structure to reach a height of 300 metres.\n\nIt is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)\nExcluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France .\n"""\nrouge_score = Rouge(reference=reference)\n\ntemplate = """Given the following article, it is your job to write a summary.\nArticle:\n{article}\nSummary: This is the summary for the above article:"""\nprompt_template = PromptTemplate(input_variables=["article"], template=template)\n\ncomet_callback = CometCallbackHandler(\n    project_name="comet-example-langchain",\n    complexity_metrics=False,\n    stream_logs=True,\n    tags=["custom_metrics"],\n    custom_metrics=rouge_score.compute_metric,\n)\ncallbacks = [StdOutCallbackHandler(), comet_callback]\nllm = OpenAI(temperature=0.9)\n\nsynopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n\ntest_prompts = [\n    {\n        "article": """\n                 The tower is 324 metres (1,063 ft) tall, about the same height as\n                 an 81-storey building, and the tallest structure in Paris. Its base is square,\n                 measuring 125 metres (410 ft) on each side.\n                 During its construction, the Eiffel Tower surpassed the\n                 Washington Monument to become the tallest man-made structure in the world,\n                 a title it held for 41 years until the Chrysler Building\n                 in New York City was finished in 1930.\n\n                 It was the first structure to reach a height of 300 metres.\n                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,\n                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).\n\n                 Excluding transmitters, the Eiffel Tower is the second tallest\n                 free-standing structure in France after the Millau Viaduct.\n                 """\n    }\n]\nprint(synopsis_chain.apply(test_prompts, callbacks=callbacks))\ncomet_callback.flush_tracker(synopsis_chain, finish=True)\n')))}u.isMDXComponent=!0}}]);