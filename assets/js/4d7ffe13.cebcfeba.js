"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[30648],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>h});var a=r(67294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function l(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function p(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},o=Object.keys(e);for(a=0;a<o.length;a++)r=o[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)r=o[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var i=a.createContext({}),s=function(e){var t=a.useContext(i),r=t;return e&&(r="function"==typeof e?e(t):l(l({},t),e)),r},c=function(e){var t=s(e.components);return a.createElement(i.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,o=e.originalType,i=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),m=s(r),d=n,h=m["".concat(i,".").concat(d)]||m[d]||u[d]||o;return r?a.createElement(h,l(l({ref:t},c),{},{components:r})):a.createElement(h,l({ref:t},c))}));function h(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=r.length,l=new Array(o);l[0]=d;var p={};for(var i in t)hasOwnProperty.call(t,i)&&(p[i]=t[i]);p.originalType=e,p[m]="string"==typeof e?e:n,l[1]=p;for(var s=2;s<o;s++)l[s]=r[s];return a.createElement.apply(null,l)}return a.createElement.apply(null,r)}d.displayName="MDXCreateElement"},64242:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>i,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>p,toc:()=>s});var a=r(87462),n=(r(67294),r(3905));const o={},l="PromptLayer ChatOpenAI",p={unversionedId:"modules/model_io/models/chat/integrations/promptlayer_chatopenai",id:"modules/model_io/models/chat/integrations/promptlayer_chatopenai",title:"PromptLayer ChatOpenAI",description:"This example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.",source:"@site/docs/modules/model_io/models/chat/integrations/promptlayer_chatopenai.md",sourceDirName:"modules/model_io/models/chat/integrations",slug:"/modules/model_io/models/chat/integrations/promptlayer_chatopenai",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/chat/integrations/promptlayer_chatopenai",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/models/chat/integrations/promptlayer_chatopenai.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"OpenAI",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/chat/integrations/openai"},next:{title:"Text embedding models",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/text_embedding/"}},i={},s=[{value:"Install PromptLayer",id:"install-promptlayer",level:2},{value:"Imports",id:"imports",level:2},{value:"Set the Environment API Key",id:"set-the-environment-api-key",level:2},{value:"Use the PromptLayerOpenAI LLM like normal",id:"use-the-promptlayeropenai-llm-like-normal",level:2},{value:"Using PromptLayer Track",id:"using-promptlayer-track",level:2}],c=(m="CodeOutputBlock",function(e){return console.warn("Component "+m+" was not imported, exported, or provided by MDXProvider as global scope"),(0,n.kt)("div",e)});var m;const u={toc:s},d="wrapper";function h(e){let{components:t,...r}=e;return(0,n.kt)(d,(0,a.Z)({},u,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"promptlayer-chatopenai"},"PromptLayer ChatOpenAI"),(0,n.kt)("p",null,"This example showcases how to connect to ",(0,n.kt)("a",{parentName:"p",href:"https://www.promptlayer.com"},"PromptLayer")," to start recording your ChatOpenAI requests."),(0,n.kt)("h2",{id:"install-promptlayer"},"Install PromptLayer"),(0,n.kt)("p",null,"The ",(0,n.kt)("inlineCode",{parentName:"p"},"promptlayer")," package is required to use PromptLayer with OpenAI. Install ",(0,n.kt)("inlineCode",{parentName:"p"},"promptlayer")," using pip."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"pip install promptlayer\n")),(0,n.kt)("h2",{id:"imports"},"Imports"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"import os\nfrom langchain.chat_models import PromptLayerChatOpenAI\nfrom langchain.schema import HumanMessage\n")),(0,n.kt)("h2",{id:"set-the-environment-api-key"},"Set the Environment API Key"),(0,n.kt)("p",null,"You can create a PromptLayer API Key at ",(0,n.kt)("a",{parentName:"p",href:"https://www.promptlayer.com"},"www.promptlayer.com")," by clicking the settings cog in the navbar."),(0,n.kt)("p",null,"Set it as an environment variable called ",(0,n.kt)("inlineCode",{parentName:"p"},"PROMPTLAYER_API_KEY"),"."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'os.environ["PROMPTLAYER_API_KEY"] = "**********"\n')),(0,n.kt)("h2",{id:"use-the-promptlayeropenai-llm-like-normal"},"Use the PromptLayerOpenAI LLM like normal"),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},"You can optionally pass in ",(0,n.kt)("inlineCode",{parentName:"em"},"pl_tags")," to track your requests with PromptLayer's tagging feature.")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'chat = PromptLayerChatOpenAI(pl_tags=["langchain"])\nchat([HumanMessage(content="I am a cat and I want")])\n')),(0,n.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})\n"))),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"The above request should now appear on your ",(0,n.kt)("a",{parentName:"strong",href:"https://www.promptlayer.com"},"PromptLayer dashboard"),".")),(0,n.kt)("h2",{id:"using-promptlayer-track"},"Using PromptLayer Track"),(0,n.kt)("p",null,"If you would like to use any of the ",(0,n.kt)("a",{parentName:"p",href:"https://magniv.notion.site/Track-4deee1b1f7a34c1680d085f82567dab9"},"PromptLayer tracking features"),", you need to pass the argument ",(0,n.kt)("inlineCode",{parentName:"p"},"return_pl_id")," when instantializing the PromptLayer LLM to get the request id.  "),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'chat = PromptLayerChatOpenAI(return_pl_id=True)\nchat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])\n\nfor res in chat_results.generations:\n    pl_request_id = res[0].generation_info["pl_request_id"]\n    promptlayer.track.score(request_id=pl_request_id, score=100)\n')),(0,n.kt)("p",null,"Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well.\nOverall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard."))}h.isMDXComponent=!0}}]);