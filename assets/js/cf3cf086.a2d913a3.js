"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[11038],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>h});var a=n(67294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function p(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var i=a.createContext({}),c=function(e){var t=a.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},s=function(e){var t=c(e.components);return a.createElement(i.Provider,{value:t},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,o=e.originalType,i=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),m=c(n),u=l,h=m["".concat(i,".").concat(u)]||m[u]||d[u]||o;return n?a.createElement(h,r(r({ref:t},s),{},{components:n})):a.createElement(h,r({ref:t},s))}));function h(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var o=n.length,r=new Array(o);r[0]=u;var p={};for(var i in t)hasOwnProperty.call(t,i)&&(p[i]=t[i]);p.originalType=e,p[m]="string"==typeof e?e:l,r[1]=p;for(var c=2;c<o;c++)r[c]=n[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},82288:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>p,toc:()=>c});var a=n(87462),l=(n(67294),n(3905));const o={},r="Replicate",p={unversionedId:"modules/model_io/models/llms/integrations/replicate",id:"modules/model_io/models/llms/integrations/replicate",title:"Replicate",description:"Replicate runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you're building your own machine learning models, Replicate makes it easy to deploy them at scale.",source:"@site/docs/modules/model_io/models/llms/integrations/replicate.md",sourceDirName:"modules/model_io/models/llms/integrations",slug:"/modules/model_io/models/llms/integrations/replicate",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/replicate",draft:!1,editUrl:"https://github.com/hwchase17/langchainjs/edit/main/docs/docs/modules/model_io/models/llms/integrations/replicate.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"RELLM",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/rellm_experimental"},next:{title:"Runhouse",permalink:"/langchain-docs-scratch/docs/modules/model_io/models/llms/integrations/runhouse"}},i={},c=[{value:"Setup",id:"setup",level:2},{value:"Calling a model",id:"calling-a-model",level:2},{value:"Chaining Calls",id:"chaining-calls",level:2}],s=(m="CodeOutputBlock",function(e){return console.warn("Component "+m+" was not imported, exported, or provided by MDXProvider as global scope"),(0,l.kt)("div",e)});var m;const d={toc:c},u="wrapper";function h(e){let{components:t,...n}=e;return(0,l.kt)(u,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"replicate"},"Replicate"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},(0,l.kt)("a",{parentName:"p",href:"https://replicate.com/blog/machine-learning-needs-better-tools"},"Replicate")," runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you're building your own machine learning models, Replicate makes it easy to deploy them at scale.")),(0,l.kt)("p",null,"This example goes over how to use LangChain to interact with ",(0,l.kt)("inlineCode",{parentName:"p"},"Replicate")," ",(0,l.kt)("a",{parentName:"p",href:"https://replicate.com/explore"},"models")),(0,l.kt)("h2",{id:"setup"},"Setup"),(0,l.kt)("p",null,"To run this notebook, you'll need to create a ",(0,l.kt)("a",{parentName:"p",href:"https://replicate.com"},"replicate")," account and install the ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/replicate/replicate-python"},"replicate python client"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"pip install replicate\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# get a token: https://replicate.com/account\n\nfrom getpass import getpass\n\nREPLICATE_API_TOKEN = getpass()\n")),(0,l.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"     \xb7\xb7\xb7\xb7\xb7\xb7\xb7\xb7\n"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'import os\n\nos.environ["REPLICATE_API_TOKEN"] = REPLICATE_API_TOKEN\n')),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.llms import Replicate\nfrom langchain import PromptTemplate, LLMChain\n")),(0,l.kt)("h2",{id:"calling-a-model"},"Calling a model"),(0,l.kt)("p",null,"Find a model on the ",(0,l.kt)("a",{parentName:"p",href:"https://replicate.com/explore"},"replicate explore page"),", and then paste in the model name and version in this format: model_name/version"),(0,l.kt)("p",null,"For example, for this ",(0,l.kt)("a",{parentName:"p",href:"https://replicate.com/replicate/dolly-v2-12b"},"dolly model"),", click on the API tab. The model name/version would be: ",(0,l.kt)("inlineCode",{parentName:"p"},"replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5")),(0,l.kt)("p",null,"Only the ",(0,l.kt)("inlineCode",{parentName:"p"},"model")," param is required, but we can add other model params when initializing."),(0,l.kt)("p",null,"For example, if we were running stable diffusion and wanted to change the image dimensions:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"Replicate(model=\"stability-ai/stable-diffusion:db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf\", input={'image_dimensions': '512x512'})\n")),(0,l.kt)("p",null,(0,l.kt)("em",{parentName:"p"},"Note that only the first output of a model will be returned.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'llm = Replicate(model="replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5")\n')),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'prompt = """\nAnswer the following yes/no question by reasoning step by step. \nCan a dog drive a car?\n"""\nllm(prompt)\n')),(0,l.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"    'The legal driving age of dogs is 2. Cars are designed for humans to drive. Therefore, the final answer is yes.'\n"))),(0,l.kt)("p",null,"We can call any replicate model using this syntax. For example, we can call stable diffusion."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"text2image = Replicate(model=\"stability-ai/stable-diffusion:db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf\", \n                       input={'image_dimensions': '512x512'})\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'image_output = text2image("A cat riding a motorcycle by Picasso")\nimage_output\n')),(0,l.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"    'https://replicate.delivery/pbxt/Cf07B1zqzFQLOSBQcKG7m9beE74wf7kuip5W9VxHJFembefKE/out-0.png'\n"))),(0,l.kt)("p",null,"The model spits out a URL. Let's render it."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from PIL import Image\nimport requests\nfrom io import BytesIO\n\nresponse = requests.get(image_output)\nimg = Image.open(BytesIO(response.content))\n\nimg\n")),(0,l.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"    \n![png](_replicate_files/output_14_0.png)\n    \n"))),(0,l.kt)("h2",{id:"chaining-calls"},"Chaining Calls"),(0,l.kt)("p",null,"The whole point of langchain is to... chain! Here's an example of how do that."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.chains import SimpleSequentialChain\n")),(0,l.kt)("p",null,"First, let's define the LLM for this model as a flan-5, and text2image as a stable diffusion model."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'dolly_llm = Replicate(model="replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5")\ntext2image = Replicate(model="stability-ai/stable-diffusion:db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf")\n')),(0,l.kt)("p",null,"First prompt in the chain"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'prompt = PromptTemplate(\n    input_variables=["product"],\n    template="What is a good name for a company that makes {product}?",\n)\n\nchain = LLMChain(llm=dolly_llm, prompt=prompt)\n')),(0,l.kt)("p",null,"Second prompt to get the logo for company description"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'second_prompt = PromptTemplate(\n    input_variables=["company_name"],\n    template="Write a description of a logo for this company: {company_name}",\n)\nchain_two = LLMChain(llm=dolly_llm, prompt=second_prompt)\n')),(0,l.kt)("p",null,"Third prompt, let's create the image based on the description output from prompt 2"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'third_prompt = PromptTemplate(\n    input_variables=["company_logo_description"],\n    template="{company_logo_description}",\n)\nchain_three = LLMChain(llm=text2image, prompt=third_prompt)\n')),(0,l.kt)("p",null,"Now let's run it!"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# Run the chain specifying only the input variable for the first chain.\noverall_chain = SimpleSequentialChain(chains=[chain, chain_two, chain_three], verbose=True)\ncatchphrase = overall_chain.run("colorful socks")\nprint(catchphrase)\n')),(0,l.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new SimpleSequentialChain chain...\n    novelty socks\n    todd & co.\n    https://replicate.delivery/pbxt/BedAP1PPBwXFfkmeD7xDygXO4BcvApp1uvWOwUdHM4tcQfvCB/out-0.png\n    \n    > Finished chain.\n    https://replicate.delivery/pbxt/BedAP1PPBwXFfkmeD7xDygXO4BcvApp1uvWOwUdHM4tcQfvCB/out-0.png\n"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'response = requests.get("https://replicate.delivery/pbxt/eq6foRJngThCAEBqse3nL3Km2MBfLnWQNd0Hy2SQRo2LuprCB/out-0.png")\nimg = Image.open(BytesIO(response.content))\nimg\n')),(0,l.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"    \n![png](_replicate_files/output_27_0.png)\n    \n"))))}h.isMDXComponent=!0}}]);